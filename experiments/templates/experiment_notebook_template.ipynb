{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# QuartumSE Experiment Pipeline Notebook\n",
        "\n",
        "This template mirrors the command-line pipeline for exploratory runs. Execute the cells sequentially or use *Run All* to reproduce the CLI output.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import yaml\n",
        "\n",
        "from experiments.pipeline.metadata_schema import ExperimentMetadata\n",
        "\n",
        "metadata_path = Path(\"experiments/shadows/examples/extended_ghz/experiment_metadata.yaml\")\n",
        "with metadata_path.open(\"r\", encoding=\"utf-8\") as fh:\n",
        "    metadata_payload = yaml.safe_load(fh) or {}\n",
        "metadata = ExperimentMetadata.model_validate(metadata_payload)\n",
        "metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "from experiments.pipeline.executor import execute_experiment\n",
        "\n",
        "output_dir = Path(\"experiments/shadows/examples/extended_ghz/notebook_output\")\n",
        "if output_dir.exists():\n",
        "    shutil.rmtree(output_dir)\n",
        "\n",
        "execution_result = execute_experiment(metadata, output_dir=output_dir)\n",
        "execution_result\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from experiments.pipeline.verifier import verify_experiment\n",
        "\n",
        "verification = verify_experiment(execution_result[\"manifest_v1\"])\n",
        "verification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from experiments.pipeline.analyzer import analyze_experiment\n",
        "from experiments.pipeline.run_full_pipeline import _normalise_targets\n",
        "\n",
        "manifest_v0 = json.loads(execution_result[\"manifest_v0\"].read_text(encoding=\"utf-8\"))\n",
        "manifest_v1 = json.loads(execution_result[\"manifest_v1\"].read_text(encoding=\"utf-8\"))\n",
        "manifest_baseline = json.loads(execution_result[\"manifest_baseline\"].read_text(encoding=\"utf-8\"))\n",
        "\n",
        "targets = _normalise_targets(metadata)\n",
        "analysis = analyze_experiment(\n",
        "    manifest_v0,\n",
        "    manifest_v1,\n",
        "    manifest_baseline,\n",
        "    ground_truth=metadata.ground_truth,\n",
        "    targets=targets if targets else None,\n",
        ")\n",
        "analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from experiments.pipeline.reporter import generate_report\n",
        "from experiments.pipeline.run_full_pipeline import _prepare_artifacts, _write_json\n",
        "\n",
        "digest = execution_result[\"result_hash\"].read_text(encoding=\"utf-8\").strip()\n",
        "analysis_path = output_dir / f\"analysis_{digest}.json\"\n",
        "_write_json(analysis_path, dict(analysis))\n",
        "\n",
        "artifacts = _prepare_artifacts(execution_result, digest)\n",
        "report_path = output_dir / f\"report_{digest}.html\"\n",
        "generate_report(metadata, artifacts, analysis, verification, report_path)\n",
        "\n",
        "{\n",
        "    \"analysis_path\": str(analysis_path),\n",
        "    \"report_path\": str(report_path),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(f\"<a href='{report_path.as_posix()}' target='_blank'>Open generated report</a>\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}