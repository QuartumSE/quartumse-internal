{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Classical Shadows: A Deep Dive into the Implementation\n",
    "\n",
    "This notebook walks through **every step** of QuartumSE's classical shadows implementation, explaining both the theory and the code.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Theory**: The mathematical foundation of classical shadows\n",
    "2. **Step 1**: Random basis selection (local Clifford sampling)\n",
    "3. **Step 2**: Circuit generation with measurement rotations\n",
    "4. **Step 3**: Measurement execution and data collection\n",
    "5. **Step 4**: Shadow reconstruction via inverse channel\n",
    "6. **Step 5**: Observable estimation with the 3^k scaling factor\n",
    "7. **Step 6**: Confidence intervals and variance bounds\n",
    "8. **Bonus**: Noise-aware shadows (v1) with MEM\n",
    "\n",
    "## Reference\n",
    "\n",
    "Huang, Kueng, Preskill (2020) - \"Predicting Many Properties of a Quantum System\" ([arXiv:2002.08953](https://arxiv.org/abs/2002.08953))\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theory-header",
   "metadata": {},
   "source": [
    "## Part 0: The Theory Behind Classical Shadows\n",
    "\n",
    "### The Core Idea\n",
    "\n",
    "Classical shadows create a **classical description** of a quantum state that can be used to estimate **any observable** later.\n",
    "\n",
    "### The Protocol\n",
    "\n",
    "1. **Prepare** the quantum state $\\rho$\n",
    "2. **Apply** a random unitary $U$ from an ensemble (e.g., local Cliffords)\n",
    "3. **Measure** in computational basis, get outcome $|b\\rangle$\n",
    "4. **Invert** to get a \"snapshot\": $\\hat{\\rho} = \\mathcal{M}^{-1}(U^\\dagger |b\\rangle\\langle b| U)$\n",
    "\n",
    "### The Key Insight\n",
    "\n",
    "The **inverse channel** $\\mathcal{M}^{-1}$ ensures that the average snapshot equals the true state:\n",
    "\n",
    "$$\\mathbb{E}[\\hat{\\rho}] = \\rho$$\n",
    "\n",
    "### For Random Local Cliffords\n",
    "\n",
    "When using random single-qubit Clifford gates (which rotate to X, Y, or Z basis):\n",
    "\n",
    "- The inverse channel for a single qubit is: $\\hat{\\rho}_q = 3|b_q\\rangle\\langle b_q| - I$\n",
    "- For n qubits: $\\hat{\\rho} = \\bigotimes_{q=1}^{n} \\hat{\\rho}_q$\n",
    "\n",
    "### Estimating Observables\n",
    "\n",
    "To estimate $\\langle O \\rangle = \\text{Tr}(O\\rho)$:\n",
    "\n",
    "$$\\hat{o} = \\frac{1}{M} \\sum_{i=1}^{M} \\text{Tr}(O \\hat{\\rho}_i)$$\n",
    "\n",
    "For **Pauli observables**, this simplifies dramatically:\n",
    "- If the measurement basis matches the Pauli, we get a signal\n",
    "- If it doesn't match, that shadow contributes 0\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Qiskit imports\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit.visualization import circuit_drawer\n",
    "\n",
    "# Add QuartumSE to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "# QuartumSE imports - we'll use these AND manually implement steps\n",
    "from quartumse.shadows.config import ShadowConfig, ShadowVersion\n",
    "from quartumse.shadows.core import Observable, ShadowEstimate\n",
    "from quartumse.shadows.v0_baseline import RandomLocalCliffordShadows\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "state-header",
   "metadata": {},
   "source": [
    "## Part 2: Create Our Test State\n",
    "\n",
    "We'll use a simple Bell state for clarity: $|\\Phi^+\\rangle = \\frac{1}{\\sqrt{2}}(|00\\rangle + |11\\rangle)$\n",
    "\n",
    "### Known Expectation Values:\n",
    "- $\\langle ZI \\rangle = 0$ (first qubit in superposition)\n",
    "- $\\langle IZ \\rangle = 0$ (second qubit in superposition)\n",
    "- $\\langle ZZ \\rangle = +1$ (perfect correlation)\n",
    "- $\\langle XX \\rangle = +1$ (perfect correlation in X basis)\n",
    "- $\\langle YY \\rangle = -1$ (anti-correlation in Y basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bell state circuit\n",
    "def create_bell_state():\n",
    "    qc = QuantumCircuit(2)\n",
    "    qc.h(0)       # Hadamard on qubit 0\n",
    "    qc.cx(0, 1)   # CNOT: control=0, target=1\n",
    "    return qc\n",
    "\n",
    "bell_circuit = create_bell_state()\n",
    "\n",
    "print(\"Bell State Preparation Circuit:\")\n",
    "print(bell_circuit)\n",
    "\n",
    "# Ground truth expectation values\n",
    "GROUND_TRUTH = {\n",
    "    \"ZI\": 0.0,\n",
    "    \"IZ\": 0.0,\n",
    "    \"ZZ\": 1.0,\n",
    "    \"XX\": 1.0,\n",
    "    \"YY\": -1.0,\n",
    "    \"XY\": 0.0,\n",
    "    \"YX\": 0.0,\n",
    "}\n",
    "\n",
    "print(\"\\nGround Truth Expectation Values:\")\n",
    "for obs, val in GROUND_TRUTH.items():\n",
    "    print(f\"  <{obs}> = {val:+.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Random Basis Selection\n",
    "\n",
    "The first step is to choose **random measurement bases** for each qubit.\n",
    "\n",
    "### The Three Bases\n",
    "\n",
    "| Index | Basis | Gate to Apply | What We Measure |\n",
    "|-------|-------|---------------|------------------|\n",
    "| 0 | Z | Identity (I) | Computational basis |\n",
    "| 1 | X | Hadamard (H) | Superposition basis |\n",
    "| 2 | Y | S†H | Y eigenbasis |\n",
    "\n",
    "### Why These Gates?\n",
    "\n",
    "- **Z basis (index 0)**: No rotation needed - just measure directly\n",
    "- **X basis (index 1)**: H rotates X eigenstates to Z eigenstates\n",
    "- **Y basis (index 2)**: S†H rotates Y eigenstates to Z eigenstates\n",
    "\n",
    "### Implementation in QuartumSE\n",
    "\n",
    "From `v0_baseline.py`:\n",
    "```python\n",
    "self.basis_gates = {\n",
    "    0: lambda qc, q: None,           # Z basis (Identity)\n",
    "    1: lambda qc, q: qc.h(q),         # X basis (Hadamard)\n",
    "    2: lambda qc, q: [qc.sdg(q), qc.h(q)],  # Y basis (S†H)\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step1-impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual implementation of random basis selection\n",
    "NUM_SHADOWS = 10  # Small number for demonstration\n",
    "NUM_QUBITS = 2\n",
    "\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "# Sample random bases: 0=Z, 1=X, 2=Y\n",
    "measurement_bases = rng.integers(0, 3, size=(NUM_SHADOWS, NUM_QUBITS))\n",
    "\n",
    "print(\"Random Measurement Bases (0=Z, 1=X, 2=Y):\")\n",
    "print(\"=\" * 50)\n",
    "basis_names = {0: 'Z', 1: 'X', 2: 'Y'}\n",
    "\n",
    "for shadow_idx in range(NUM_SHADOWS):\n",
    "    bases = measurement_bases[shadow_idx]\n",
    "    basis_str = \"\".join(basis_names[b] for b in bases)\n",
    "    print(f\"Shadow {shadow_idx}: qubit bases = {bases} -> measuring in {basis_str} basis\")\n",
    "\n",
    "# Count basis distribution\n",
    "print(\"\\nBasis Distribution:\")\n",
    "for basis_idx, basis_name in basis_names.items():\n",
    "    count = (measurement_bases == basis_idx).sum()\n",
    "    pct = 100 * count / measurement_bases.size\n",
    "    print(f\"  {basis_name}: {count} times ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\nNote: With uniform random sampling, each basis appears ~33% of the time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Generate Measurement Circuits\n",
    "\n",
    "For each shadow, we:\n",
    "1. Copy the state preparation circuit\n",
    "2. Add rotation gates based on the selected bases\n",
    "3. Add measurements\n",
    "\n",
    "### The Gate Mapping\n",
    "\n",
    "```\n",
    "If basis == 0 (Z): Do nothing\n",
    "If basis == 1 (X): Apply H\n",
    "If basis == 2 (Y): Apply S†, then H\n",
    "```\n",
    "\n",
    "### Why This Works\n",
    "\n",
    "- To measure in X basis: $H|+\\rangle = |0\\rangle$, $H|-\\rangle = |1\\rangle$\n",
    "- To measure in Y basis: $HS^\\dagger|+i\\rangle = |0\\rangle$, $HS^\\dagger|-i\\rangle = |1\\rangle$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step2-impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_basis_rotation(qc: QuantumCircuit, qubit: int, basis: int) -> None:\n",
    "    \"\"\"\n",
    "    Apply rotation to measure in the specified basis.\n",
    "    \n",
    "    basis=0 (Z): No rotation\n",
    "    basis=1 (X): Apply H\n",
    "    basis=2 (Y): Apply S†, then H\n",
    "    \"\"\"\n",
    "    if basis == 0:  # Z basis\n",
    "        pass  # No rotation needed\n",
    "    elif basis == 1:  # X basis\n",
    "        qc.h(qubit)\n",
    "    elif basis == 2:  # Y basis\n",
    "        qc.sdg(qubit)  # S-dagger\n",
    "        qc.h(qubit)\n",
    "\n",
    "\n",
    "def generate_shadow_circuit(base_circuit: QuantumCircuit, bases: np.ndarray) -> QuantumCircuit:\n",
    "    \"\"\"\n",
    "    Generate a single shadow measurement circuit.\n",
    "    \n",
    "    Args:\n",
    "        base_circuit: State preparation circuit\n",
    "        bases: Array of basis indices for each qubit\n",
    "    \n",
    "    Returns:\n",
    "        Circuit with rotations and measurements\n",
    "    \"\"\"\n",
    "    qc = base_circuit.copy()\n",
    "    \n",
    "    # Apply basis rotations\n",
    "    for qubit_idx, basis in enumerate(bases):\n",
    "        apply_basis_rotation(qc, qubit_idx, basis)\n",
    "    \n",
    "    # Add measurements\n",
    "    qc.measure_all()\n",
    "    \n",
    "    return qc\n",
    "\n",
    "\n",
    "# Generate circuits for our shadows\n",
    "shadow_circuits = []\n",
    "for shadow_idx in range(NUM_SHADOWS):\n",
    "    bases = measurement_bases[shadow_idx]\n",
    "    circuit = generate_shadow_circuit(bell_circuit, bases)\n",
    "    shadow_circuits.append(circuit)\n",
    "\n",
    "print(f\"Generated {len(shadow_circuits)} shadow circuits\")\n",
    "\n",
    "# Show a few example circuits\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Example Shadow Circuits:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i in [0, 1, 2]:\n",
    "    bases = measurement_bases[i]\n",
    "    basis_str = \"\".join(basis_names[b] for b in bases)\n",
    "    print(f\"\\nShadow {i} - Measuring in {basis_str} basis:\")\n",
    "    print(shadow_circuits[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Execute Circuits and Collect Measurements\n",
    "\n",
    "Now we run each circuit **once** (single shot per circuit) and record the outcome.\n",
    "\n",
    "### Why Single Shot Per Circuit?\n",
    "\n",
    "Each shadow is an independent random measurement. Running with `shots=1` gives us:\n",
    "- One bitstring outcome per shadow\n",
    "- Maximum information diversity across different measurement bases\n",
    "\n",
    "### The Data We Collect\n",
    "\n",
    "For each shadow $i$:\n",
    "- `measurement_bases[i]`: Which basis was measured for each qubit\n",
    "- `measurement_outcomes[i]`: The binary outcome (0 or 1) for each qubit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step3-impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute circuits\n",
    "backend = AerSimulator(seed_simulator=RANDOM_SEED)\n",
    "\n",
    "# Transpile circuits\n",
    "transpiled_circuits = transpile(shadow_circuits, backend=backend)\n",
    "\n",
    "# Run with shots=1 per circuit\n",
    "job = backend.run(transpiled_circuits, shots=1)\n",
    "result = job.result()\n",
    "\n",
    "# Extract measurement outcomes\n",
    "measurement_outcomes = []\n",
    "\n",
    "for circuit_idx in range(NUM_SHADOWS):\n",
    "    counts = result.get_counts(circuit_idx)\n",
    "    # Get the single bitstring outcome\n",
    "    bitstring = list(counts.keys())[0].replace(\" \", \"\")\n",
    "    # Convert to array (note: Qiskit bitstrings are reversed)\n",
    "    outcomes = np.array([int(b) for b in bitstring[::-1]], dtype=int)\n",
    "    measurement_outcomes.append(outcomes)\n",
    "\n",
    "measurement_outcomes = np.array(measurement_outcomes)\n",
    "\n",
    "print(\"Measurement Results:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Shadow':<8} {'Bases':<10} {'Basis Names':<12} {'Outcomes':<10} {'Bitstring'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i in range(NUM_SHADOWS):\n",
    "    bases = measurement_bases[i]\n",
    "    outcomes = measurement_outcomes[i]\n",
    "    basis_str = \"\".join(basis_names[b] for b in bases)\n",
    "    bitstring = \"\".join(str(b) for b in outcomes)\n",
    "    print(f\"{i:<8} {str(bases):<10} {basis_str:<12} {str(outcomes):<10} |{bitstring}>\")\n",
    "\n",
    "print(\"\\nData shapes:\")\n",
    "print(f\"  measurement_bases: {measurement_bases.shape}\")\n",
    "print(f\"  measurement_outcomes: {measurement_outcomes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: The Inverse Channel (Shadow Reconstruction)\n",
    "\n",
    "This is the **key mathematical step** that makes classical shadows work.\n",
    "\n",
    "### The Problem\n",
    "\n",
    "When we measure in a random basis and get outcome $|b\\rangle$, we have:\n",
    "$$\\text{measured state} = U^\\dagger |b\\rangle\\langle b| U$$\n",
    "\n",
    "But this is **biased** - averaging these directly doesn't give us $\\rho$.\n",
    "\n",
    "### The Solution: Inverse Channel\n",
    "\n",
    "Apply a correction factor to \"undo\" the bias:\n",
    "\n",
    "For a **single qubit** with outcome $b \\in \\{0, 1\\}$:\n",
    "$$\\hat{\\rho}_q = 3|b\\rangle\\langle b| - I$$\n",
    "\n",
    "In matrix form:\n",
    "- If outcome = 0: $\\hat{\\rho} = 3\\begin{pmatrix}1&0\\\\0&0\\end{pmatrix} - I = \\begin{pmatrix}2&0\\\\0&-1\\end{pmatrix}$\n",
    "- If outcome = 1: $\\hat{\\rho} = 3\\begin{pmatrix}0&0\\\\0&1\\end{pmatrix} - I = \\begin{pmatrix}-1&0\\\\0&2\\end{pmatrix}$\n",
    "\n",
    "### Why Factor of 3?\n",
    "\n",
    "The factor of 3 comes from inverting the \"measurement channel\":\n",
    "- With 3 equally likely bases (X, Y, Z), the average measurement projects onto $\\frac{1}{3}$ of the information\n",
    "- Multiplying by 3 corrects for this\n",
    "\n",
    "### For Multiple Qubits\n",
    "\n",
    "The full snapshot is a tensor product:\n",
    "$$\\hat{\\rho} = \\bigotimes_{q=1}^{n} (3|b_q\\rangle\\langle b_q| - I)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step4-impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the inverse channel matrices\n",
    "def inverse_channel_single_qubit(outcome: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the inverse channel snapshot for a single qubit.\n",
    "    \n",
    "    Formula: rho_hat = 3|b><b| - I\n",
    "    \n",
    "    Args:\n",
    "        outcome: 0 or 1\n",
    "    \n",
    "    Returns:\n",
    "        2x2 matrix representing the snapshot\n",
    "    \"\"\"\n",
    "    if outcome == 0:\n",
    "        ket_b = np.array([[1], [0]])  # |0>\n",
    "    else:\n",
    "        ket_b = np.array([[0], [1]])  # |1>\n",
    "    \n",
    "    # |b><b|\n",
    "    proj_b = ket_b @ ket_b.T\n",
    "    \n",
    "    # 3|b><b| - I\n",
    "    snapshot = 3 * proj_b - np.eye(2)\n",
    "    \n",
    "    return snapshot\n",
    "\n",
    "\n",
    "# Demonstrate the inverse channel\n",
    "print(\"Inverse Channel Matrices:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nOutcome = 0:\")\n",
    "print(\"  rho_hat = 3|0><0| - I =\")\n",
    "print(inverse_channel_single_qubit(0))\n",
    "\n",
    "print(\"\\nOutcome = 1:\")\n",
    "print(\"  rho_hat = 3|1><1| - I =\")\n",
    "print(inverse_channel_single_qubit(1))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Verification: Average of snapshots equals maximally mixed state\")\n",
    "print(\"=\"*50)\n",
    "avg_snapshot = 0.5 * inverse_channel_single_qubit(0) + 0.5 * inverse_channel_single_qubit(1)\n",
    "print(\"\\nE[rho_hat] for uniform outcomes:\")\n",
    "print(avg_snapshot)\n",
    "print(\"\\nThis equals I/2 (maximally mixed), which is correct for a random qubit!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Observable Estimation (The Core Algorithm)\n",
    "\n",
    "Now comes the key part: estimating expectation values from our shadow data.\n",
    "\n",
    "### The Estimator Formula\n",
    "\n",
    "For a Pauli observable $P = P_{q_1} \\otimes P_{q_2} \\otimes \\ldots$ (where each $P_q \\in \\{I, X, Y, Z\\}$):\n",
    "\n",
    "$$\\langle P \\rangle \\approx \\frac{1}{M} \\sum_{i=1}^{M} \\text{Tr}(P \\cdot \\hat{\\rho}_i)$$\n",
    "\n",
    "### The Clever Trick\n",
    "\n",
    "For **random local Clifford** shadows, we don't need to compute full density matrices!\n",
    "\n",
    "For each shadow $i$ and observable $P$:\n",
    "\n",
    "1. **Check compatibility**: Did we measure in the right basis for each non-identity Pauli?\n",
    "   - If $P_q = Z$, we need to have measured qubit $q$ in Z basis\n",
    "   - If $P_q = X$, we need to have measured qubit $q$ in X basis\n",
    "   - If $P_q = Y$, we need to have measured qubit $q$ in Y basis\n",
    "\n",
    "2. **If compatible**: Compute $3^k \\times \\prod_{q \\in \\text{support}} (-1)^{b_q}$\n",
    "   - $k$ = number of non-identity Paulis (the \"support size\")\n",
    "   - $b_q$ = measurement outcome for qubit $q$\n",
    "   - The $3^k$ factor comes from the inverse channel!\n",
    "\n",
    "3. **If incompatible**: This shadow contributes 0 to the estimate\n",
    "\n",
    "### Why This Works\n",
    "\n",
    "- Pauli operators are eigenstates of the corresponding measurement basis\n",
    "- $\\text{Tr}(Z \\cdot (3|b\\rangle\\langle b| - I)) = 3(1-2b) - 0 = 3 \\times (\\pm 1)$\n",
    "- The trace over non-matching bases gives 0 (orthogonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step5-impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pauli_single_shadow(\n",
    "    shadow_idx: int,\n",
    "    pauli_string: str,\n",
    "    measurement_bases: np.ndarray,\n",
    "    measurement_outcomes: np.ndarray,\n",
    "    verbose: bool = False\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Estimate Pauli expectation value from a single shadow.\n",
    "    \n",
    "    This implements the core classical shadows estimator.\n",
    "    \n",
    "    Args:\n",
    "        shadow_idx: Index of the shadow\n",
    "        pauli_string: e.g., \"ZI\", \"XX\", \"YY\"\n",
    "        measurement_bases: Array of shape (num_shadows, num_qubits)\n",
    "        measurement_outcomes: Array of shape (num_shadows, num_qubits)\n",
    "        verbose: Print detailed computation steps\n",
    "    \n",
    "    Returns:\n",
    "        Contribution from this shadow (may be 0 if incompatible)\n",
    "    \"\"\"\n",
    "    # Map Pauli characters to required basis indices\n",
    "    pauli_to_basis = {'X': 1, 'Y': 2, 'Z': 0, 'I': None}\n",
    "    \n",
    "    bases = measurement_bases[shadow_idx]\n",
    "    outcomes = measurement_outcomes[shadow_idx]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  Shadow {shadow_idx}: bases={bases}, outcomes={outcomes}\")\n",
    "    \n",
    "    expectation = 1.0\n",
    "    support_size = 0  # Count non-identity Paulis\n",
    "    \n",
    "    for qubit_idx, pauli in enumerate(pauli_string):\n",
    "        if pauli == 'I':\n",
    "            continue  # Identity doesn't affect the result\n",
    "        \n",
    "        support_size += 1\n",
    "        required_basis = pauli_to_basis[pauli]\n",
    "        measured_basis = bases[qubit_idx]\n",
    "        outcome = outcomes[qubit_idx]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"    Qubit {qubit_idx}: Pauli={pauli}, need basis={required_basis}, got basis={measured_basis}\")\n",
    "        \n",
    "        if measured_basis != required_basis:\n",
    "            if verbose:\n",
    "                print(f\"    -> INCOMPATIBLE! Returning 0\")\n",
    "            return 0.0  # Incompatible measurement\n",
    "        \n",
    "        # Compatible: multiply by sign based on outcome\n",
    "        # outcome=0 -> +1, outcome=1 -> -1\n",
    "        sign = 1 - 2 * outcome\n",
    "        expectation *= sign\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"    -> outcome={outcome}, sign={sign:+d}\")\n",
    "    \n",
    "    # Apply the 3^k scaling factor from the inverse channel\n",
    "    scaling_factor = 3 ** support_size\n",
    "    result = scaling_factor * expectation\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  -> support_size={support_size}, scaling=3^{support_size}={scaling_factor}, result={result:+.0f}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Demonstrate with a specific example\n",
    "print(\"Detailed Estimation Example:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nEstimating <ZZ> (expect +1 for Bell state):\")\n",
    "print()\n",
    "\n",
    "for shadow_idx in range(min(5, NUM_SHADOWS)):\n",
    "    result = estimate_pauli_single_shadow(\n",
    "        shadow_idx, \"ZZ\", measurement_bases, measurement_outcomes, verbose=True\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step5-full",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_observable_from_shadows(\n",
    "    pauli_string: str,\n",
    "    measurement_bases: np.ndarray,\n",
    "    measurement_outcomes: np.ndarray,\n",
    "    coefficient: float = 1.0\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Estimate observable using all shadow data.\n",
    "    \n",
    "    Returns:\n",
    "        dict with expectation, variance, individual contributions\n",
    "    \"\"\"\n",
    "    num_shadows = len(measurement_outcomes)\n",
    "    \n",
    "    # Compute contribution from each shadow\n",
    "    contributions = []\n",
    "    for i in range(num_shadows):\n",
    "        contrib = estimate_pauli_single_shadow(\n",
    "            i, pauli_string, measurement_bases, measurement_outcomes\n",
    "        )\n",
    "        contributions.append(contrib)\n",
    "    \n",
    "    contributions = np.array(contributions)\n",
    "    \n",
    "    # Mean estimator\n",
    "    expectation = np.mean(contributions) * coefficient\n",
    "    \n",
    "    # Variance\n",
    "    variance = np.var(contributions)\n",
    "    \n",
    "    # Count compatible shadows\n",
    "    compatible_count = np.sum(contributions != 0)\n",
    "    \n",
    "    return {\n",
    "        'expectation': expectation,\n",
    "        'variance': variance,\n",
    "        'std_error': np.sqrt(variance / num_shadows),\n",
    "        'contributions': contributions,\n",
    "        'compatible_shadows': compatible_count,\n",
    "        'compatibility_rate': compatible_count / num_shadows,\n",
    "    }\n",
    "\n",
    "\n",
    "# Estimate all our target observables\n",
    "print(\"Observable Estimation Results (Manual Implementation):\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Observable':<12} {'Estimated':<12} {'Expected':<10} {'Error':<10} {'Compatible':<12} {'Contrib Dist'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for obs_str, expected in GROUND_TRUTH.items():\n",
    "    result = estimate_observable_from_shadows(\n",
    "        obs_str, measurement_bases, measurement_outcomes\n",
    "    )\n",
    "    est = result['expectation']\n",
    "    err = abs(est - expected)\n",
    "    compat = result['compatible_shadows']\n",
    "    compat_pct = 100 * result['compatibility_rate']\n",
    "    \n",
    "    # Show distribution of contributions\n",
    "    contribs = result['contributions']\n",
    "    nonzero = contribs[contribs != 0]\n",
    "    if len(nonzero) > 0:\n",
    "        contrib_str = f\"mean={np.mean(nonzero):+.1f}\"\n",
    "    else:\n",
    "        contrib_str = \"all zero\"\n",
    "    \n",
    "    print(f\"{obs_str:<12} {est:>+10.4f}   {expected:>+8.1f}   {err:>8.4f}   {compat}/{NUM_SHADOWS} ({compat_pct:4.1f}%)  {contrib_str}\")\n",
    "\n",
    "print(\"\\nNote: With only 10 shadows, estimates may be noisy. More shadows = better precision.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step6-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Confidence Intervals and Variance Bounds\n",
    "\n",
    "### Theoretical Variance Bound\n",
    "\n",
    "For random local Clifford shadows, the variance of the estimator is bounded by:\n",
    "\n",
    "$$\\text{Var}[\\hat{o}] \\leq \\frac{4^k}{M}$$\n",
    "\n",
    "where:\n",
    "- $k$ = support size (number of non-identity Paulis)\n",
    "- $M$ = number of shadows\n",
    "\n",
    "### Why $4^k$?\n",
    "\n",
    "- Each non-identity Pauli can contribute $\\pm 3$ when compatible\n",
    "- The probability of being compatible is $1/3$ per qubit\n",
    "- The variance of a single shadow's contribution is $O(9^k \\cdot (1/3)^k) = O(3^k)$\n",
    "- The theoretical bound is $4^k$ (slightly looser for simplicity)\n",
    "\n",
    "### Confidence Intervals\n",
    "\n",
    "Using the normal approximation (valid for large M):\n",
    "\n",
    "$$\\text{CI}_{95\\%} = \\bar{o} \\pm 1.96 \\cdot \\frac{\\sigma}{\\sqrt{M}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step6-impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def compute_confidence_interval(\n",
    "    mean: float,\n",
    "    variance: float,\n",
    "    n_samples: int,\n",
    "    confidence: float = 0.95\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Compute confidence interval using normal approximation.\n",
    "    \"\"\"\n",
    "    std_error = np.sqrt(variance / n_samples)\n",
    "    z_score = stats.norm.ppf((1 + confidence) / 2)\n",
    "    \n",
    "    ci_lower = mean - z_score * std_error\n",
    "    ci_upper = mean + z_score * std_error\n",
    "    \n",
    "    return (ci_lower, ci_upper)\n",
    "\n",
    "\n",
    "def variance_bound(pauli_string: str, shadow_size: int) -> float:\n",
    "    \"\"\"\n",
    "    Compute theoretical variance bound for a Pauli observable.\n",
    "    \n",
    "    Var <= 4^k / M, where k is the support size.\n",
    "    \"\"\"\n",
    "    support_size = sum(1 for p in pauli_string if p != 'I')\n",
    "    return (4 ** support_size) / shadow_size\n",
    "\n",
    "\n",
    "print(\"Confidence Intervals and Variance Analysis:\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"{'Observable':<12} {'Support':<8} {'Var Bound':<12} {'Actual Var':<12} {'95% CI':<25} {'Contains Truth?'}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for obs_str, expected in GROUND_TRUTH.items():\n",
    "    result = estimate_observable_from_shadows(\n",
    "        obs_str, measurement_bases, measurement_outcomes\n",
    "    )\n",
    "    \n",
    "    support = sum(1 for p in obs_str if p != 'I')\n",
    "    var_bound = variance_bound(obs_str, NUM_SHADOWS)\n",
    "    actual_var = result['variance']\n",
    "    \n",
    "    ci = compute_confidence_interval(\n",
    "        result['expectation'], actual_var, NUM_SHADOWS\n",
    "    )\n",
    "    \n",
    "    contains_truth = ci[0] <= expected <= ci[1]\n",
    "    \n",
    "    ci_str = f\"[{ci[0]:>+6.2f}, {ci[1]:>+6.2f}]\"\n",
    "    \n",
    "    print(f\"{obs_str:<12} {support:<8} {var_bound:<12.2f} {actual_var:<12.2f} {ci_str:<25} {'Yes' if contains_truth else 'No'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"Key Insight: Variance scales as 4^k, so observables with larger support are harder to estimate.\")\n",
    "print(\"More shadows are needed for high-weight observables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scale-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Scaling Up - More Shadows for Better Precision\n",
    "\n",
    "Let's see how estimation improves with more shadows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scale-impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with more shadows using the QuartumSE implementation\n",
    "SHADOW_SIZES = [10, 50, 100, 500, 1000]\n",
    "\n",
    "results_by_size = {}\n",
    "\n",
    "for shadow_size in SHADOW_SIZES:\n",
    "    # Configure shadows\n",
    "    config = ShadowConfig(\n",
    "        version=ShadowVersion.V0_BASELINE,\n",
    "        shadow_size=shadow_size,\n",
    "        random_seed=RANDOM_SEED,\n",
    "        confidence_level=0.95,\n",
    "    )\n",
    "    \n",
    "    # Create shadow implementation\n",
    "    shadow_impl = RandomLocalCliffordShadows(config)\n",
    "    \n",
    "    # Generate circuits\n",
    "    circuits = shadow_impl.generate_measurement_circuits(bell_circuit, shadow_size)\n",
    "    \n",
    "    # Execute\n",
    "    transpiled = transpile(circuits, backend=backend)\n",
    "    job = backend.run(transpiled, shots=1)\n",
    "    result = job.result()\n",
    "    \n",
    "    # Extract outcomes\n",
    "    outcomes_list = []\n",
    "    for i in range(shadow_size):\n",
    "        counts = result.get_counts(i)\n",
    "        bitstring = list(counts.keys())[0].replace(\" \", \"\")\n",
    "        outcomes = np.array([int(b) for b in bitstring[::-1]], dtype=int)\n",
    "        outcomes_list.append(outcomes)\n",
    "    \n",
    "    measurement_outcomes_scaled = np.array(outcomes_list)\n",
    "    \n",
    "    # Reconstruct\n",
    "    shadow_impl.reconstruct_classical_shadow(\n",
    "        measurement_outcomes_scaled, shadow_impl.measurement_bases\n",
    "    )\n",
    "    \n",
    "    # Estimate observables\n",
    "    estimates = {}\n",
    "    for obs_str in GROUND_TRUTH.keys():\n",
    "        obs = Observable(obs_str, coefficient=1.0)\n",
    "        est = shadow_impl.estimate_observable(obs)\n",
    "        estimates[obs_str] = {\n",
    "            'value': est.expectation_value,\n",
    "            'ci': est.confidence_interval,\n",
    "            'ci_width': est.ci_width,\n",
    "        }\n",
    "    \n",
    "    results_by_size[shadow_size] = estimates\n",
    "\n",
    "print(\"Estimation Precision vs Shadow Size:\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scale-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scaling\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Error vs shadow size\n",
    "for obs_str, expected in GROUND_TRUTH.items():\n",
    "    errors = [abs(results_by_size[s][obs_str]['value'] - expected) for s in SHADOW_SIZES]\n",
    "    axes[0].plot(SHADOW_SIZES, errors, 'o-', label=obs_str, markersize=8)\n",
    "\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xlabel('Shadow Size (M)', fontsize=12)\n",
    "axes[0].set_ylabel('Absolute Error', fontsize=12)\n",
    "axes[0].set_title('Estimation Error vs Shadow Size', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add theoretical 1/sqrt(M) line\n",
    "theoretical_scaling = [1/np.sqrt(s) for s in SHADOW_SIZES]\n",
    "axes[0].plot(SHADOW_SIZES, theoretical_scaling, 'k--', alpha=0.5, label='1/sqrt(M)')\n",
    "\n",
    "# Right: CI width vs shadow size\n",
    "for obs_str in GROUND_TRUTH.keys():\n",
    "    ci_widths = [results_by_size[s][obs_str]['ci_width'] for s in SHADOW_SIZES]\n",
    "    axes[1].plot(SHADOW_SIZES, ci_widths, 'o-', label=obs_str, markersize=8)\n",
    "\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xlabel('Shadow Size (M)', fontsize=12)\n",
    "axes[1].set_ylabel('95% CI Width', fontsize=12)\n",
    "axes[1].set_title('Confidence Interval Width vs Shadow Size', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observations:\")\n",
    "print(\"- Error decreases roughly as 1/sqrt(M) (standard deviation scaling)\")\n",
    "print(\"- CI width shrinks with more shadows\")\n",
    "print(\"- Higher-weight observables (like YY) may have more variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v1-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus: Noise-Aware Shadows (v1) with MEM\n",
    "\n",
    "On real hardware, measurement errors corrupt our outcomes. The v1 implementation adds **Measurement Error Mitigation (MEM)**.\n",
    "\n",
    "### How MEM Works\n",
    "\n",
    "1. **Calibration**: Prepare all $2^n$ computational basis states, measure each many times\n",
    "2. **Build Confusion Matrix**: $A_{ij}$ = probability of measuring state $i$ when state $j$ was prepared\n",
    "3. **Correction**: For each shadow, apply $A^{-1}$ to correct the measurement distribution\n",
    "\n",
    "### In QuartumSE\n",
    "\n",
    "The `NoiseAwareRandomLocalCliffordShadows` class:\n",
    "1. Inherits from `RandomLocalCliffordShadows`\n",
    "2. Takes a `MeasurementErrorMitigation` instance\n",
    "3. Overrides `reconstruct_classical_shadow` to apply MEM correction\n",
    "4. Overrides `_pauli_expectation_single_shadow` to use corrected distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v1-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate MEM calibration (on ideal simulator, matrix should be ~identity)\n",
    "from quartumse.mitigation import MeasurementErrorMitigation\n",
    "\n",
    "# Create MEM instance\n",
    "mem = MeasurementErrorMitigation(backend)\n",
    "\n",
    "# Calibrate for 2 qubits\n",
    "mem.calibrate(qubits=[0, 1], shots=1024)\n",
    "\n",
    "print(\"Measurement Error Mitigation Calibration:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nConfusion Matrix (rows=measured, cols=prepared):\")\n",
    "print(\"States: |00>, |01>, |10>, |11>\")\n",
    "print()\n",
    "print(np.round(mem.confusion_matrix, 4))\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Diagonal elements = probability of correct measurement\")\n",
    "print(\"- Off-diagonal = probability of measurement errors\")\n",
    "print(\"- On ideal simulator, this should be ~identity matrix\")\n",
    "\n",
    "# Check if close to identity\n",
    "is_ideal = np.allclose(mem.confusion_matrix, np.eye(4), atol=0.05)\n",
    "print(f\"\\nClose to identity: {is_ideal} (expected on noiseless simulator)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v1-workflow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the v1 workflow\n",
    "from quartumse.shadows.v1_noise_aware import NoiseAwareRandomLocalCliffordShadows\n",
    "\n",
    "# Configure v1 shadows\n",
    "config_v1 = ShadowConfig(\n",
    "    version=ShadowVersion.V1_NOISE_AWARE,\n",
    "    shadow_size=100,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    apply_inverse_channel=True,\n",
    ")\n",
    "\n",
    "# Create v1 implementation with MEM\n",
    "shadow_v1 = NoiseAwareRandomLocalCliffordShadows(config_v1, mem)\n",
    "\n",
    "# Generate circuits\n",
    "circuits_v1 = shadow_v1.generate_measurement_circuits(bell_circuit, 100)\n",
    "\n",
    "# Execute\n",
    "transpiled_v1 = transpile(circuits_v1, backend=backend)\n",
    "job_v1 = backend.run(transpiled_v1, shots=1)\n",
    "result_v1 = job_v1.result()\n",
    "\n",
    "# Extract outcomes\n",
    "outcomes_v1 = []\n",
    "for i in range(100):\n",
    "    counts = result_v1.get_counts(i)\n",
    "    bitstring = list(counts.keys())[0].replace(\" \", \"\")\n",
    "    outcomes = np.array([int(b) for b in bitstring[::-1]], dtype=int)\n",
    "    outcomes_v1.append(outcomes)\n",
    "\n",
    "outcomes_v1 = np.array(outcomes_v1)\n",
    "\n",
    "# Reconstruct (this applies MEM correction internally)\n",
    "shadow_v1.reconstruct_classical_shadow(outcomes_v1, shadow_v1.measurement_bases)\n",
    "\n",
    "print(\"Noise-Aware Shadows (v1) Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Observable':<12} {'v1 Estimate':<15} {'Expected':<10} {'Error'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for obs_str, expected in GROUND_TRUTH.items():\n",
    "    obs = Observable(obs_str, coefficient=1.0)\n",
    "    est = shadow_v1.estimate_observable(obs)\n",
    "    err = abs(est.expectation_value - expected)\n",
    "    print(f\"{obs_str:<12} {est.expectation_value:>+12.4f}   {expected:>+8.1f}   {err:.4f}\")\n",
    "\n",
    "print(\"\\nNote: On ideal simulator, v0 and v1 should give similar results.\")\n",
    "print(\"On real hardware with noise, v1 should show improved accuracy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architecture-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## QuartumSE Architecture Summary\n",
    "\n",
    "### Class Hierarchy\n",
    "\n",
    "```\n",
    "ClassicalShadows (ABC)              # Abstract base class\n",
    "├── generate_measurement_circuits() # Step 1-2: Basis selection + circuit generation\n",
    "├── reconstruct_classical_shadow()  # Step 4: Inverse channel\n",
    "├── estimate_observable()           # Step 5: Expectation estimation\n",
    "└── compute_variance_bound()        # Step 6: Theoretical bounds\n",
    "\n",
    "RandomLocalCliffordShadows          # v0 baseline implementation\n",
    "├── basis_gates: {0: Z, 1: X, 2: Y} # Gate mapping\n",
    "├── inverse_channel: 3|b><b| - I    # Reconstruction formula\n",
    "└── _pauli_expectation_single_shadow() # Core estimator\n",
    "\n",
    "NoiseAwareRandomLocalCliffordShadows # v1 with MEM\n",
    "├── mem: MeasurementErrorMitigation # Confusion matrix correction\n",
    "├── noise_corrected_distributions   # Corrected probability distributions\n",
    "└── _pauli_expectation_single_shadow() # Uses corrected distributions\n",
    "```\n",
    "\n",
    "### Data Flow\n",
    "\n",
    "```\n",
    "State Preparation Circuit\n",
    "         ↓\n",
    "generate_measurement_circuits(circuit, num_shadows)\n",
    "         ↓\n",
    "[Circuit with random rotations + measurements] × num_shadows\n",
    "         ↓\n",
    "Backend Execution (shots=1 per circuit)\n",
    "         ↓\n",
    "measurement_outcomes: (num_shadows, num_qubits)\n",
    "measurement_bases: (num_shadows, num_qubits)\n",
    "         ↓\n",
    "reconstruct_classical_shadow(outcomes, bases)\n",
    "         ↓\n",
    "[Shadow snapshots stored internally]\n",
    "         ↓\n",
    "estimate_observable(observable) × num_observables\n",
    "         ↓\n",
    "ShadowEstimate(expectation, variance, CI, ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: The 6 Steps of Classical Shadows\n",
    "\n",
    "| Step | What Happens | Key Formula |\n",
    "|------|--------------|-------------|\n",
    "| **1. Basis Selection** | Sample random basis per qubit | $b_q \\sim \\text{Uniform}(X, Y, Z)$ |\n",
    "| **2. Circuit Generation** | Add rotation gates + measurements | $H$ for X, $S^\\dagger H$ for Y |\n",
    "| **3. Execution** | Run circuits, collect outcomes | 1 shot per shadow |\n",
    "| **4. Inverse Channel** | Apply correction factor | $\\hat{\\rho}_q = 3\\|b_q\\rangle\\langle b_q\\| - I$ |\n",
    "| **5. Estimation** | Average compatible shadows | $\\hat{o} = \\frac{1}{M}\\sum_i 3^k \\cdot \\text{sign}$ |\n",
    "| **6. Confidence** | Compute variance and CI | $\\text{Var} \\leq 4^k / M$ |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Random Bases**: The randomization is crucial - it distributes information across all observables\n",
    "2. **Inverse Channel**: The $3^k$ factor corrects for the \"dilution\" from random measurement\n",
    "3. **Compatibility**: Only shadows measured in the right basis contribute (others give 0)\n",
    "4. **Scaling**: Variance scales as $4^k/M$, so more shadows needed for high-weight observables\n",
    "5. **Noise Mitigation**: v1 adds MEM to correct measurement errors on real hardware\n",
    "\n",
    "---\n",
    "\n",
    "*QuartumSE - Shot-efficient quantum measurement optimization*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
