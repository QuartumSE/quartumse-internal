{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# QuartumSE Benchmark Suite\n",
    "\n",
    "This notebook demonstrates the **unified benchmark suite** API for running publication-grade benchmarks.\n",
    "\n",
    "## The 8 Tasks (Measurements Bible)\n",
    "\n",
    "| Task | Name | Question |\n",
    "|------|------|----------|\n",
    "| 1 | Worst-Case Guarantee | What N* achieves max SE ≤ ε for all observables? |\n",
    "| 2 | Average Target | What N* achieves mean SE ≤ ε? |\n",
    "| 3 | Fixed Budget | What is the SE distribution at fixed N? |\n",
    "| 4 | Dominance | Which protocol wins on more observables? |\n",
    "| 5 | Pilot Selection | How much budget for pilot vs main run? |\n",
    "| 6 | Bias-Variance | How does MSE decompose into bias² + variance? |\n",
    "| 7 | Noise Sensitivity | How does performance degrade with noise? |\n",
    "| 8 | Adaptive Efficiency | Can we reallocate budget based on pilot? |\n",
    "\n",
    "## Benchmark Modes\n",
    "\n",
    "| Mode | What it runs | Use case |\n",
    "|------|--------------|----------|\n",
    "| `basic` | Tasks 1, 3, 6 + basic report | Quick sanity check |\n",
    "| `complete` | All 8 tasks + complete report | Publication benchmark |\n",
    "| `analysis` | Complete + enhanced analysis | Deep dive with statistics |\n",
    "\n",
    "All results are saved with **unique timestamped directories** - no overwrites!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup ---\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "\n",
    "from quartumse import (\n",
    "    run_benchmark_suite,\n",
    "    BenchmarkMode,\n",
    "    BenchmarkSuiteConfig,\n",
    "    generate_observable_set,\n",
    "    Observable,\n",
    "    ObservableSet,\n",
    ")\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Define Circuit and Observables\n",
    "\n",
    "You can use **any Qiskit circuit** and **any set of observables**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Circuit ---\n",
    "N_QUBITS = 4\n",
    "\n",
    "def build_ghz(n_qubits: int) -> QuantumCircuit:\n",
    "    \"\"\"Build GHZ state preparation circuit.\"\"\"\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "    qc.h(0)\n",
    "    for i in range(1, n_qubits):\n",
    "        qc.cx(i - 1, i)\n",
    "    return qc\n",
    "\n",
    "circuit = build_ghz(N_QUBITS)\n",
    "print(circuit.draw('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "observables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Observables ---\n",
    "# Generate random observables with mixed localities\n",
    "observables = []\n",
    "for k in range(1, N_QUBITS + 1):\n",
    "    obs_set = generate_observable_set(\n",
    "        generator_id='random_pauli',\n",
    "        n_qubits=N_QUBITS,\n",
    "        n_observables=5,\n",
    "        seed=42 + k,\n",
    "        weight_distribution='fixed',\n",
    "        fixed_weight=k,\n",
    "    )\n",
    "    observables.extend(list(obs_set.observables))\n",
    "\n",
    "# Add GHZ stabilizers\n",
    "observables.extend([\n",
    "    Observable('Z' * N_QUBITS),\n",
    "    Observable('X' * N_QUBITS),\n",
    "])\n",
    "\n",
    "obs_set = ObservableSet(\n",
    "    observables=observables,\n",
    "    observable_set_id='benchmark_observables',\n",
    "    generator_id='mixed',\n",
    "    generator_seed=42,\n",
    ")\n",
    "\n",
    "# Build locality map for analysis mode\n",
    "locality_map = {}\n",
    "for obs in observables:\n",
    "    locality = sum(1 for c in obs.pauli_string if c != 'I')\n",
    "    locality_map[obs.observable_id] = locality\n",
    "\n",
    "print(f\"Generated {len(obs_set)} observables\")\n",
    "from collections import Counter\n",
    "loc_counts = Counter(locality_map.values())\n",
    "for k in sorted(loc_counts.keys()):\n",
    "    print(f\"  K={k}: {loc_counts[k]} observables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Basic Benchmark\n",
    "\n",
    "Quick sanity check with Tasks 1, 3, 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# --- Basic Benchmark ---\n",
    "config = BenchmarkSuiteConfig(\n",
    "    mode=BenchmarkMode.BASIC,\n",
    "    n_shots_grid=[100, 500, 1000],\n",
    "    n_replicates=5,  # Fewer for quick test\n",
    "    seed=42,\n",
    "    output_base_dir=\"benchmark_results\",\n",
    ")\n",
    "\n",
    "result = run_benchmark_suite(\n",
    "    circuit=circuit,\n",
    "    observable_set=obs_set,\n",
    "    circuit_id=\"ghz_4q\",\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- View Basic Results ---\n",
    "print(f\"Run ID: {result.run_id}\")\n",
    "print(f\"Output: {result.output_dir}\")\n",
    "print(f\"Reports: {list(result.reports.keys())}\")\n",
    "print()\n",
    "print(\"Protocol summaries:\")\n",
    "for protocol, stats in result.summary.get('protocol_summaries', {}).items():\n",
    "    print(f\"  {protocol}: mean_se={stats.get('mean_se', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Complete Benchmark (All 8 Tasks)\n",
    "\n",
    "Publication-grade benchmark with all tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# --- Complete Benchmark ---\n",
    "config = BenchmarkSuiteConfig(\n",
    "    mode=BenchmarkMode.COMPLETE,\n",
    "    n_shots_grid=[100, 500, 1000, 5000],\n",
    "    n_replicates=10,\n",
    "    seed=42,\n",
    "    epsilon=0.01,\n",
    "    delta=0.05,\n",
    "    output_base_dir=\"benchmark_results\",\n",
    ")\n",
    "\n",
    "result = run_benchmark_suite(\n",
    "    circuit=circuit,\n",
    "    observable_set=obs_set,\n",
    "    circuit_id=\"ghz_4q\",\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- View Complete Results ---\n",
    "print(f\"Run ID: {result.run_id}\")\n",
    "print(f\"All tasks completed: {len(result.all_task_results or {})}\")\n",
    "print()\n",
    "if result.all_task_results:\n",
    "    for task_id in sorted(result.all_task_results.keys()):\n",
    "        print(f\"  {task_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Full Analysis Mode\n",
    "\n",
    "Complete benchmark + enhanced analysis:\n",
    "- N* interpolation (power-law fitting)\n",
    "- Per-observable crossover\n",
    "- Locality correlation\n",
    "- Bootstrap hypothesis testing\n",
    "- Cost-normalized metrics\n",
    "- Multi-pilot fraction analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# --- Full Analysis ---\n",
    "config = BenchmarkSuiteConfig(\n",
    "    mode=BenchmarkMode.ANALYSIS,\n",
    "    n_shots_grid=[100, 500, 1000, 5000],\n",
    "    n_replicates=20,\n",
    "    seed=42,\n",
    "    epsilon=0.01,\n",
    "    delta=0.05,\n",
    "    shadows_protocol_id=\"classical_shadows_v0\",\n",
    "    baseline_protocol_id=\"direct_grouped\",\n",
    "    output_base_dir=\"benchmark_results\",\n",
    ")\n",
    "\n",
    "result = run_benchmark_suite(\n",
    "    circuit=circuit,\n",
    "    observable_set=obs_set,\n",
    "    circuit_id=\"ghz_4q\",\n",
    "    config=config,\n",
    "    locality_map=locality_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Analysis Summary ---\n",
    "print(f\"Run ID: {result.run_id}\")\n",
    "print(f\"Output: {result.output_dir}\")\n",
    "print()\n",
    "\n",
    "if result.analysis:\n",
    "    print(\"Analysis Summary:\")\n",
    "    for key, value in result.analysis.summary.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-reports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Display Reports ---\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "print(\"Generated Reports:\")\n",
    "for name, path in result.reports.items():\n",
    "    print(f\"  {name}: {path}\")\n",
    "\n",
    "# Display the analysis report\n",
    "if 'analysis' in result.reports:\n",
    "    report_content = result.reports['analysis'].read_text()\n",
    "    display(Markdown(report_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "custom-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Custom Circuit Example\n",
    "\n",
    "Use any circuit you want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom Circuit Example ---\n",
    "# Example: Random circuit\n",
    "import numpy as np\n",
    "\n",
    "def build_random_circuit(n_qubits: int, depth: int, seed: int = 42) -> QuantumCircuit:\n",
    "    \"\"\"Build a random circuit.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "    \n",
    "    for _ in range(depth):\n",
    "        # Random single-qubit gates\n",
    "        for q in range(n_qubits):\n",
    "            gate = rng.choice(['h', 'x', 'y', 'z', 's', 't'])\n",
    "            getattr(qc, gate)(q)\n",
    "        \n",
    "        # Random CNOTs\n",
    "        for q in range(0, n_qubits - 1, 2):\n",
    "            if rng.random() > 0.5:\n",
    "                qc.cx(q, q + 1)\n",
    "    \n",
    "    return qc\n",
    "\n",
    "custom_circuit = build_random_circuit(4, 3)\n",
    "print(custom_circuit.draw('text'))\n",
    "\n",
    "# You can now run:\n",
    "# result = run_benchmark_suite(custom_circuit, obs_set, circuit_id=\"random_4q_d3\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "The unified benchmark suite provides:\n",
    "\n",
    "1. **Single entry point**: `run_benchmark_suite(circuit, observables)`\n",
    "2. **Three modes**: basic, complete, analysis\n",
    "3. **Automatic timestamped directories**: No overwrites\n",
    "4. **Appropriate reports for each mode**:\n",
    "   - Basic: `basic_report.md`\n",
    "   - Complete: `complete_report.md` (all 8 tasks)\n",
    "   - Analysis: `analysis_report.md` + `analysis.json`\n",
    "\n",
    "All results are fully reproducible with seeded randomness and provenance tracking."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
