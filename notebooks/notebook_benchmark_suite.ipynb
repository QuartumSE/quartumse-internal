{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# QuartumSE Benchmark Suite\n",
    "\n",
    "This notebook benchmarks **classical shadows** against direct measurement baselines for a single circuit.\n",
    "\n",
    "## The 8 Tasks (Measurements Bible)\n",
    "\n",
    "| Task | Question |\n",
    "|------|----------|\n",
    "| 1 | What N* achieves max SE ≤ ε for ALL observables? |\n",
    "| 2 | What N* achieves mean SE ≤ ε? |\n",
    "| 3 | What is the SE distribution at fixed N? |\n",
    "| 4 | Which protocol wins on more observables? |\n",
    "| 5 | What fraction of budget for pilot? |\n",
    "| 6 | How does MSE decompose into bias² + variance? |\n",
    "| 7 | How does performance degrade with noise? |\n",
    "| 8 | Can budget reallocation improve results? |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup ---\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from qiskit import QuantumCircuit\n",
    "\n",
    "from quartumse import (\n",
    "    run_benchmark_suite,\n",
    "    BenchmarkMode,\n",
    "    BenchmarkSuiteConfig,\n",
    "    generate_observable_set,\n",
    "    Observable,\n",
    "    ObservableSet,\n",
    ")\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Circuit Configuration\n",
    "\n",
    "Define the circuit and observables to benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CIRCUIT CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "CIRCUIT_ID = \"ghz_4q\"  # Identifier for this benchmark\n",
    "N_QUBITS = 4\n",
    "\n",
    "# --- Build Circuit ---\n",
    "def build_ghz(n_qubits: int) -> QuantumCircuit:\n",
    "    \"\"\"GHZ state: (|00...0⟩ + |11...1⟩) / sqrt(2)\"\"\"\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "    qc.h(0)\n",
    "    for i in range(1, n_qubits):\n",
    "        qc.cx(i - 1, i)\n",
    "    return qc\n",
    "\n",
    "circuit = build_ghz(N_QUBITS)\n",
    "print(f\"Circuit: {CIRCUIT_ID}\")\n",
    "print(circuit.draw('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "observables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Observables ---\n",
    "observables = []\n",
    "\n",
    "# Random observables with mixed localities\n",
    "for k in range(1, N_QUBITS + 1):\n",
    "    obs_set = generate_observable_set(\n",
    "        generator_id='random_pauli',\n",
    "        n_qubits=N_QUBITS,\n",
    "        n_observables=5,\n",
    "        seed=42 + k,\n",
    "        weight_distribution='fixed',\n",
    "        fixed_weight=k,\n",
    "    )\n",
    "    observables.extend(list(obs_set.observables))\n",
    "\n",
    "# Add GHZ stabilizers\n",
    "observables.extend([\n",
    "    Observable('Z' * N_QUBITS),\n",
    "    Observable('X' * N_QUBITS),\n",
    "])\n",
    "\n",
    "obs_set = ObservableSet(\n",
    "    observables=observables,\n",
    "    observable_set_id=f'{CIRCUIT_ID}_obs',\n",
    "    generator_id='mixed',\n",
    "    generator_seed=42,\n",
    ")\n",
    "\n",
    "# Build locality map\n",
    "locality_map = {}\n",
    "for obs in observables:\n",
    "    locality = sum(1 for c in obs.pauli_string if c != 'I')\n",
    "    locality_map[obs.observable_id] = locality\n",
    "\n",
    "print(f\"Observables: {len(obs_set)}\")\n",
    "loc_counts = Counter(locality_map.values())\n",
    "for k in sorted(loc_counts.keys()):\n",
    "    print(f\"  K={k}: {loc_counts[k]} observables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Benchmark Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BENCHMARK CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "config = BenchmarkSuiteConfig(\n",
    "    mode=BenchmarkMode.ANALYSIS,      # Full analysis with all tasks\n",
    "    n_shots_grid=[100, 500, 1000, 5000],\n",
    "    n_replicates=20,                  # 20 for publication quality\n",
    "    seed=42,\n",
    "    epsilon=0.01,                     # Target precision\n",
    "    delta=0.05,                       # Failure probability\n",
    "    shadows_protocol_id=\"classical_shadows_v0\",\n",
    "    baseline_protocol_id=\"direct_grouped\",\n",
    "    output_base_dir=\"benchmark_results\",\n",
    ")\n",
    "\n",
    "print(\"Benchmark Configuration:\")\n",
    "print(f\"  Mode: {config.mode.value}\")\n",
    "print(f\"  Shot grid: {config.n_shots_grid}\")\n",
    "print(f\"  Replicates: {config.n_replicates}\")\n",
    "print(f\"  Target ε: {config.epsilon}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Run Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# =============================================================================\n",
    "# RUN BENCHMARK\n",
    "# =============================================================================\n",
    "\n",
    "result = run_benchmark_suite(\n",
    "    circuit=circuit,\n",
    "    observable_set=obs_set,\n",
    "    circuit_id=CIRCUIT_ID,\n",
    "    config=config,\n",
    "    locality_map=locality_map,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Task Summary Report\n",
    "\n",
    "Clear quantitative answers to each of the 8 benchmark questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TASK SUMMARY REPORT\n",
    "# =============================================================================\n",
    "\n",
    "long_form = result.long_form_results\n",
    "truth_values = result.ground_truth.truth_values if result.ground_truth else {}\n",
    "max_n = max(result.summary.get('n_shots_grid', [5000]))\n",
    "epsilon = config.epsilon\n",
    "\n",
    "# Group data by protocol and N\n",
    "by_protocol_n = defaultdict(lambda: defaultdict(list))\n",
    "for row in long_form:\n",
    "    by_protocol_n[row.protocol_id][row.N_total].append(row)\n",
    "\n",
    "protocols = list(by_protocol_n.keys())\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"BENCHMARK TASK SUMMARY REPORT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nCircuit: {CIRCUIT_ID}\")\n",
    "print(f\"Qubits: {N_QUBITS}\")\n",
    "print(f\"Observables: {len(obs_set)}\")\n",
    "print(f\"Protocols: {', '.join(protocols)}\")\n",
    "print(f\"Shot Grid: {result.summary.get('n_shots_grid', [])}\")\n",
    "print(f\"Replicates: {config.n_replicates}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TASK 1: Worst-Case Guarantee ---\n",
    "print(\"-\" * 80)\n",
    "print(\"TASK 1: WORST-CASE GUARANTEE\")\n",
    "print(\"Question: What N* achieves max SE ≤ ε for ALL observables?\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"\\nTarget ε = {epsilon}\")\n",
    "print()\n",
    "\n",
    "for protocol in protocols:\n",
    "    n_star = None\n",
    "    for n in sorted(by_protocol_n[protocol].keys()):\n",
    "        rows = by_protocol_n[protocol][n]\n",
    "        max_se = max(r.se for r in rows if r.se is not None)\n",
    "        if max_se <= epsilon:\n",
    "            n_star = n\n",
    "            break\n",
    "    \n",
    "    if n_star:\n",
    "        print(f\"  {protocol}: N* = {n_star} shots\")\n",
    "    else:\n",
    "        rows = by_protocol_n[protocol][max_n]\n",
    "        max_se = max(r.se for r in rows if r.se is not None)\n",
    "        print(f\"  {protocol}: N* > {max_n} (max SE = {max_se:.4f} at N={max_n})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TASK 2: Average Target ---\n",
    "print(\"-\" * 80)\n",
    "print(\"TASK 2: AVERAGE TARGET\")\n",
    "print(\"Question: What N* achieves mean SE ≤ ε?\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"\\nTarget ε = {epsilon}\")\n",
    "print()\n",
    "\n",
    "for protocol in protocols:\n",
    "    n_star = None\n",
    "    for n in sorted(by_protocol_n[protocol].keys()):\n",
    "        rows = by_protocol_n[protocol][n]\n",
    "        mean_se = np.mean([r.se for r in rows if r.se is not None])\n",
    "        if mean_se <= epsilon:\n",
    "            n_star = n\n",
    "            break\n",
    "    \n",
    "    if n_star:\n",
    "        print(f\"  {protocol}: N* = {n_star} shots\")\n",
    "    else:\n",
    "        rows = by_protocol_n[protocol][max_n]\n",
    "        mean_se = np.mean([r.se for r in rows if r.se is not None])\n",
    "        print(f\"  {protocol}: N* > {max_n} (mean SE = {mean_se:.4f} at N={max_n})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TASK 3: Fixed Budget Distribution ---\n",
    "print(\"-\" * 80)\n",
    "print(\"TASK 3: FIXED BUDGET DISTRIBUTION\")\n",
    "print(f\"Question: What is the SE distribution at N = {max_n}?\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "print(f\"{'Protocol':<25} {'Mean SE':>10} {'Median SE':>10} {'Max SE':>10} {'Std SE':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for protocol in protocols:\n",
    "    rows = by_protocol_n[protocol][max_n]\n",
    "    ses = [r.se for r in rows if r.se is not None]\n",
    "    if ses:\n",
    "        print(f\"{protocol:<25} {np.mean(ses):>10.4f} {np.median(ses):>10.4f} \"\n",
    "              f\"{np.max(ses):>10.4f} {np.std(ses):>10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TASK 4: Dominance ---\n",
    "print(\"-\" * 80)\n",
    "print(\"TASK 4: DOMINANCE\")\n",
    "print(\"Question: Which protocol wins on more observables?\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "# Find best protocol for each observable at max N\n",
    "obs_best = defaultdict(lambda: {'se': float('inf'), 'protocol': None})\n",
    "for protocol in protocols:\n",
    "    rows = by_protocol_n[protocol][max_n]\n",
    "    for row in rows:\n",
    "        if row.se < obs_best[row.observable_id]['se']:\n",
    "            obs_best[row.observable_id] = {'se': row.se, 'protocol': protocol}\n",
    "\n",
    "wins = defaultdict(int)\n",
    "for obs_id, data in obs_best.items():\n",
    "    if data['protocol']:\n",
    "        wins[data['protocol']] += 1\n",
    "\n",
    "total_obs = len(obs_best)\n",
    "print(f\"At N = {max_n}:\")\n",
    "for protocol in protocols:\n",
    "    win_count = wins[protocol]\n",
    "    win_pct = 100 * win_count / total_obs if total_obs > 0 else 0\n",
    "    print(f\"  {protocol}: wins on {win_count}/{total_obs} observables ({win_pct:.1f}%)\")\n",
    "\n",
    "if wins:\n",
    "    overall_winner = max(wins, key=wins.get)\n",
    "    print(f\"\\n  WINNER: {overall_winner}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TASK 5: Pilot Selection ---\n",
    "print(\"-\" * 80)\n",
    "print(\"TASK 5: PILOT SELECTION\")\n",
    "print(\"Question: What fraction of budget should be used for pilot?\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "if result.analysis and hasattr(result.analysis, 'pilot_analysis') and result.analysis.pilot_analysis:\n",
    "    pilot = result.analysis.pilot_analysis\n",
    "    print(f\"{'Pilot %':>10} {'Accuracy':>12} {'Mean Regret':>12}\")\n",
    "    print(\"-\" * 40)\n",
    "    for frac, res in sorted(pilot.results.items()):\n",
    "        print(f\"{frac*100:>9.0f}% {res.selection_accuracy*100:>11.1f}% {res.mean_regret:>12.4f}\")\n",
    "    print(f\"\\n  OPTIMAL PILOT: {pilot.optimal_fraction*100:.0f}% of budget\")\n",
    "else:\n",
    "    print(\"  (Requires analysis mode for detailed pilot study)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TASK 6: Bias-Variance Decomposition ---\n",
    "print(\"-\" * 80)\n",
    "print(\"TASK 6: BIAS-VARIANCE DECOMPOSITION\")\n",
    "print(\"Question: How does MSE decompose into bias² + variance?\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "\n",
    "if truth_values:\n",
    "    print(f\"{'Protocol':<25} {'Bias²':>12} {'Variance':>12} {'MSE':>12}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for protocol in protocols:\n",
    "        rows = by_protocol_n[protocol][max_n]\n",
    "        \n",
    "        # Group by observable\n",
    "        by_obs = defaultdict(list)\n",
    "        for row in rows:\n",
    "            if row.observable_id in truth_values:\n",
    "                by_obs[row.observable_id].append(row.estimate)\n",
    "        \n",
    "        biases_sq = []\n",
    "        variances = []\n",
    "        for obs_id, estimates in by_obs.items():\n",
    "            truth = truth_values[obs_id]\n",
    "            mean_est = np.mean(estimates)\n",
    "            bias = mean_est - truth\n",
    "            var = np.var(estimates)\n",
    "            biases_sq.append(bias**2)\n",
    "            variances.append(var)\n",
    "        \n",
    "        if biases_sq:\n",
    "            mean_bias_sq = np.mean(biases_sq)\n",
    "            mean_var = np.mean(variances)\n",
    "            mse = mean_bias_sq + mean_var\n",
    "            print(f\"{protocol:<25} {mean_bias_sq:>12.6f} {mean_var:>12.6f} {mse:>12.6f}\")\n",
    "else:\n",
    "    print(\"  (Requires ground truth for bias-variance decomposition)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TASK 7: Noise Sensitivity ---\n",
    "print(\"-\" * 80)\n",
    "print(\"TASK 7: NOISE SENSITIVITY\")\n",
    "print(\"Question: How does performance degrade with noise?\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "print(\"  (Requires running benchmark with multiple noise profiles)\")\n",
    "print(\"  Current run: ideal (noiseless) simulation\")\n",
    "print()\n",
    "\n",
    "# --- TASK 8: Adaptive Efficiency ---\n",
    "print(\"-\" * 80)\n",
    "print(\"TASK 8: ADAPTIVE EFFICIENCY\")\n",
    "print(\"Question: Can budget reallocation improve results?\")\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "print(\"  (Requires two-stage adaptive protocol implementation)\")\n",
    "print(\"  See pilot analysis (Task 5) for related insights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXECUTIVE SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"EXECUTIVE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "protocol_summaries = result.summary.get('protocol_summaries', {})\n",
    "if protocol_summaries:\n",
    "    best_by_mean = min(protocol_summaries, key=lambda p: protocol_summaries[p].get('mean_se', float('inf')))\n",
    "    best_by_max = min(protocol_summaries, key=lambda p: protocol_summaries[p].get('max_se', float('inf')))\n",
    "    \n",
    "    print(f\"Best protocol (mean SE): {best_by_mean}\")\n",
    "    print(f\"Best protocol (max SE):  {best_by_max}\")\n",
    "    print()\n",
    "    \n",
    "    # Shadows vs baseline comparison\n",
    "    if 'classical_shadows_v0' in protocol_summaries and 'direct_grouped' in protocol_summaries:\n",
    "        shadows_se = protocol_summaries['classical_shadows_v0'].get('mean_se', 1)\n",
    "        grouped_se = protocol_summaries['direct_grouped'].get('mean_se', 1)\n",
    "        ratio = shadows_se / grouped_se if grouped_se > 0 else float('inf')\n",
    "        \n",
    "        print(f\"Shadows vs Grouped SE ratio: {ratio:.2f}x\")\n",
    "        if ratio < 1:\n",
    "            ssf = 1 / (ratio ** 2)  # Shot savings factor\n",
    "            print(f\"  → Classical shadows is {1/ratio:.1f}x more efficient\")\n",
    "            print(f\"  → Shot Savings Factor (SSF): {ssf:.1f}x\")\n",
    "        else:\n",
    "            print(f\"  → Direct grouped is {ratio:.1f}x more efficient\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(f\"Full results saved to: {result.output_dir}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This benchmark answered the 8 Measurements Bible questions:\n",
    "\n",
    "| Task | Question | Answer Format |\n",
    "|------|----------|---------------|\n",
    "| 1 | Worst-case N*? | N* = X shots (or N* > max_N) |\n",
    "| 2 | Average N*? | N* = X shots (or N* > max_N) |\n",
    "| 3 | SE distribution? | mean, median, max, std |\n",
    "| 4 | Dominance? | Protocol X wins Y% |\n",
    "| 5 | Pilot fraction? | Optimal = X% |\n",
    "| 6 | Bias-variance? | Bias² = X, Var = Y, MSE = Z |\n",
    "| 7 | Noise sensitivity? | (requires noise sweep) |\n",
    "| 8 | Adaptive efficiency? | (requires adaptive protocol) |\n",
    "\n",
    "All results saved to timestamped directory for reproducibility."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
