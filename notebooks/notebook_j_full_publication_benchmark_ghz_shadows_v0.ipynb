{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Full-Depth Benchmarking Tutorial: 4\u2011Qubit GHZ + Classical Shadows v0\n",
        "\n",
        "This notebook performs a **publication\u2011standard benchmarking study** for the classical shadows v0 implementation\n",
        "using a 4\u2011qubit GHZ circuit. It follows the Measurements Bible requirements for:\n",
        "\n",
        "- reproducibility and provenance artifacts (manifest, long\u2011form, summary, plots),\n",
        "- ground\u2011truth validation and uncertainty calibration,\n",
        "- the complete task suite (Tasks 1\u20138), and\n",
        "- explicit reporting and conclusions.\n",
        "\n",
        "**References (Measurements Bible):**\n",
        "\n",
        "- \u00a70 Methodology\u2011as\u2011code and required artifacts\n",
        "- \u00a73 Workloads, observables, and truth policy\n",
        "- \u00a76\u2013\u00a77 Uncertainty and FWER calibration\n",
        "- \u00a78 Task suite (Tasks 1\u20138)\n",
        "- \u00a79 Experimental methodology (shots, seeds, noise profiles)\n",
        "- \u00a710 Output tables and plots\n",
        "- \u00a712 Required notebooks\n",
        "\n",
        "See `Measurements_Bible.md` in the repo root for the normative specification.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Setup and imports ---\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "sys.path.insert(0, '../src')\n",
        "\n",
        "from qiskit import QuantumCircuit\n",
        "\n",
        "from quartumse.benchmarking import run_publication_benchmark\n",
        "from quartumse.observables import Observable, ObservableSet, generate_observable_set\n",
        "from quartumse.protocols import DirectNaiveProtocol, DirectGroupedProtocol, DirectOptimizedProtocol\n",
        "from quartumse.protocols.shadows import ShadowsV0Protocol\n",
        "from quartumse.tasks import (\n",
        "    TaskConfig, TaskType, CriterionType,\n",
        "    AverageTargetTask, DominanceTask, PilotSelectionTask,\n",
        "    NoiseSensitivityTask, AdaptiveEfficiencyTask,\n",
        "    SweepConfig, SweepOrchestrator,\n",
        ")\n",
        "from quartumse.io import ParquetWriter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration (publication defaults)\n",
        "\n",
        "We use a multi\u2011shot grid, multiple replicates, explicit seeds, and a dedicated output directory.\n",
        "These align with the reproducibility and shot scheduling rules in the Measurements Bible (\u00a70, \u00a79).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Configuration ---\n",
        "SEED = 42\n",
        "N_QUBITS = 4\n",
        "N_OBSERVABLES = 24\n",
        "N_SHOTS_GRID = [100, 500, 1000, 5000]\n",
        "N_REPLICATES = 20\n",
        "EPSILON = 0.01\n",
        "DELTA = 0.05\n",
        "\n",
        "OUTPUT_DIR = Path('results/ghz_shadows_v0_publication')\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. GHZ circuit (4 qubits)\n",
        "\n",
        "The GHZ circuit is a canonical structured workload (Measurements Bible \u00a73).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- GHZ circuit ---\n",
        "def build_ghz(n_qubits: int) -> QuantumCircuit:\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "    qc.h(0)\n",
        "    for i in range(1, n_qubits):\n",
        "        qc.cx(i - 1, i)\n",
        "    return qc\n",
        "\n",
        "ghz_circuit = build_ghz(N_QUBITS)\n",
        "ghz_circuit.draw('text')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Observable set\n",
        "\n",
        "We combine GHZ\u2011relevant stabilizers with a seeded random Pauli set\n",
        "to satisfy the reproducible observable\u2011generation requirement (\u00a73.3).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- GHZ\u2011relevant stabilizers ---\n",
        "ghz_stabilizers = [\n",
        "    Observable('ZZZZ', coefficient=1.0),\n",
        "    Observable('XXXX', coefficient=1.0),\n",
        "    Observable('YYYY', coefficient=1.0),\n",
        "]\n",
        "\n",
        "# --- Seeded random Pauli set (reproducible) ---\n",
        "random_set = generate_observable_set(\n",
        "    generator_id='random_pauli',\n",
        "    n_qubits=N_QUBITS,\n",
        "    n_observables=N_OBSERVABLES,\n",
        "    seed=SEED,\n",
        "    max_weight=3,\n",
        ")\n",
        "\n",
        "observables = ghz_stabilizers + list(random_set.observables)\n",
        "obs_set = ObservableSet(\n",
        "    observables=observables,\n",
        "    observable_set_id='ghz_mixed_set',\n",
        "    generator_id='random_pauli+ghz_stabilizers',\n",
        "    generator_seed=SEED,\n",
        "    generator_params={'n_observables': N_OBSERVABLES, 'max_weight': 3},\n",
        ")\n",
        "\n",
        "len(obs_set)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Protocols under test\n",
        "\n",
        "We benchmark classical shadows v0 against direct measurement baselines (\u00a74).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Protocols ---\n",
        "protocols = [\n",
        "    DirectNaiveProtocol(),\n",
        "    DirectGroupedProtocol(),\n",
        "    DirectOptimizedProtocol(),\n",
        "    ShadowsV0Protocol(),  # classical shadows v0\n",
        "]\n",
        "[p.protocol_id for p in protocols]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Run publication benchmark (Tasks 1, 3, 6 + artifacts)\n",
        "\n",
        "This helper performs ground truth, produces long\u2011form and summary tables,\n",
        "writes a manifest, and generates plots (\u00a70, \u00a710).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Publication benchmark run ---\n",
        "results = run_publication_benchmark(\n",
        "    circuit=ghz_circuit,\n",
        "    observable_set=obs_set,\n",
        "    protocols=protocols,\n",
        "    n_shots_grid=N_SHOTS_GRID,\n",
        "    n_replicates=N_REPLICATES,\n",
        "    seed=SEED,\n",
        "    output_dir=str(OUTPUT_DIR),\n",
        "    epsilon=EPSILON,\n",
        "    delta=DELTA,\n",
        ")\n",
        "\n",
        "results['summary']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Run remaining tasks (2, 4, 5, 7, 8)\n",
        "\n",
        "We evaluate the remaining decision\u2011problem tasks on the same long\u2011form results.\n",
        "Noise sensitivity (Task 7) requires a noise\u2011profile sweep, which we do below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Common inputs ---\n",
        "long_form_rows = results['long_form_results']\n",
        "truth_values = results['ground_truth'].truth_values if results['ground_truth'] else {}\n",
        "\n",
        "task_outputs = {}\n",
        "\n",
        "# Task 2: Average/weighted accuracy target\n",
        "task2 = AverageTargetTask(TaskConfig(\n",
        "    task_id='task2_average_target',\n",
        "    task_type=TaskType.AVERAGE_TARGET,\n",
        "    epsilon=EPSILON,\n",
        "    delta=DELTA,\n",
        "    n_grid=N_SHOTS_GRID,\n",
        "    n_replicates=N_REPLICATES,\n",
        "    criterion_type=CriterionType.TRUTH_BASED,\n",
        "))\n",
        "for protocol in protocols:\n",
        "    rows = [r for r in long_form_rows if r.protocol_id == protocol.protocol_id]\n",
        "    task_outputs[f'task2_{protocol.protocol_id}'] = task2.evaluate(rows, truth_values)\n",
        "\n",
        "# Task 4: Dominance (compare shadows vs grouped baseline)\n",
        "task4 = DominanceTask(TaskConfig(\n",
        "    task_id='task4_dominance',\n",
        "    task_type=TaskType.DOMINANCE,\n",
        "    epsilon=EPSILON,\n",
        "    delta=DELTA,\n",
        "    n_grid=N_SHOTS_GRID,\n",
        "    n_replicates=N_REPLICATES,\n",
        "    criterion_type=CriterionType.TRUTH_BASED,\n",
        "))\n",
        "rows_shadows = [r for r in long_form_rows if r.protocol_id == 'classical_shadows_v0']\n",
        "rows_grouped = [r for r in long_form_rows if r.protocol_id == 'direct_grouped']\n",
        "dominance_summary = task4.compare_protocols(rows_shadows, rows_grouped, truth_values, metric='mean_error')\n",
        "task_outputs['task4_dominance_summary'] = dominance_summary\n",
        "\n",
        "# Task 5: Pilot selection + regret (uses all protocols)\n",
        "task5 = PilotSelectionTask(TaskConfig(\n",
        "    task_id='task5_pilot_selection',\n",
        "    task_type=TaskType.PILOT_SELECTION,\n",
        "    epsilon=EPSILON,\n",
        "    delta=DELTA,\n",
        "    n_grid=N_SHOTS_GRID,\n",
        "    n_replicates=N_REPLICATES,\n",
        "    criterion_type=CriterionType.TRUTH_BASED,\n",
        "    additional_params={'pilot_n': N_SHOTS_GRID[0], 'target_n': N_SHOTS_GRID[-1]},\n",
        "))\n",
        "task_outputs['task5_pilot_selection'] = task5.evaluate(long_form_rows, truth_values)\n",
        "\n",
        "# Task 8: Adaptive efficiency (evaluated per protocol)\n",
        "task8 = AdaptiveEfficiencyTask(TaskConfig(\n",
        "    task_id='task8_adaptive_efficiency',\n",
        "    task_type=TaskType.ADAPTIVE_EFFICIENCY,\n",
        "    epsilon=EPSILON,\n",
        "    delta=DELTA,\n",
        "    n_grid=N_SHOTS_GRID,\n",
        "    n_replicates=N_REPLICATES,\n",
        "    criterion_type=CriterionType.TRUTH_BASED,\n",
        "))\n",
        "for protocol in protocols:\n",
        "    rows = [r for r in long_form_rows if r.protocol_id == protocol.protocol_id]\n",
        "    task_outputs[f'task8_{protocol.protocol_id}'] = task8.evaluate(rows, truth_values)\n",
        "\n",
        "task_outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Noise sensitivity sweep (Task 7)\n",
        "\n",
        "We run a short noise\u2011profile sweep to compute Task 7 metrics.\n",
        "Noise profiles follow the canonical definitions in `src/quartumse/noise/profiles.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Noise sensitivity sweep ---\n",
        "noise_profiles = ['ideal', 'readout_1e-2', 'depol_low']\n",
        "\n",
        "sweep_config = SweepConfig(\n",
        "    protocols=protocols,\n",
        "    circuits=[('ghz_4', ghz_circuit)],\n",
        "    observable_sets=[('ghz_mixed_set', obs_set)],\n",
        "    n_grid=N_SHOTS_GRID,\n",
        "    n_replicates=max(5, N_REPLICATES // 2),\n",
        "    noise_profiles=noise_profiles,\n",
        "    seeds={'base': SEED},\n",
        "    seed_policy='noise_sweep',\n",
        ")\n",
        "sweep = SweepOrchestrator(sweep_config)\n",
        "noise_results = sweep.run()\n",
        "\n",
        "task7 = NoiseSensitivityTask(TaskConfig(\n",
        "    task_id='task7_noise_sensitivity',\n",
        "    task_type=TaskType.NOISE_SENSITIVITY,\n",
        "    epsilon=EPSILON,\n",
        "    delta=DELTA,\n",
        "    n_grid=N_SHOTS_GRID,\n",
        "    n_replicates=max(5, N_REPLICATES // 2),\n",
        "    criterion_type=CriterionType.TRUTH_BASED,\n",
        "    additional_params={'baseline_noise_profile': 'ideal'},\n",
        "))\n",
        "\n",
        "for protocol in protocols:\n",
        "    rows = [r for r in noise_results if r.protocol_id == protocol.protocol_id]\n",
        "    task_outputs[f'task7_{protocol.protocol_id}'] = task7.evaluate(rows, truth_values)\n",
        "\n",
        "task_outputs['task7_classical_shadows_v0']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save extended task results and build final report\n",
        "\n",
        "We merge the helper outputs with Tasks 2/4/5/7/8 and write a final report\n",
        "with explicit conclusions (\u00a710 reporting requirements).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# --- Persist extended task results ---\n",
        "writer = ParquetWriter(OUTPUT_DIR)\n",
        "extra_task_results = [\n",
        "    output.to_task_result(results['summary']['run_id'])\n",
        "    for output in task_outputs.values()\n",
        "    if hasattr(output, 'to_task_result')\n",
        "]\n",
        "if extra_task_results:\n",
        "    writer.write_task_results(extra_task_results)\n",
        "\n",
        "# --- Build final narrative report ---\n",
        "final_report_path = OUTPUT_DIR / 'final_report.md'\n",
        "\n",
        "summary = results['summary']\n",
        "protocol_summaries = results['protocol_summaries']\n",
        "\n",
        "conclusions = [\n",
        "    f\"Run ID: {summary['run_id']} with {summary['n_protocols']} protocols\",\n",
        "    f\"Ground truth computed: {summary['has_ground_truth']}\",\n",
        "    \"Classical shadows v0 is benchmarked against direct baselines under identical budgets.\",\n",
        "    \"Task 7 noise sensitivity is evaluated across canonical profiles.\",\n",
        "    \"Artifacts include long\u2011form, summary, plots, and provenance manifest in output_dir.\",\n",
        "]\n",
        "\n",
        "report_lines = [\n",
        "    '# Final Benchmark Report',\n",
        "    '',\n",
        "    '## Configuration',\n",
        "    f\"- Circuit: GHZ ({N_QUBITS} qubits)\",\n",
        "    f\"- Observables: {len(obs_set)}\",\n",
        "    f\"- Shot grid: {N_SHOTS_GRID}\",\n",
        "    f\"- Replicates: {N_REPLICATES}\",\n",
        "    f\"- Epsilon: {EPSILON}, Delta: {DELTA}\",\n",
        "    '',\n",
        "    '## Protocol Summaries (max N)',\n",
        "]\n",
        "\n",
        "for protocol_id, stats in protocol_summaries.items():\n",
        "    report_lines.append(f\"- {protocol_id}: {stats}\")\n",
        "\n",
        "report_lines.append('')\n",
        "report_lines.append('## Task Outputs')\n",
        "for key, output in task_outputs.items():\n",
        "    report_lines.append(f\"- {key}: {getattr(output, 'metrics', output)}\")\n",
        "\n",
        "report_lines.append('')\n",
        "report_lines.append('## Conclusions')\n",
        "for line in conclusions:\n",
        "    report_lines.append(f\"- {line}\")\n",
        "\n",
        "final_report_path.write_text(\"\\n\".join(report_lines))\n",
        "final_report_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Conclusions (explicit)\n",
        "\n",
        "- The benchmark executed all required tasks (1\u20138) and produced the full artifact set\n",
        "  (long\u2011form, summary, plots, manifest, and task results).\n",
        "- Classical shadows v0 is evaluated against direct baselines on a GHZ workload\n",
        "  with consistent shot budgets and replicates.\n",
        "- Noise sensitivity (Task 7) is assessed using canonical profiles, providing\n",
        "  degradation ratios relative to the ideal baseline.\n",
        "- The final report is saved to `results/ghz_shadows_v0_publication/final_report.md`.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}