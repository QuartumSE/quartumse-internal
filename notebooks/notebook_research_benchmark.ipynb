{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# QuartumSE Complete Benchmark Suite\n",
    "\n",
    "**The canonical benchmark notebook** for classical shadows vs direct measurement.\n",
    "\n",
    "This notebook consolidates ALL benchmarking functionality:\n",
    "- All 8 Measurements Bible tasks\n",
    "- All circuits from research workstreams (S, C, O, B, M)\n",
    "- Enhanced statistical analysis (bootstrap, K-S tests, crossover)\n",
    "- Optional noise sensitivity sweep (Task 7)\n",
    "- Locality breakdown and cost-normalized metrics\n",
    "- Cross-circuit consolidated comparison\n",
    "\n",
    "## Research Workstreams\n",
    "\n",
    "| Workstream | Focus | Circuits |\n",
    "|------------|-------|----------|\n",
    "| **S** | Shadows Core | GHZ, Bell pairs, Clifford, Ising |\n",
    "| **C** | Chemistry | H2, LiH, BeH2 molecular ansatze |\n",
    "| **O** | Optimization | QAOA MAX-CUT |\n",
    "| **B** | Benchmarking | RB/XEB random circuits |\n",
    "| **M** | Metrology | GHZ phase sensing |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:29:41.815900Z",
     "iopub.status.busy": "2026-02-27T14:29:41.815126Z",
     "iopub.status.idle": "2026-02-27T14:30:00.359477Z",
     "shell.execute_reply": "2026-02-27T14:30:00.352744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n",
      "Suite types available: ['workload', 'stress', 'posthoc', 'commuting', 'diagnostic']\n",
      "Default HW profile: ibm_heron_r2 (2Q gate: 300.0ns)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SETUP\n",
    "# =============================================================================\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from qiskit import QuantumCircuit\n",
    "from scipy import stats\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from quartumse import (\n",
    "    run_benchmark_suite,\n",
    "    BenchmarkMode,\n",
    "    BenchmarkSuiteConfig,\n",
    "    Observable,\n",
    "    ObservableSet,\n",
    ")\n",
    "\n",
    "# NEW: Import timing model for hardware time estimates\n",
    "from quartumse.analysis.quantum_time_model import (\n",
    "    HardwareTimingProfile,\n",
    "    IBM_HERON,\n",
    ")\n",
    "\n",
    "# NEW: Import suite classes and builders\n",
    "from quartumse.observables.suites import (\n",
    "    ObservableSuite,\n",
    "    ObjectiveType,\n",
    "    SuiteType,\n",
    "    # Circuit-specific suite builders\n",
    "    make_ghz_suites,\n",
    "    make_bell_suites,\n",
    "    make_ising_suites,\n",
    "    make_qaoa_ring_suites,\n",
    "    make_phase_sensing_suites,\n",
    "    make_chemistry_suites,\n",
    "    # Generic builders\n",
    "    make_stress_suite,\n",
    "    make_posthoc_library,\n",
    "    make_commuting_suite,\n",
    ")\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(\"Suite types available:\", [t.value for t in SuiteType])\n",
    "print(f\"Default HW profile: {IBM_HERON.profile_id} (2Q gate: {IBM_HERON.gate_2q_ns}ns)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circuits-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Circuit and Observable Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "circuit-builders",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:30:00.369390Z",
     "iopub.status.busy": "2026-02-27T14:30:00.368007Z",
     "iopub.status.idle": "2026-02-27T14:30:00.438342Z",
     "shell.execute_reply": "2026-02-27T14:30:00.432813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit builders defined!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CIRCUIT BUILDERS\n",
    "# =============================================================================\n",
    "\n",
    "def build_ghz(n_qubits: int) -> QuantumCircuit:\n",
    "    \"\"\"GHZ state: |00...0> + |11...1> / sqrt(2)\"\"\"\n",
    "    qc = QuantumCircuit(n_qubits, name=f'GHZ_{n_qubits}q')\n",
    "    qc.h(0)\n",
    "    for i in range(1, n_qubits):\n",
    "        qc.cx(i - 1, i)\n",
    "    return qc\n",
    "\n",
    "def build_bell_pairs(n_pairs: int) -> QuantumCircuit:\n",
    "    \"\"\"Parallel Bell pairs.\"\"\"\n",
    "    n_qubits = 2 * n_pairs\n",
    "    qc = QuantumCircuit(n_qubits, name=f'Bell_{n_pairs}pairs')\n",
    "    for i in range(n_pairs):\n",
    "        qc.h(2 * i)\n",
    "        qc.cx(2 * i, 2 * i + 1)\n",
    "    return qc\n",
    "\n",
    "def build_random_clifford(n_qubits: int, depth: int, seed: int = 42) -> QuantumCircuit:\n",
    "    \"\"\"Random Clifford circuit.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    qc = QuantumCircuit(n_qubits, name=f'Clifford_{n_qubits}q_d{depth}')\n",
    "    clifford_gates = ['h', 's', 'sdg', 'x', 'y', 'z']\n",
    "    for _ in range(depth):\n",
    "        for q in range(n_qubits):\n",
    "            gate = rng.choice(clifford_gates)\n",
    "            getattr(qc, gate)(q)\n",
    "        for q in range(0, n_qubits - 1, 2):\n",
    "            if rng.random() > 0.3:\n",
    "                qc.cx(q, q + 1)\n",
    "    return qc\n",
    "\n",
    "def build_ising_trotter(n_qubits: int, steps: int = 3, dt: float = 0.5) -> QuantumCircuit:\n",
    "    \"\"\"Trotterized transverse-field Ising model.\"\"\"\n",
    "    qc = QuantumCircuit(n_qubits, name=f'Ising_{n_qubits}q_t{steps}')\n",
    "    J, h = 1.0, 0.5\n",
    "    for q in range(n_qubits):\n",
    "        qc.h(q)\n",
    "    for _ in range(steps):\n",
    "        for q in range(n_qubits - 1):\n",
    "            qc.cx(q, q + 1)\n",
    "            qc.rz(2 * J * dt, q + 1)\n",
    "            qc.cx(q, q + 1)\n",
    "        for q in range(n_qubits):\n",
    "            qc.rx(2 * h * dt, q)\n",
    "    return qc\n",
    "\n",
    "def build_h2_ansatz(theta: float = 0.5) -> QuantumCircuit:\n",
    "    \"\"\"H2 molecule ansatz (4 qubits).\"\"\"\n",
    "    qc = QuantumCircuit(4, name='H2_ansatz')\n",
    "    qc.x(0); qc.x(1)\n",
    "    qc.cx(1, 2); qc.ry(theta, 2); qc.cx(1, 2)\n",
    "    qc.cx(0, 3); qc.ry(theta / 2, 3); qc.cx(0, 3)\n",
    "    return qc\n",
    "\n",
    "def build_lih_ansatz(theta: float = 0.5) -> QuantumCircuit:\n",
    "    \"\"\"LiH molecule ansatz (6 qubits).\"\"\"\n",
    "    qc = QuantumCircuit(6, name='LiH_ansatz')\n",
    "    for i in range(4): qc.x(i)\n",
    "    qc.cx(3, 4); qc.ry(theta, 4); qc.cx(3, 4)\n",
    "    qc.cx(2, 5); qc.ry(theta / 2, 5); qc.cx(2, 5)\n",
    "    return qc\n",
    "\n",
    "def build_beh2_ansatz(theta: float = 0.5) -> QuantumCircuit:\n",
    "    \"\"\"BeH2 molecule ansatz (8 qubits).\"\"\"\n",
    "    qc = QuantumCircuit(8, name='BeH2_ansatz')\n",
    "    for i in range(6): qc.x(i)\n",
    "    qc.cx(5, 6); qc.ry(theta, 6); qc.cx(5, 6)\n",
    "    qc.cx(4, 7); qc.ry(theta / 2, 7); qc.cx(4, 7)\n",
    "    return qc\n",
    "\n",
    "def build_qaoa_maxcut_ring(n_qubits: int, p: int = 1, gamma: float = 0.5, beta: float = 0.5) -> QuantumCircuit:\n",
    "    \"\"\"QAOA for MAX-CUT on ring graph.\"\"\"\n",
    "    qc = QuantumCircuit(n_qubits, name=f'QAOA_ring_{n_qubits}q_p{p}')\n",
    "    for q in range(n_qubits): qc.h(q)\n",
    "    for _ in range(p):\n",
    "        for q in range(n_qubits):\n",
    "            q_next = (q + 1) % n_qubits\n",
    "            qc.cx(q, q_next); qc.rz(2 * gamma, q_next); qc.cx(q, q_next)\n",
    "        for q in range(n_qubits): qc.rx(2 * beta, q)\n",
    "    return qc\n",
    "\n",
    "def build_ghz_phase_sensing(n_qubits: int, phi: float = 0.1) -> QuantumCircuit:\n",
    "    \"\"\"GHZ state with phase encoding.\"\"\"\n",
    "    qc = build_ghz(n_qubits)\n",
    "    qc.name = f'GHZ_phase_{n_qubits}q'\n",
    "    for q in range(n_qubits): qc.rz(phi, q)\n",
    "    return qc\n",
    "\n",
    "def build_xeb_circuit(n_qubits: int, depth: int, seed: int = 42) -> QuantumCircuit:\n",
    "    \"\"\"Cross-Entropy Benchmarking random circuit.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    qc = QuantumCircuit(n_qubits, name=f'XEB_{n_qubits}q_d{depth}')\n",
    "    gates_1q = ['h', 'x', 'y', 'z', 's', 't', 'sdg', 'tdg']\n",
    "    for d in range(depth):\n",
    "        for q in range(n_qubits):\n",
    "            getattr(qc, rng.choice(gates_1q))(q)\n",
    "        for q in range(d % 2, n_qubits - 1, 2):\n",
    "            qc.cx(q, q + 1)\n",
    "    return qc\n",
    "\n",
    "print(\"Circuit builders defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "observable-builders",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:30:00.453435Z",
     "iopub.status.busy": "2026-02-27T14:30:00.452039Z",
     "iopub.status.idle": "2026-02-27T14:30:03.103492Z",
     "shell.execute_reply": "2026-02-27T14:30:03.099571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "AVAILABLE SUITES BY CIRCUIT TYPE\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GHZ-4:\n",
      "  workload_stabilizers           |    7 obs | per-obs  | 2 groups\n",
      "  stress_random_1000             |  255 obs | per-obs  | 81 groups\n",
      "  commuting_z_only               |   11 obs | per-obs  | FULLY COMMUTING\n",
      "  posthoc_library                |  255 obs | per-obs  | 81 groups\n",
      "\n",
      "Bell-2pairs:\n",
      "  workload_pair_correlations     |    6 obs | per-obs  | 3 groups\n",
      "  diagnostics_single_qubit       |    4 obs | per-obs  | FULLY COMMUTING\n",
      "  diagnostics_cross_pair         |    1 obs | per-obs  | FULLY COMMUTING\n",
      "  stress_random_1000             |  255 obs | per-obs  | 81 groups\n",
      "\n",
      "Ising-4:\n",
      "  workload_energy                |    7 obs | weighted | 2 groups\n",
      "  workload_correlations          |    6 obs | per-obs  | FULLY COMMUTING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  stress_random_1000             |  255 obs | per-obs  | 81 groups\n",
      "\n",
      "QAOA-5-ring:\n",
      "  workload_cost                  |    5 obs | weighted | FULLY COMMUTING\n",
      "  commuting_cost                 |    5 obs | weighted | FULLY COMMUTING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  stress_random_1000             |  705 obs | per-obs  | 207 groups\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  posthoc_library                | 1018 obs | per-obs  | 243 groups\n",
      "\n",
      "Phase-3:\n",
      "  workload_phase_signal          |    2 obs | per-obs  | 2 groups\n",
      "  workload_stabilizers           |    4 obs | per-obs  | 3 groups\n",
      "  stress_random_500              |   63 obs | per-obs  | 27 groups\n",
      "\n",
      "======================================================================\n",
      "KEY INSIGHT: Commuting suites (e.g., QAOA cost) favor grouped measurement\n",
      "             Non-commuting suites (e.g., stress) may favor shadows\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# OBSERVABLE SUITES (from quartumse.observables.suites module)\n",
    "# =============================================================================\n",
    "# \n",
    "# The suite system provides task-aligned observable sets for each circuit family.\n",
    "# Each circuit gets multiple suites:\n",
    "#   - workload: What practitioners actually measure (energy, cost, fidelity)\n",
    "#   - stress: Large sets (1000+) for testing protocol scaling  \n",
    "#   - commuting: All-commuting baselines (where grouped measurement wins)\n",
    "#   - posthoc: Libraries for \"measure once, query later\" tests\n",
    "#\n",
    "# Suite builders:\n",
    "#   make_ghz_suites(n)           -> stabilizers, stress, commuting, posthoc\n",
    "#   make_bell_suites(n_pairs)    -> pair correlations, diagnostics, stress\n",
    "#   make_ising_suites(n)         -> energy (weighted), correlations, stress\n",
    "#   make_qaoa_ring_suites(n)     -> cost (weighted, with wrap edge!), stress, posthoc\n",
    "#   make_phase_sensing_suites(n) -> phase signal (X^n, Y^n), stabilizers, stress\n",
    "#   make_chemistry_suites(n)     -> energy (weighted), stress\n",
    "\n",
    "# Demo: Show what suites are generated for each circuit type\n",
    "print(\"=\"*70)\n",
    "print(\"AVAILABLE SUITES BY CIRCUIT TYPE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "demo_configs = [\n",
    "    (\"GHZ-4\", make_ghz_suites(4)),\n",
    "    (\"Bell-2pairs\", make_bell_suites(2)),\n",
    "    (\"Ising-4\", make_ising_suites(4)),\n",
    "    (\"QAOA-5-ring\", make_qaoa_ring_suites(5)),\n",
    "    (\"Phase-3\", make_phase_sensing_suites(3)),\n",
    "]\n",
    "\n",
    "for name, suites in demo_configs:\n",
    "    print(f\"\\n{name}:\")\n",
    "    for suite_name, suite in suites.items():\n",
    "        obj = \"weighted\" if suite.objective == ObjectiveType.WEIGHTED_SUM else \"per-obs\"\n",
    "        comm = suite.commutation_analysis()\n",
    "        comm_str = \"FULLY COMMUTING\" if comm['fully_commuting'] else f\"{comm['n_commuting_groups']} groups\"\n",
    "        print(f\"  {suite_name:30s} | {suite.n_observables:4d} obs | {obj:8s} | {comm_str}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY INSIGHT: Commuting suites (e.g., QAOA cost) favor grouped measurement\")\n",
    "print(\"             Non-commuting suites (e.g., stress) may favor shadows\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "circuit-selection",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:30:03.115535Z",
     "iopub.status.busy": "2026-02-27T14:30:03.114046Z",
     "iopub.status.idle": "2026-02-27T14:30:03.154304Z",
     "shell.execute_reply": "2026-02-27T14:30:03.147326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuits to run: 1 / 12\n",
      "  + S-BELL-2\n",
      "\n",
      "Suite types to run: ['merged', 'workload', 'stress', 'commuting', 'posthoc', 'diagnostics']\n",
      "  Stress observables: 100\n",
      "  Posthoc observables: 200\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CIRCUIT AND SUITE SELECTION\n",
    "# =============================================================================\n",
    "\n",
    "# Which circuits to benchmark\n",
    "CIRCUITS_TO_RUN = {\n",
    "    # WORKSTREAM S: SHADOWS CORE\n",
    "    'S-GHZ-4':    False,    # 4-qubit GHZ          -- DONE\n",
    "    'S-GHZ-5':    False,    # 5-qubit GHZ          -- DONE\n",
    "    'S-BELL-2':   True,     # 2 Bell pairs (4 qubits) -- QUICK TEST\n",
    "    'S-BELL-3':   False,    # 3 Bell pairs (6 qubits) -- DONE\n",
    "    'S-ISING-4':  False,    # 4-qubit Ising\n",
    "    'S-ISING-6':  False,    # 6-qubit Ising\n",
    "    # WORKSTREAM C: CHEMISTRY\n",
    "    'C-H2':       False,    # H2 molecule (4 qubits) -- DONE\n",
    "    'C-LiH':      False,    # LiH molecule (6 qubits)\n",
    "    # WORKSTREAM O: OPTIMIZATION\n",
    "    'O-QAOA-5':   False,    # QAOA 5q ring\n",
    "    'O-QAOA-7':   False,    # QAOA 7q ring\n",
    "    # WORKSTREAM M: METROLOGY\n",
    "    'M-PHASE-3':  False,    # 3-qubit phase sensing\n",
    "    'M-PHASE-4':  False,    # 4-qubit phase sensing\n",
    "}\n",
    "\n",
    "SUITES_TO_RUN = {\n",
    "    'merged': True,         # Merged (all unique observables)\n",
    "    'workload': True,       # Task-aligned workload suites (energy, cost, etc.)\n",
    "    'stress': True,         # Large random observable set\n",
    "    'commuting': True,      # All-commuting baseline\n",
    "    'posthoc': True,        # Post-hoc query library\n",
    "    'diagnostics': True,    # System diagnostics\n",
    "}\n",
    "\n",
    "# Number of observables for stress/posthoc suites\n",
    "N_STRESS_OBSERVABLES = 100\n",
    "N_POSTHOC_OBSERVABLES = 200\n",
    "\n",
    "# Count enabled\n",
    "enabled_circuits = [k for k, v in CIRCUITS_TO_RUN.items() if v]\n",
    "enabled_suites = [k for k, v in SUITES_TO_RUN.items() if v]\n",
    "\n",
    "print(f\"Circuits to run: {len(enabled_circuits)} / {len(CIRCUITS_TO_RUN)}\")\n",
    "for c in enabled_circuits:\n",
    "    print(f\"  + {c}\")\n",
    "\n",
    "print()\n",
    "print(f\"Suite types to run: {enabled_suites}\")\n",
    "if SUITES_TO_RUN.get('stress'):\n",
    "    print(f\"  Stress observables: {N_STRESS_OBSERVABLES}\")\n",
    "if SUITES_TO_RUN.get('posthoc'):\n",
    "    print(f\"  Posthoc observables: {N_POSTHOC_OBSERVABLES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "benchmark-config",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:30:03.165688Z",
     "iopub.status.busy": "2026-02-27T14:30:03.164845Z",
     "iopub.status.idle": "2026-02-27T14:30:03.197094Z",
     "shell.execute_reply": "2026-02-27T14:30:03.190965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: analysis\n",
      "Shots: [10000]\n",
      "Replicates: 10\n",
      "Timeout per protocol: 1s\n",
      "HW timing profile: ibm_heron_r2\n",
      "Noise sweep: True\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BENCHMARK CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Per-protocol timeout: stop any single protocol.run() that exceeds this limit.\n",
    "# The protocol will finalize with partial data and flag timed_out=True.\n",
    "# Set to None to disable (run to completion).\n",
    "TIMEOUT_PER_PROTOCOL_S = 1  # 1 second per protocol run; None to disable\n",
    "\n",
    "# Hardware timing profile for estimating real-device execution time.\n",
    "# This does NOT affect simulation - it adds an est_quantum_hw_s column\n",
    "# to results showing what the run WOULD cost on real hardware.\n",
    "# Set to None to skip hardware time estimation.\n",
    "HW_TIMING_PROFILE = IBM_HERON  # IBM Heron R2 defaults; None to disable\n",
    "\n",
    "CONFIG = BenchmarkSuiteConfig(\n",
    "    mode=BenchmarkMode.ANALYSIS,      # Full analysis with all features\n",
    "    n_shots_grid=[10000],\n",
    "    n_replicates=10,                  # Increase to 20+ for publication\n",
    "    seed=42,\n",
    "    epsilon=0.05,                     # Target precision\n",
    "    delta=0.05,                       # Failure probability\n",
    "    shadows_protocol_id=\"classical_shadows_v0\",\n",
    "    baseline_protocol_id=\"direct_grouped\",\n",
    "    output_base_dir=\"benchmark_results\",\n",
    "    timeout_per_protocol_s=TIMEOUT_PER_PROTOCOL_S,\n",
    "    hw_timing_profile=HW_TIMING_PROFILE,\n",
    ")\n",
    "\n",
    "# Optional: Enable noise sweep for Task 7\n",
    "RUN_NOISE_SWEEP = True  # Run with multiple noise profiles\n",
    "NOISE_PROFILES = ['ideal', 'readout_1e-2', 'depol_low']  # If enabled\n",
    "\n",
    "print(f\"Mode: {CONFIG.mode.value}\")\n",
    "print(f\"Shots: {CONFIG.n_shots_grid}\")\n",
    "print(f\"Replicates: {CONFIG.n_replicates}\")\n",
    "print(f\"Timeout per protocol: {TIMEOUT_PER_PROTOCOL_S}s\" if TIMEOUT_PER_PROTOCOL_S else \"Timeout: disabled\")\n",
    "print(f\"HW timing profile: {HW_TIMING_PROFILE.profile_id}\" if HW_TIMING_PROFILE else \"HW timing: disabled\")\n",
    "print(f\"Noise sweep: {RUN_NOISE_SWEEP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "build-circuits",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:30:03.214092Z",
     "iopub.status.busy": "2026-02-27T14:30:03.211907Z",
     "iopub.status.idle": "2026-02-27T14:30:06.118753Z",
     "shell.execute_reply": "2026-02-27T14:30:06.115824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Built 1 circuits:\n",
      "================================================================================\n",
      "\n",
      "S-BELL-2 (4 qubits):\n",
      "  â€¢ workload_pair_correlations        6 obs  3 groups        \n",
      "  â€¢ diagnostics_single_qubit          4 obs  COMMUTING       \n",
      "  â€¢ diagnostics_cross_pair            1 obs  COMMUTING       \n",
      "  â€¢ stress_random_1000               87 obs  32 groups       \n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  âœ“ MERGED: 90 unique obs (saved 8 redundant)\n",
      "\n",
      "================================================================================\n",
      "TOTAL: 1 benchmark runs\n",
      "EFFICIENCY: 90 unique obs from 98 total (8 redundant, 8% saved)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BUILD CIRCUITS AND SUITES\n",
    "# =============================================================================\n",
    "\n",
    "from quartumse.observables.core import Observable, ObservableSet\n",
    "\n",
    "def filter_suites(all_suites: dict, enabled_types: dict) -> dict:\n",
    "    \"\"\"Filter suites based on enabled suite types.\"\"\"\n",
    "    filtered = {}\n",
    "    for name, suite in all_suites.items():\n",
    "        suite_type = suite.suite_type.value\n",
    "        # Check if this suite type is enabled\n",
    "        if enabled_types.get(suite_type, False):\n",
    "            filtered[name] = suite\n",
    "        # Also check for partial matches (e.g., 'workload_energy' matches 'workload')\n",
    "        elif any(enabled_types.get(t, False) and t in name for t in enabled_types):\n",
    "            filtered[name] = suite\n",
    "    return filtered\n",
    "\n",
    "def merge_suites_for_circuit(suites: dict[str, ObservableSuite], circuit_id: str) -> tuple[ObservableSet, dict]:\n",
    "    \"\"\"Merge multiple suites into one ObservableSet, deduplicating by pauli_string.\n",
    "    \n",
    "    Returns:\n",
    "        merged_set: ObservableSet with all unique observables, tagged with source suites\n",
    "        suite_mapping: dict mapping observable_id -> list of source suite names\n",
    "    \"\"\"\n",
    "    # Collect all observables, tracking which suites they came from\n",
    "    pauli_to_obs = {}  # pauli_string -> (Observable, set of suite names)\n",
    "    \n",
    "    for suite_name, suite in suites.items():\n",
    "        for obs in suite.observables:\n",
    "            key = obs.pauli_string\n",
    "            if key in pauli_to_obs:\n",
    "                # Observable already exists - add this suite to its sources\n",
    "                pauli_to_obs[key][1].add(suite_name)\n",
    "            else:\n",
    "                # New observable - create entry with this suite as source\n",
    "                pauli_to_obs[key] = (obs, {suite_name})\n",
    "    \n",
    "    # Build merged observable list with suite tags in metadata\n",
    "    merged_observables = []\n",
    "    suite_mapping = {}\n",
    "    \n",
    "    for pauli_string, (obs, source_suites) in pauli_to_obs.items():\n",
    "        # Create new observable with suite membership in metadata\n",
    "        new_metadata = dict(obs.metadata) if obs.metadata else {}\n",
    "        new_metadata['source_suites'] = sorted(source_suites)\n",
    "        \n",
    "        merged_obs = Observable(\n",
    "            pauli_string=obs.pauli_string,\n",
    "            coefficient=obs.coefficient,\n",
    "            observable_id=obs.observable_id,\n",
    "            group_id=obs.group_id,\n",
    "            metadata=new_metadata,\n",
    "        )\n",
    "        merged_observables.append(merged_obs)\n",
    "        suite_mapping[merged_obs.observable_id] = sorted(source_suites)\n",
    "    \n",
    "    # Create merged ObservableSet (n_qubits is derived from observables)\n",
    "    merged_set = ObservableSet(\n",
    "        observables=merged_observables,\n",
    "        observable_set_id=f\"{circuit_id}_merged\",\n",
    "        generator_id=\"suite_merger\",\n",
    "        generator_version=\"1.0.0\",\n",
    "        metadata={\n",
    "            'merged_from': list(suites.keys()),\n",
    "            'original_counts': {name: suite.n_observables for name, suite in suites.items()},\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    return merged_set, suite_mapping\n",
    "\n",
    "# Circuit definitions: (circuit_builder, suite_builder)\n",
    "CIRCUIT_DEFS = {\n",
    "    # Workstream S: Shadows Core\n",
    "    'S-GHZ-4':   (build_ghz(4), make_ghz_suites(4)),\n",
    "    'S-GHZ-5':   (build_ghz(5), make_ghz_suites(5)),\n",
    "    'S-BELL-2':  (build_bell_pairs(2), make_bell_suites(2)),\n",
    "    'S-BELL-3':  (build_bell_pairs(3), make_bell_suites(3)),\n",
    "    'S-ISING-4': (build_ising_trotter(4, 3), make_ising_suites(4)),\n",
    "    'S-ISING-6': (build_ising_trotter(6, 3), make_ising_suites(6)),\n",
    "    # Workstream C: Chemistry\n",
    "    'C-H2':      (build_h2_ansatz(), make_chemistry_suites(4, molecule_name='H2')),\n",
    "    'C-LiH':     (build_lih_ansatz(), make_chemistry_suites(6, molecule_name='LiH')),\n",
    "    # Workstream O: Optimization\n",
    "    'O-QAOA-5':  (build_qaoa_maxcut_ring(5, p=1), make_qaoa_ring_suites(5)),\n",
    "    'O-QAOA-7':  (build_qaoa_maxcut_ring(7, p=1), make_qaoa_ring_suites(7)),\n",
    "    # Workstream M: Metrology\n",
    "    'M-PHASE-3': (build_ghz_phase_sensing(3, 0.1), make_phase_sensing_suites(3)),\n",
    "    'M-PHASE-4': (build_ghz_phase_sensing(4, 0.1), make_phase_sensing_suites(4)),\n",
    "}\n",
    "\n",
    "# Build selected circuits with filtered suites\n",
    "circuits = {}\n",
    "for cid, run in CIRCUITS_TO_RUN.items():\n",
    "    if run and cid in CIRCUIT_DEFS:\n",
    "        circ, all_suites = CIRCUIT_DEFS[cid]\n",
    "        filtered = filter_suites(all_suites, SUITES_TO_RUN)\n",
    "        \n",
    "        if filtered:\n",
    "            circuits[cid] = {\n",
    "                'circuit': circ,\n",
    "                'suites': filtered,\n",
    "                'n_qubits': circ.num_qubits,\n",
    "            }\n",
    "\n",
    "# Override stress suites with configurable observable count\n",
    "if N_STRESS_OBSERVABLES != 1000:\n",
    "    for cid, info in circuits.items():\n",
    "        stress_keys = [k for k in info['suites'] if 'stress' in k]\n",
    "        for key in stress_keys:\n",
    "            info['suites'][key] = make_stress_suite(\n",
    "                n_qubits=info['n_qubits'],\n",
    "                n_observables=N_STRESS_OBSERVABLES,\n",
    "                seed=42,  # Same seed as original\n",
    "            )\n",
    "\n",
    "# Override posthoc suites with configurable observable count\n",
    "# Use different seed (1042) to avoid overlap with stress observables\n",
    "if N_POSTHOC_OBSERVABLES != 2000:\n",
    "    for cid, info in circuits.items():\n",
    "        posthoc_keys = [k for k in info['suites'] if 'posthoc' in k]\n",
    "        for key in posthoc_keys:\n",
    "            info['suites'][key] = make_posthoc_library(\n",
    "                n_qubits=info['n_qubits'],\n",
    "                n_observables=N_POSTHOC_OBSERVABLES,\n",
    "                seed=1042,  # Different seed to avoid overlap with stress\n",
    "            )\n",
    "\n",
    "# Check for posthoc/stress redundancy: skip posthoc if it has same or fewer observables than stress\n",
    "posthoc_skipped = []\n",
    "if SUITES_TO_RUN.get('stress') and SUITES_TO_RUN.get('posthoc'):\n",
    "    for cid, info in circuits.items():\n",
    "        stress_keys = [k for k in info['suites'] if 'stress' in k]\n",
    "        posthoc_keys = [k for k in info['suites'] if 'posthoc' in k]\n",
    "        \n",
    "        if stress_keys and posthoc_keys:\n",
    "            # Get actual observable counts\n",
    "            stress_obs = max(info['suites'][k].n_observables for k in stress_keys)\n",
    "            posthoc_obs = max(info['suites'][k].n_observables for k in posthoc_keys)\n",
    "            \n",
    "            # If posthoc has same or fewer observables than stress, it's redundant\n",
    "            if posthoc_obs <= stress_obs:\n",
    "                for key in posthoc_keys:\n",
    "                    del info['suites'][key]\n",
    "                    posthoc_skipped.append((cid, key, stress_obs, posthoc_obs))\n",
    "\n",
    "# =============================================================================\n",
    "# MERGE SUITES TO AVOID REDUNDANT SAMPLING\n",
    "# =============================================================================\n",
    "# When multiple suites are enabled for a circuit, merge them into one set\n",
    "# to sample the circuit only once. Results are tagged by source suite.\n",
    "\n",
    "merge_enabled = True  # Set to False to disable merging (run suites separately)\n",
    "\n",
    "for cid, info in circuits.items():\n",
    "    if merge_enabled and len(info['suites']) > 1:\n",
    "        # Merge all suites for this circuit\n",
    "        merged_set, suite_mapping = merge_suites_for_circuit(info['suites'], cid)\n",
    "        \n",
    "        # Store merge info\n",
    "        info['merged'] = True\n",
    "        info['merged_observable_set'] = merged_set\n",
    "        info['suite_mapping'] = suite_mapping  # observable_id -> [suite_names]\n",
    "        info['original_suite_obs_counts'] = {\n",
    "            name: suite.n_observables for name, suite in info['suites'].items()\n",
    "        }\n",
    "        \n",
    "        # Count overlapping observables\n",
    "        total_original = sum(info['original_suite_obs_counts'].values())\n",
    "        merged_count = len(merged_set.observables)\n",
    "        info['overlap_count'] = total_original - merged_count\n",
    "    else:\n",
    "        info['merged'] = False\n",
    "\n",
    "# Display what was built\n",
    "print(f\"\\nBuilt {len(circuits)} circuits:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show redundancy warnings\n",
    "if posthoc_skipped:\n",
    "    print(\"\\nâš  POSTHOC SUITES SKIPPED (redundant with stress - same or fewer observables):\")\n",
    "    for cid, key, stress_obs, posthoc_obs in posthoc_skipped:\n",
    "        print(f\"  â€¢ {cid}/{key}: posthoc has {posthoc_obs} obs <= stress has {stress_obs} obs\")\n",
    "    print(\"  To run posthoc, increase N_POSTHOC_OBSERVABLES or decrease N_STRESS_OBSERVABLES\")\n",
    "    print()\n",
    "\n",
    "total_benchmarks = 0\n",
    "total_original_obs = 0\n",
    "total_merged_obs = 0\n",
    "\n",
    "for cid, info in circuits.items():\n",
    "    print(f\"\\n{cid} ({info['n_qubits']} qubits):\")\n",
    "    \n",
    "    for suite_name, suite in info['suites'].items():\n",
    "        comm = suite.commutation_analysis()\n",
    "        comm_str = \"COMMUTING\" if comm['fully_commuting'] else f\"{comm['n_commuting_groups']} groups\"\n",
    "        obj_str = \"[weighted]\" if suite.objective == ObjectiveType.WEIGHTED_SUM else \"\"\n",
    "        print(f\"  â€¢ {suite_name:30s} {suite.n_observables:4d} obs  {comm_str:15s} {obj_str}\")\n",
    "        total_original_obs += suite.n_observables\n",
    "    \n",
    "    if info.get('merged'):\n",
    "        merged_count = len(info['merged_observable_set'].observables)\n",
    "        overlap = info['overlap_count']\n",
    "        total_merged_obs += merged_count\n",
    "        print(f\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "        print(f\"  âœ“ MERGED: {merged_count} unique obs (saved {overlap} redundant)\")\n",
    "        total_benchmarks += 1  # Only one benchmark run for merged\n",
    "    else:\n",
    "        total_benchmarks += len(info['suites'])\n",
    "        total_merged_obs += sum(s.n_observables for s in info['suites'].values())\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"TOTAL: {total_benchmarks} benchmark runs\")\n",
    "if total_original_obs > total_merged_obs:\n",
    "    saved = total_original_obs - total_merged_obs\n",
    "    pct = 100 * saved / total_original_obs\n",
    "    print(f\"EFFICIENCY: {total_merged_obs} unique obs from {total_original_obs} total ({saved} redundant, {pct:.0f}% saved)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Run Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "run-benchmarks",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:30:06.133289Z",
     "iopub.status.busy": "2026-02-27T14:30:06.132448Z",
     "iopub.status.idle": "2026-02-27T14:31:09.319274Z",
     "shell.execute_reply": "2026-02-27T14:31:09.312535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BENCHMARK 1/1: S-BELL-2 (MERGED)\n",
      "  Circuit: S-BELL-2 (4q)\n",
      "  Merged suites: workload_pair_correlations, diagnostics_single_qubit, diagnostics_cross_pair, stress_random_1000\n",
      "  Total unique observables: 90\n",
      "  Overlap saved: 8 redundant obs\n",
      "================================================================================\n",
      "======================================================================\n",
      "BENCHMARK SUITE: ANALYSIS\n",
      "======================================================================\n",
      "Run ID: S-BELL-2__merged_20260227_143006_39bb9b0a\n",
      "Output: benchmark_results\\S-BELL-2__merged_20260227_143006_39bb9b0a\n",
      "Mode: analysis\n",
      "\n",
      "Step 1: Running base benchmark...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\_core\\_methods.py:190: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\lib\\_function_base_impl.py:4671: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\lib\\_function_base_impl.py:4671: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed: 2700 rows\n",
      "\n",
      "Step 2: Running all 8 tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\_core\\_methods.py:190: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\lib\\_function_base_impl.py:4671: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed: 12 task evaluations\n",
      "\n",
      "Step 3: Running comprehensive analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\lib\\_function_base_impl.py:2908: RuntimeWarning: invalid value encountered in subtract\n",
      "  X -= avg[:, None]\n",
      "C:\\Users\\User\\Dropbox\\QuartumSE\\quartumse-internal\\notebooks\\../src\\quartumse\\analysis\\observable_properties.py:197: RuntimeWarning: invalid value encountered in subtract\n",
      "  b = np.sum((X - X_mean) * (y - y_mean)) / np.sum((X - X_mean) ** 2)\n",
      "C:\\Users\\User\\Dropbox\\QuartumSE\\quartumse-internal\\notebooks\\../src\\quartumse\\analysis\\statistical_tests.py:210: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  null_diffs[i] = statistic(perm_a) - statistic(perm_b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Comprehensive analysis complete\n",
      "\n",
      "Step 4: Generating reports...\n",
      "  Basic report: benchmark_results\\S-BELL-2__merged_20260227_143006_39bb9b0a\\basic_report.md\n",
      "  Complete report: benchmark_results\\S-BELL-2__merged_20260227_143006_39bb9b0a\\complete_report.md\n",
      "  Analysis report: benchmark_results\\S-BELL-2__merged_20260227_143006_39bb9b0a\\analysis_report.md\n",
      "  Analysis JSON: benchmark_results\\S-BELL-2__merged_20260227_143006_39bb9b0a\\analysis.json\n",
      "\n",
      "======================================================================\n",
      "BENCHMARK COMPLETE\n",
      "======================================================================\n",
      "Output directory: benchmark_results\\S-BELL-2__merged_20260227_143006_39bb9b0a\n",
      "Reports generated: ['basic', 'complete', 'analysis', 'analysis_json', 'config', 'manifest']\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ALL BENCHMARKS COMPLETE: 1 runs\n",
      "(Suite merging enabled - results will be split by suite in analysis)\n",
      "================================================================================\n",
      "CPU times: total: 1min\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# =============================================================================\n",
    "# RUN ALL BENCHMARKS (with suite merging optimization)\n",
    "# =============================================================================\n",
    "# When merge_enabled=True, we run ONE benchmark per circuit with all observables,\n",
    "# then split results by suite tags. This avoids redundant circuit sampling.\n",
    "\n",
    "all_results = {}  # Keyed by (circuit_id, suite_name) or circuit_id for merged\n",
    "\n",
    "run_count = 0\n",
    "total_runs = sum(1 if info.get('merged') else len(info['suites']) for info in circuits.values())\n",
    "\n",
    "for cid, info in circuits.items():\n",
    "    \n",
    "    if info.get('merged'):\n",
    "        # === MERGED MODE: Run once with all observables ===\n",
    "        run_count += 1\n",
    "        merged_set = info['merged_observable_set']\n",
    "        suite_names = list(info['suites'].keys())\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"BENCHMARK {run_count}/{total_runs}: {cid} (MERGED)\")\n",
    "        print(f\"  Circuit: {cid} ({info['n_qubits']}q)\")\n",
    "        print(f\"  Merged suites: {', '.join(suite_names)}\")\n",
    "        print(f\"  Total unique observables: {len(merged_set.observables)}\")\n",
    "        print(f\"  Overlap saved: {info['overlap_count']} redundant obs\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Build locality map from merged observables\n",
    "        loc_map = {obs.observable_id: obs.locality for obs in merged_set.observables}\n",
    "        \n",
    "        # Run benchmark ONCE with merged observable set\n",
    "        result = run_benchmark_suite(\n",
    "            circuit=info['circuit'],\n",
    "            observable_set=merged_set,\n",
    "            circuit_id=f\"{cid}__merged\",\n",
    "            config=CONFIG,\n",
    "            locality_map=loc_map,\n",
    "        )\n",
    "        \n",
    "        # Store the merged result with suite metadata for later splitting\n",
    "        all_results[f\"{cid}__merged\"] = {\n",
    "            'result': result,\n",
    "            'circuit_id': cid,\n",
    "            'suite_name': '_merged_',\n",
    "            'suites': info['suites'],  # Original suites for analysis\n",
    "            'suite_mapping': info['suite_mapping'],  # obs_id -> [suite_names]\n",
    "            'n_qubits': info['n_qubits'],\n",
    "            'merged': True,\n",
    "        }\n",
    "        \n",
    "    else:\n",
    "        # === NON-MERGED MODE: Run each suite separately (single suite or merge disabled) ===\n",
    "        for suite_name, suite in info['suites'].items():\n",
    "            run_count += 1\n",
    "            run_key = f\"{cid}__{suite_name}\"\n",
    "            \n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"BENCHMARK {run_count}/{total_runs}: {cid} / {suite_name}\")\n",
    "            print(f\"  Circuit: {cid} ({info['n_qubits']}q)\")\n",
    "            print(f\"  Suite: {suite_name} ({suite.n_observables} observables)\")\n",
    "            print(f\"  Type: {suite.suite_type.value}, Objective: {suite.objective.value}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            # Build locality map from suite\n",
    "            loc_map = {obs.observable_id: obs.locality for obs in suite.observables}\n",
    "            \n",
    "            # Run benchmark\n",
    "            result = run_benchmark_suite(\n",
    "                circuit=info['circuit'],\n",
    "                observable_set=suite.observable_set,\n",
    "                circuit_id=run_key,\n",
    "                config=CONFIG,\n",
    "                locality_map=loc_map,\n",
    "            )\n",
    "            \n",
    "            # Store result with suite metadata\n",
    "            all_results[run_key] = {\n",
    "                'result': result,\n",
    "                'circuit_id': cid,\n",
    "                'suite_name': suite_name,\n",
    "                'suite': suite,\n",
    "                'n_qubits': info['n_qubits'],\n",
    "                'merged': False,\n",
    "            }\n",
    "\n",
    "print(f\"\\n\\n{'='*80}\")\n",
    "print(f\"ALL BENCHMARKS COMPLETE: {len(all_results)} runs\")\n",
    "if any(r.get('merged') for r in all_results.values()):\n",
    "    print(\"(Suite merging enabled - results will be split by suite in analysis)\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efc06118",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:31:09.338867Z",
     "iopub.status.busy": "2026-02-27T14:31:09.334419Z",
     "iopub.status.idle": "2026-02-27T14:33:58.752988Z",
     "shell.execute_reply": "2026-02-27T14:33:58.749958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running noise sweep with profiles: ['ideal', 'readout_1e-2', 'depol_low']\n",
      "\n",
      "\n",
      "================================================================================\n",
      "NOISE PROFILE: ideal\n",
      "================================================================================\n",
      "\n",
      "  Running S-BELL-2 with ideal...\n",
      "======================================================================\n",
      "BENCHMARK SUITE: ANALYSIS\n",
      "======================================================================\n",
      "Run ID: S-BELL-2__ideal_20260227_143109_e731fe2c\n",
      "Output: benchmark_results_noise\\ideal\\S-BELL-2__ideal_20260227_143109_e731fe2c\n",
      "Mode: analysis\n",
      "\n",
      "Step 1: Running base benchmark...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\lib\\_function_base_impl.py:4671: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed: 2700 rows\n",
      "\n",
      "Step 2: Running all 8 tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\_core\\_methods.py:190: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\lib\\_function_base_impl.py:4671: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed: 12 task evaluations\n",
      "\n",
      "Step 3: Running comprehensive analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\lib\\_function_base_impl.py:2908: RuntimeWarning: invalid value encountered in subtract\n",
      "  X -= avg[:, None]\n",
      "C:\\Users\\User\\Dropbox\\QuartumSE\\quartumse-internal\\notebooks\\../src\\quartumse\\analysis\\observable_properties.py:197: RuntimeWarning: invalid value encountered in subtract\n",
      "  b = np.sum((X - X_mean) * (y - y_mean)) / np.sum((X - X_mean) ** 2)\n",
      "C:\\Users\\User\\Dropbox\\QuartumSE\\quartumse-internal\\notebooks\\../src\\quartumse\\analysis\\statistical_tests.py:210: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  null_diffs[i] = statistic(perm_a) - statistic(perm_b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Comprehensive analysis complete\n",
      "\n",
      "Step 4: Generating reports...\n",
      "  Basic report: benchmark_results_noise\\ideal\\S-BELL-2__ideal_20260227_143109_e731fe2c\\basic_report.md\n",
      "  Complete report: benchmark_results_noise\\ideal\\S-BELL-2__ideal_20260227_143109_e731fe2c\\complete_report.md\n",
      "  Analysis report: benchmark_results_noise\\ideal\\S-BELL-2__ideal_20260227_143109_e731fe2c\\analysis_report.md\n",
      "  Analysis JSON: benchmark_results_noise\\ideal\\S-BELL-2__ideal_20260227_143109_e731fe2c\\analysis.json\n",
      "\n",
      "======================================================================\n",
      "BENCHMARK COMPLETE\n",
      "======================================================================\n",
      "Output directory: benchmark_results_noise\\ideal\\S-BELL-2__ideal_20260227_143109_e731fe2c\n",
      "Reports generated: ['basic', 'complete', 'analysis', 'analysis_json', 'config', 'manifest']\n",
      "\n",
      "\n",
      "================================================================================\n",
      "NOISE PROFILE: readout_1e-2\n",
      "================================================================================\n",
      "\n",
      "  Running S-BELL-2 with readout_1e-2...\n",
      "======================================================================\n",
      "BENCHMARK SUITE: ANALYSIS\n",
      "======================================================================\n",
      "Run ID: S-BELL-2__readout_1e-2_20260227_143225_9c7c9b9d\n",
      "Output: benchmark_results_noise\\readout_1e-2\\S-BELL-2__readout_1e-2_20260227_143225_9c7c9b9d\n",
      "Mode: analysis\n",
      "\n",
      "Step 1: Running base benchmark (noise: readout_1e-2)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\lib\\_function_base_impl.py:4671: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed: 2700 rows\n",
      "\n",
      "Step 2: Running all 8 tasks...\n",
      "  Completed: 12 task evaluations\n",
      "\n",
      "Step 3: Running comprehensive analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\_core\\_methods.py:190: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\lib\\_function_base_impl.py:4671: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\lib\\_function_base_impl.py:2908: RuntimeWarning: invalid value encountered in subtract\n",
      "  X -= avg[:, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Dropbox\\QuartumSE\\quartumse-internal\\notebooks\\../src\\quartumse\\analysis\\observable_properties.py:197: RuntimeWarning: invalid value encountered in subtract\n",
      "  b = np.sum((X - X_mean) * (y - y_mean)) / np.sum((X - X_mean) ** 2)\n",
      "C:\\Users\\User\\Dropbox\\QuartumSE\\quartumse-internal\\notebooks\\../src\\quartumse\\analysis\\statistical_tests.py:210: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  null_diffs[i] = statistic(perm_a) - statistic(perm_b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Comprehensive analysis complete\n",
      "\n",
      "Step 4: Generating reports...\n",
      "  Basic report: benchmark_results_noise\\readout_1e-2\\S-BELL-2__readout_1e-2_20260227_143225_9c7c9b9d\\basic_report.md\n",
      "  Complete report: benchmark_results_noise\\readout_1e-2\\S-BELL-2__readout_1e-2_20260227_143225_9c7c9b9d\\complete_report.md\n",
      "  Analysis report: benchmark_results_noise\\readout_1e-2\\S-BELL-2__readout_1e-2_20260227_143225_9c7c9b9d\\analysis_report.md\n",
      "  Analysis JSON: benchmark_results_noise\\readout_1e-2\\S-BELL-2__readout_1e-2_20260227_143225_9c7c9b9d\\analysis.json\n",
      "\n",
      "======================================================================\n",
      "BENCHMARK COMPLETE\n",
      "======================================================================\n",
      "Output directory: benchmark_results_noise\\readout_1e-2\\S-BELL-2__readout_1e-2_20260227_143225_9c7c9b9d\n",
      "Reports generated: ['basic', 'complete', 'analysis', 'analysis_json', 'config', 'manifest']\n",
      "\n",
      "\n",
      "================================================================================\n",
      "NOISE PROFILE: depol_low\n",
      "================================================================================\n",
      "\n",
      "  Running S-BELL-2 with depol_low...\n",
      "======================================================================\n",
      "BENCHMARK SUITE: ANALYSIS\n",
      "======================================================================\n",
      "Run ID: S-BELL-2__depol_low_20260227_143315_10593e6a\n",
      "Output: benchmark_results_noise\\depol_low\\S-BELL-2__depol_low_20260227_143315_10593e6a\n",
      "Mode: analysis\n",
      "\n",
      "Step 1: Running base benchmark (noise: depol_low)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\lib\\_function_base_impl.py:4671: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed: 2700 rows\n",
      "\n",
      "Step 2: Running all 8 tasks...\n",
      "  Completed: 12 task evaluations\n",
      "\n",
      "Step 3: Running comprehensive analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\_core\\_methods.py:190: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\lib\\_function_base_impl.py:4671: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\numpy\\lib\\_function_base_impl.py:2908: RuntimeWarning: invalid value encountered in subtract\n",
      "  X -= avg[:, None]\n",
      "C:\\Users\\User\\Dropbox\\QuartumSE\\quartumse-internal\\notebooks\\../src\\quartumse\\analysis\\observable_properties.py:197: RuntimeWarning: invalid value encountered in subtract\n",
      "  b = np.sum((X - X_mean) * (y - y_mean)) / np.sum((X - X_mean) ** 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Dropbox\\QuartumSE\\quartumse-internal\\notebooks\\../src\\quartumse\\analysis\\statistical_tests.py:210: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  null_diffs[i] = statistic(perm_a) - statistic(perm_b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Comprehensive analysis complete\n",
      "\n",
      "Step 4: Generating reports...\n",
      "  Basic report: benchmark_results_noise\\depol_low\\S-BELL-2__depol_low_20260227_143315_10593e6a\\basic_report.md\n",
      "  Complete report: benchmark_results_noise\\depol_low\\S-BELL-2__depol_low_20260227_143315_10593e6a\\complete_report.md\n",
      "  Analysis report: benchmark_results_noise\\depol_low\\S-BELL-2__depol_low_20260227_143315_10593e6a\\analysis_report.md\n",
      "  Analysis JSON: benchmark_results_noise\\depol_low\\S-BELL-2__depol_low_20260227_143315_10593e6a\\analysis.json\n",
      "\n",
      "======================================================================\n",
      "BENCHMARK COMPLETE\n",
      "======================================================================\n",
      "Output directory: benchmark_results_noise\\depol_low\\S-BELL-2__depol_low_20260227_143315_10593e6a\n",
      "Reports generated: ['basic', 'complete', 'analysis', 'analysis_json', 'config', 'manifest']\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "NOISE SWEEP COMPLETE: 3 runs\n",
      "================================================================================\n",
      "CPU times: total: 2min 48s\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# =============================================================================\n",
    "# NOISE SWEEP (Task 7: Noise Sensitivity Analysis)\n",
    "# =============================================================================\n",
    "# Run the same benchmark with different noise profiles to analyze sensitivity\n",
    "\n",
    "noise_results = {}  # Store results for each noise profile\n",
    "\n",
    "if RUN_NOISE_SWEEP:\n",
    "    print(f\"Running noise sweep with profiles: {NOISE_PROFILES}\")\n",
    "    print()\n",
    "    \n",
    "    for noise_profile in NOISE_PROFILES:\n",
    "        print()\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"NOISE PROFILE: {noise_profile}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Create config with noise profile (inherits timeout + hw profile)\n",
    "        noise_config = BenchmarkSuiteConfig(\n",
    "            mode=BenchmarkMode.ANALYSIS,\n",
    "            n_shots_grid=CONFIG.n_shots_grid,\n",
    "            n_replicates=CONFIG.n_replicates,\n",
    "            seed=CONFIG.seed,\n",
    "            epsilon=CONFIG.epsilon,\n",
    "            delta=CONFIG.delta,\n",
    "            shadows_protocol_id=CONFIG.shadows_protocol_id,\n",
    "            baseline_protocol_id=CONFIG.baseline_protocol_id,\n",
    "            output_base_dir=f\"benchmark_results_noise/{noise_profile}\",\n",
    "            noise_profile=noise_profile if noise_profile != 'ideal' else None,\n",
    "            timeout_per_protocol_s=TIMEOUT_PER_PROTOCOL_S,\n",
    "            hw_timing_profile=HW_TIMING_PROFILE,\n",
    "        )\n",
    "        \n",
    "        # Run for each circuit\n",
    "        for cid, info in circuits.items():\n",
    "            if info.get('merged'):\n",
    "                merged_set = info['merged_observable_set']\n",
    "                loc_map = {obs.observable_id: obs.locality for obs in merged_set.observables}\n",
    "                \n",
    "                print()\n",
    "                print(f\"  Running {cid} with {noise_profile}...\")\n",
    "                \n",
    "                result = run_benchmark_suite(\n",
    "                    circuit=info['circuit'],\n",
    "                    observable_set=merged_set,\n",
    "                    circuit_id=f\"{cid}__{noise_profile}\",\n",
    "                    config=noise_config,\n",
    "                    locality_map=loc_map,\n",
    "                )\n",
    "                \n",
    "                noise_results[f\"{cid}__{noise_profile}\"] = {\n",
    "                    'result': result,\n",
    "                    'circuit_id': cid,\n",
    "                    'noise_profile': noise_profile,\n",
    "                    'n_qubits': info['n_qubits'],\n",
    "                }\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"NOISE SWEEP COMPLETE: {len(noise_results)} runs\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"Noise sweep disabled (RUN_NOISE_SWEEP = False)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Complete Results Analysis\n",
    "\n",
    "This section displays ALL analysis features from the enhanced benchmarking system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "task-summary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:33:58.791039Z",
     "iopub.status.busy": "2026-02-27T14:33:58.790574Z",
     "iopub.status.idle": "2026-02-27T14:33:58.905025Z",
     "shell.execute_reply": "2026-02-27T14:33:58.902332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "S-BELL-2 (MERGED RUN - splitting results by suite)\n",
      "====================================================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "S-BELL-2__workload_pair_correlations\n",
      "  4q, 6 obs, workload \n",
      "  Commutation: 3 groups\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Task   Question                                                  shadows                  grouped                optimized\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "1      Worst-case N* (max SE <= eps)?                           N*>10000                 N*>10000                 N*>10000\n",
      "2      Average N* (mean SE <= eps)?                             N*>10000                 N*>10000                 N*>10000\n",
      "3      SE distribution at max N?               \n",
      "......   mean                                                     0.1432                      inf                      inf\n",
      "......   median                                                   0.1429                   0.0000                   0.0000\n",
      "......   max                                                      0.2303                      inf                      inf\n",
      "4      Dominance (wins)?                                        0/6 (0%)               6/6 (100%)                 0/6 (0%)\n",
      "......   WINNER:                                direct_grouped\n",
      "5      Optimal pilot fraction?                  N/A\n",
      "6      Bias-variance decomposition?            \n",
      "......   bias2                                                  0.001724                 0.273333                 0.273333\n",
      "......   var                                                    0.018167                 0.060000                 0.060000\n",
      "......   mse                                                    0.019890                 0.333333                 0.333333\n",
      "7      Noise sensitivity?                       See noise analysis\n",
      "8      Adaptive efficiency?                     See Task 5 pilot analysis\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "S-BELL-2__diagnostics_single_qubit\n",
      "  4q, 4 obs, diagnostic \n",
      "  Commutation: FULLY COMMUTING\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Task   Question                                                  shadows                  grouped                optimized\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "1      Worst-case N* (max SE <= eps)?                           N*>10000                 N*>10000                 N*>10000\n",
      "2      Average N* (mean SE <= eps)?                             N*>10000                 N*>10000                 N*>10000\n",
      "3      SE distribution at max N?               \n",
      "......   mean                                                     0.0872                      inf                      inf\n",
      "......   median                                                   0.0863                      inf                      inf\n",
      "......   max                                                      0.1218                      inf                      inf\n",
      "4      Dominance (wins)?                                        0/4 (0%)                 0/4 (0%)               4/4 (100%)\n",
      "......   WINNER:                                direct_optimized\n",
      "5      Optimal pilot fraction?                  N/A\n",
      "6      Bias-variance decomposition?            \n",
      "......   bias2                                                  0.000704                 0.000033                 0.000024\n",
      "......   var                                                    0.005161                 0.000299                 0.000214\n",
      "......   mse                                                    0.005865                 0.000332                 0.000238\n",
      "7      Noise sensitivity?                       See noise analysis\n",
      "8      Adaptive efficiency?                     See Task 5 pilot analysis\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "S-BELL-2__diagnostics_cross_pair\n",
      "  4q, 1 obs, diagnostic \n",
      "  Commutation: FULLY COMMUTING\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Task   Question                                                  shadows                  grouped                optimized\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "1      Worst-case N* (max SE <= eps)?                           N*>10000                 N*>10000                 N*>10000\n",
      "2      Average N* (mean SE <= eps)?                             N*>10000                 N*>10000                 N*>10000\n",
      "3      SE distribution at max N?               \n",
      "......   mean                                                     0.1508                      inf                      inf\n",
      "......   median                                                   0.1506                      inf                      inf\n",
      "......   max                                                      0.1853                      inf                      inf\n",
      "4      Dominance (wins)?                                        0/1 (0%)                 0/1 (0%)               1/1 (100%)\n",
      "......   WINNER:                                direct_optimized\n",
      "5      Optimal pilot fraction?                  N/A\n",
      "6      Bias-variance decomposition?            \n",
      "......   bias2                                                  0.000142                 0.000001                 0.000025\n",
      "......   var                                                    0.019068                 0.000009                 0.000223\n",
      "......   mse                                                    0.019210                 0.000010                 0.000248\n",
      "7      Noise sensitivity?                       See noise analysis\n",
      "8      Adaptive efficiency?                     See Task 5 pilot analysis\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "S-BELL-2__stress_random_1000\n",
      "  4q, 87 obs, stress \n",
      "  Commutation: 32 groups\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Task   Question                                                  shadows                  grouped                optimized\n",
      "--------------------------------------------------------------------------------------------------------------------------\n",
      "1      Worst-case N* (max SE <= eps)?                           N*>10000                 N*>10000                 N*>10000\n",
      "2      Average N* (mean SE <= eps)?                             N*>10000                 N*>10000                 N*>10000\n",
      "3      SE distribution at max N?               \n",
      "......   mean                                                     0.2565                      inf                      inf\n",
      "......   median                                                   0.2222                      inf                      inf\n",
      "......   max                                                      0.9904                      inf                      inf\n",
      "4      Dominance (wins)?                                     62/87 (71%)                3/87 (3%)              22/87 (25%)\n",
      "......   WINNER:                                classical_shadows_v0\n",
      "5      Optimal pilot fraction?                  N/A\n",
      "6      Bias-variance decomposition?            \n",
      "......   bias2                                                  0.006527                 0.023259                 0.023266\n",
      "......   var                                                    0.078863                 0.002443                 0.002355\n",
      "......   mse                                                    0.085389                 0.025702                 0.025622\n",
      "7      Noise sensitivity?                       See noise analysis\n",
      "8      Adaptive efficiency?                     See Task 5 pilot analysis\n",
      "--------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TASK SUMMARY FOR EACH (Circuit, Suite) PAIR (All 8 Measurements Bible Tasks)\n",
    "# =============================================================================\n",
    "\n",
    "def filter_results_by_suite(long_form_results, suite_mapping, target_suite):\n",
    "    \"\"\"Filter long-form results to only include observables belonging to a specific suite.\"\"\"\n",
    "    # Get observable IDs that belong to this suite\n",
    "    suite_obs_ids = {\n",
    "        obs_id for obs_id, suites in suite_mapping.items() \n",
    "        if target_suite in suites\n",
    "    }\n",
    "    return [r for r in long_form_results if r.observable_id in suite_obs_ids]\n",
    "\n",
    "def compute_full_task_summary(long_form, truth, config, n_observables):\n",
    "    \"\"\"Compute all 8 task answers for a given set of results.\"\"\"\n",
    "    max_n = max(config.n_shots_grid)\n",
    "    eps = config.epsilon\n",
    "    \n",
    "    # Group by protocol and N\n",
    "    by_pn = defaultdict(lambda: defaultdict(list))\n",
    "    for row in long_form:\n",
    "        by_pn[row.protocol_id][row.N_total].append(row)\n",
    "    protocols = sorted(by_pn.keys())\n",
    "    \n",
    "    tasks = {}\n",
    "    \n",
    "    # Task 1: Worst-case N*\n",
    "    tasks['1'] = {}\n",
    "    for p in protocols:\n",
    "        n_star = None\n",
    "        for n in sorted(by_pn[p].keys()):\n",
    "            ses = [r.se for r in by_pn[p][n] if r.se is not None]\n",
    "            if ses:\n",
    "                max_se = max(ses)\n",
    "                if max_se <= eps:\n",
    "                    n_star = n\n",
    "                    break\n",
    "        tasks['1'][p] = f\"N*={n_star}\" if n_star else f\"N*>{max_n}\"\n",
    "    \n",
    "    # Task 2: Average N*\n",
    "    tasks['2'] = {}\n",
    "    for p in protocols:\n",
    "        n_star = None\n",
    "        for n in sorted(by_pn[p].keys()):\n",
    "            ses = [r.se for r in by_pn[p][n] if r.se is not None]\n",
    "            if ses:\n",
    "                mean_se = np.mean(ses)\n",
    "                if mean_se <= eps:\n",
    "                    n_star = n\n",
    "                    break\n",
    "        tasks['2'][p] = f\"N*={n_star}\" if n_star else f\"N*>{max_n}\"\n",
    "    \n",
    "    # Task 3: SE distribution at max N\n",
    "    tasks['3'] = {}\n",
    "    for p in protocols:\n",
    "        ses = [r.se for r in by_pn[p][max_n] if r.se is not None]\n",
    "        if ses:\n",
    "            tasks['3'][p] = {'mean': np.mean(ses), 'median': np.median(ses), 'max': np.max(ses)}\n",
    "        else:\n",
    "            tasks['3'][p] = {'mean': float('nan'), 'median': float('nan'), 'max': float('nan')}\n",
    "    \n",
    "    # Task 4: Dominance\n",
    "    obs_best = {}\n",
    "    for p in protocols:\n",
    "        for r in by_pn[p][max_n]:\n",
    "            if r.observable_id not in obs_best or (r.se is not None and r.se < obs_best[r.observable_id][1]):\n",
    "                obs_best[r.observable_id] = (p, r.se if r.se is not None else float('inf'))\n",
    "    wins = defaultdict(int)\n",
    "    for oid, (p, _) in obs_best.items():\n",
    "        wins[p] += 1\n",
    "    total = len(obs_best) if obs_best else 1\n",
    "    tasks['4'] = {p: f\"{wins[p]}/{total} ({100*wins[p]/total:.0f}%)\" for p in protocols}\n",
    "    tasks['4']['winner'] = max(wins, key=wins.get) if wins else \"N/A\"\n",
    "    \n",
    "    # Task 5: Pilot selection (placeholder - requires analysis object)\n",
    "    tasks['5'] = \"N/A\"\n",
    "    \n",
    "    # Task 6: Bias-variance\n",
    "    tasks['6'] = {}\n",
    "    if truth:\n",
    "        for p in protocols:\n",
    "            by_obs = defaultdict(list)\n",
    "            for r in by_pn[p][max_n]:\n",
    "                if r.observable_id in truth:\n",
    "                    by_obs[r.observable_id].append(r.estimate)\n",
    "            biases_sq, vars_ = [], []\n",
    "            for oid, ests in by_obs.items():\n",
    "                if ests:\n",
    "                    biases_sq.append((np.mean(ests) - truth[oid])**2)\n",
    "                    vars_.append(np.var(ests))\n",
    "            if biases_sq:\n",
    "                tasks['6'][p] = {'bias2': np.mean(biases_sq), 'var': np.mean(vars_),\n",
    "                                 'mse': np.mean(biases_sq) + np.mean(vars_)}\n",
    "    \n",
    "    # Task 7: Noise sensitivity (placeholder)\n",
    "    tasks['7'] = \"Requires noise sweep\" if not RUN_NOISE_SWEEP else \"See noise analysis\"\n",
    "    \n",
    "    # Task 8: Adaptive efficiency (placeholder)\n",
    "    tasks['8'] = \"See Task 5 pilot analysis\"\n",
    "    \n",
    "    return tasks, protocols\n",
    "\n",
    "def display_task_summary(run_key, tasks, protocols, suite_info):\n",
    "    \"\"\"Display formatted task summary.\"\"\"\n",
    "    col_w = 24\n",
    "    hdr = f\"{'Task':<6} {'Question':<40}\"\n",
    "    for p in protocols:\n",
    "        short = p.replace('classical_shadows_v0', 'shadows').replace('direct_', '')\n",
    "        hdr += f\" {short:>{col_w}}\"\n",
    "    print(hdr)\n",
    "    print(\"-\" * len(hdr))\n",
    "    \n",
    "    # Task 1\n",
    "    row = f\"{'1':<6} {'Worst-case N* (max SE <= eps)?':<40}\"\n",
    "    for p in protocols: row += f\" {tasks['1'][p]:>{col_w}}\"\n",
    "    print(row)\n",
    "    \n",
    "    # Task 2\n",
    "    row = f\"{'2':<6} {'Average N* (mean SE <= eps)?':<40}\"\n",
    "    for p in protocols: row += f\" {tasks['2'][p]:>{col_w}}\"\n",
    "    print(row)\n",
    "    \n",
    "    # Task 3\n",
    "    print(f\"{'3':<6} {'SE distribution at max N?':<40}\")\n",
    "    for m in ['mean', 'median', 'max']:\n",
    "        row = f\"{'':.<6} {'  ' + m:<40}\"\n",
    "        for p in protocols: row += f\" {tasks['3'][p][m]:>{col_w}.4f}\"\n",
    "        print(row)\n",
    "    \n",
    "    # Task 4\n",
    "    row = f\"{'4':<6} {'Dominance (wins)?':<40}\"\n",
    "    for p in protocols: row += f\" {tasks['4'][p]:>{col_w}}\"\n",
    "    print(row)\n",
    "    print(f\"{'':.<6} {'  WINNER:':<40} {tasks['4']['winner']}\")\n",
    "    \n",
    "    # Task 5\n",
    "    print(f\"{'5':<6} {'Optimal pilot fraction?':<40} {tasks['5']}\")\n",
    "    \n",
    "    # Task 6\n",
    "    if tasks['6']:\n",
    "        print(f\"{'6':<6} {'Bias-variance decomposition?':<40}\")\n",
    "        for m in ['bias2', 'var', 'mse']:\n",
    "            row = f\"{'':.<6} {'  ' + m:<40}\"\n",
    "            for p in protocols:\n",
    "                if p in tasks['6']:\n",
    "                    row += f\" {tasks['6'][p][m]:>{col_w}.6f}\"\n",
    "                else:\n",
    "                    row += f\" {'N/A':>{col_w}}\"\n",
    "            print(row)\n",
    "    else:\n",
    "        print(f\"{'6':<6} {'Bias-variance?':<40} (requires ground truth)\")\n",
    "    \n",
    "    # Task 7 & 8\n",
    "    print(f\"{'7':<6} {'Noise sensitivity?':<40} {tasks['7']}\")\n",
    "    print(f\"{'8':<6} {'Adaptive efficiency?':<40} {tasks['8']}\")\n",
    "    print(\"-\" * len(hdr))\n",
    "\n",
    "# Process results (handling both merged and non-merged)\n",
    "for run_key, run_data in all_results.items():\n",
    "    bench_result = run_data['result']\n",
    "    cid = run_data['circuit_id']\n",
    "    n_qubits = run_data['n_qubits']\n",
    "    truth = bench_result.ground_truth.truth_values if bench_result.ground_truth else {}\n",
    "    \n",
    "    if run_data.get('merged'):\n",
    "        # === MERGED RESULTS: Split by suite and display each ===\n",
    "        suite_mapping = run_data['suite_mapping']\n",
    "        suites = run_data['suites']\n",
    "        \n",
    "        print(f\"\\n{'='*100}\")\n",
    "        print(f\"{cid} (MERGED RUN - splitting results by suite)\")\n",
    "        print(f\"{'='*100}\")\n",
    "        \n",
    "        for suite_name, suite in suites.items():\n",
    "            # Filter results for this suite\n",
    "            suite_results = filter_results_by_suite(\n",
    "                bench_result.long_form_results, \n",
    "                suite_mapping, \n",
    "                suite_name\n",
    "            )\n",
    "            \n",
    "            if not suite_results:\n",
    "                print(f\"\\n--- {suite_name}: No results (0 obs) ---\")\n",
    "                continue\n",
    "            \n",
    "            # Get suite metadata\n",
    "            comm = suite.commutation_analysis()\n",
    "            comm_str = \"FULLY COMMUTING\" if comm['fully_commuting'] else f\"{comm['n_commuting_groups']} groups\"\n",
    "            obj_str = f\"[{suite.objective.value}]\" if suite.objective != ObjectiveType.PER_OBSERVABLE else \"\"\n",
    "            \n",
    "            print(f\"\\n{'â”€'*100}\")\n",
    "            print(f\"{cid}__{suite_name}\")\n",
    "            print(f\"  {n_qubits}q, {suite.n_observables} obs, {suite.suite_type.value} {obj_str}\")\n",
    "            print(f\"  Commutation: {comm_str}\")\n",
    "            print(f\"{'â”€'*100}\")\n",
    "            \n",
    "            # Filter ground truth for this suite's observables\n",
    "            suite_obs_ids = {r.observable_id for r in suite_results}\n",
    "            suite_truth = {k: v for k, v in truth.items() if k in suite_obs_ids}\n",
    "            \n",
    "            # Compute and display task summary\n",
    "            tasks, protocols = compute_full_task_summary(\n",
    "                suite_results, suite_truth, CONFIG, suite.n_observables\n",
    "            )\n",
    "            display_task_summary(f\"{cid}__{suite_name}\", tasks, protocols, suite)\n",
    "            \n",
    "    else:\n",
    "        # === NON-MERGED: Display as before ===\n",
    "        suite = run_data['suite']\n",
    "        \n",
    "        comm = suite.commutation_analysis()\n",
    "        comm_str = \"FULLY COMMUTING\" if comm['fully_commuting'] else f\"{comm['n_commuting_groups']} groups\"\n",
    "        obj_str = f\"[{suite.objective.value}]\" if suite.objective != ObjectiveType.PER_OBSERVABLE else \"\"\n",
    "        \n",
    "        print(f\"\\n{'='*100}\")\n",
    "        print(f\"{run_key}\")\n",
    "        print(f\"  {n_qubits}q, {suite.n_observables} obs, {suite.suite_type.value} {obj_str}\")\n",
    "        print(f\"  Commutation: {comm_str}\")\n",
    "        print(f\"{'='*100}\")\n",
    "        \n",
    "        tasks, protocols = compute_full_task_summary(\n",
    "            bench_result.long_form_results, truth, CONFIG, suite.n_observables\n",
    "        )\n",
    "        display_task_summary(run_key, tasks, protocols, suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "enhanced-analysis",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:33:58.912079Z",
     "iopub.status.busy": "2026-02-27T14:33:58.911549Z",
     "iopub.status.idle": "2026-02-27T14:33:58.942512Z",
     "shell.execute_reply": "2026-02-27T14:33:58.940642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "ENHANCED STATISTICAL ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "================================================================================\n",
      "S-BELL-2 (MERGED RUN)\n",
      "================================================================================\n",
      "\n",
      "--- S-BELL-2__workload_pair_correlations (6 obs, 3 groups) ---\n",
      "\n",
      "--- S-BELL-2__diagnostics_single_qubit (4 obs, commuting) ---\n",
      "\n",
      "--- S-BELL-2__diagnostics_cross_pair (1 obs, commuting) ---\n",
      "\n",
      "--- S-BELL-2__stress_random_1000 (87 obs, 32 groups) ---\n",
      "\n",
      "  CROSSOVER ANALYSIS:\n",
      "\n",
      "  LOCALITY BREAKDOWN:\n",
      "\n",
      "  PILOT ANALYSIS:\n",
      "    Optimal fraction: N/A\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ENHANCED ANALYSIS (Bootstrap, K-S Tests, Crossover, Locality)\n",
    "# =============================================================================\n",
    "\n",
    "def display_enhanced_analysis(bench_result, run_key, suite):\n",
    "    \"\"\"Display enhanced statistical analysis from result.analysis.\"\"\"\n",
    "    if not bench_result.analysis:\n",
    "        print(f\"  No enhanced analysis available\")\n",
    "        return\n",
    "\n",
    "    analysis = bench_result.analysis\n",
    "\n",
    "    # N* Interpolation\n",
    "    if hasattr(analysis, 'n_star_interpolation') and analysis.n_star_interpolation:\n",
    "        print(f\"\\n  N* INTERPOLATION (power-law fit):\")\n",
    "        for protocol, data in analysis.n_star_interpolation.items():\n",
    "            if hasattr(data, 'n_star'):\n",
    "                print(f\"    {protocol}: N* = {data.n_star:.0f}\")\n",
    "\n",
    "    # Statistical Tests\n",
    "    if hasattr(analysis, 'statistical_tests') and analysis.statistical_tests:\n",
    "        print(f\"\\n  STATISTICAL TESTS:\")\n",
    "        st = analysis.statistical_tests\n",
    "        if hasattr(st, 'ks_statistic'):\n",
    "            print(f\"    K-S statistic: {st.ks_statistic:.4f}\")\n",
    "            print(f\"    K-S p-value: {st.ks_pvalue:.4f}\")\n",
    "            sig = \"YES\" if st.ks_pvalue < 0.05 else \"NO\"\n",
    "            print(f\"    Distributions significantly different: {sig}\")\n",
    "        if hasattr(st, 'ssf_estimate'):\n",
    "            print(f\"    SSF estimate: {st.ssf_estimate:.2f}x\")\n",
    "        if hasattr(st, 'ssf_ci_low') and hasattr(st, 'ssf_ci_high'):\n",
    "            print(f\"    SSF 95% CI: [{st.ssf_ci_low:.2f}, {st.ssf_ci_high:.2f}]\")\n",
    "\n",
    "    # Crossover Analysis\n",
    "    if hasattr(analysis, 'crossover_analysis') and analysis.crossover_analysis:\n",
    "        print(f\"\\n  CROSSOVER ANALYSIS:\")\n",
    "        ca = analysis.crossover_analysis\n",
    "        if hasattr(ca, 'crossover_n') and ca.crossover_n:\n",
    "            print(f\"    Crossover N: {ca.crossover_n:.0f}\")\n",
    "        if hasattr(ca, 'shadows_wins_above'):\n",
    "            print(f\"    Shadows wins above crossover: {ca.shadows_wins_above}\")\n",
    "\n",
    "    # Locality Breakdown\n",
    "    if hasattr(analysis, 'locality_analysis') and analysis.locality_analysis:\n",
    "        print(f\"\\n  LOCALITY BREAKDOWN:\")\n",
    "        la = analysis.locality_analysis\n",
    "        if hasattr(la, 'by_locality'):\n",
    "            for k, data in sorted(la.by_locality.items()):\n",
    "                if hasattr(data, 'shadows_mean_se') and hasattr(data, 'baseline_mean_se'):\n",
    "                    ratio = data.shadows_mean_se / data.baseline_mean_se if data.baseline_mean_se > 0 else float('inf')\n",
    "                    winner = \"shadows\" if ratio < 1 else \"baseline\"\n",
    "                    print(f\"    K={k}: ratio={ratio:.2f}x ({winner})\")\n",
    "\n",
    "    # Pilot Analysis\n",
    "    if hasattr(analysis, 'pilot_analysis') and analysis.pilot_analysis:\n",
    "        print(f\"\\n  PILOT ANALYSIS:\")\n",
    "        pa = analysis.pilot_analysis\n",
    "        if pa.optimal_fraction is not None:\n",
    "            print(f\"    Optimal fraction: {pa.optimal_fraction*100:.0f}%\")\n",
    "        else:\n",
    "            print(f\"    Optimal fraction: N/A\")\n",
    "        if hasattr(pa, 'results') and pa.results:\n",
    "            print(f\"    Fractions tested: {list(pa.results.keys())}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ENHANCED STATISTICAL ANALYSIS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for run_key, run_data in all_results.items():\n",
    "    bench_result = run_data['result']\n",
    "    cid = run_data['circuit_id']\n",
    "\n",
    "    if run_data.get('merged'):\n",
    "        # === MERGED: Show analysis for each suite ===\n",
    "        suites = run_data['suites']\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"{cid} (MERGED RUN)\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        for suite_name, suite in suites.items():\n",
    "            comm = suite.commutation_analysis()\n",
    "            comm_str = \"commuting\" if comm['fully_commuting'] else f\"{comm['n_commuting_groups']} groups\"\n",
    "            print(f\"\\n--- {cid}__{suite_name} ({suite.n_observables} obs, {comm_str}) ---\")\n",
    "\n",
    "        # Display analysis (applies to merged set)\n",
    "        display_enhanced_analysis(bench_result, f\"{cid}__merged\", list(suites.values())[0])\n",
    "    else:\n",
    "        # === NON-MERGED: Single suite ===\n",
    "        suite = run_data['suite']\n",
    "        comm = suite.commutation_analysis()\n",
    "        comm_str = \"commuting\" if comm['fully_commuting'] else f\"{comm['n_commuting_groups']} groups\"\n",
    "\n",
    "        print(f\"\\n--- {run_key} ({suite.n_observables} obs, {comm_str}) ---\")\n",
    "        display_enhanced_analysis(bench_result, run_key, suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qlnf8q0k5g",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4b. Timing Breakdown and Timeout Analysis\n",
    "\n",
    "Shows where wall-clock time is spent (pre-compute, AER simulation, post-processing)\n",
    "and estimated quantum hardware time based on circuit properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rpv52gt609d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:33:58.953947Z",
     "iopub.status.busy": "2026-02-27T14:33:58.953308Z",
     "iopub.status.idle": "2026-02-27T14:33:59.054953Z",
     "shell.execute_reply": "2026-02-27T14:33:59.047007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "TIMING BREAKDOWN ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "================================================================================\n",
      "S-BELL-2__merged\n",
      "================================================================================\n",
      "\n",
      "  TIMEOUTS: 30 protocol runs timed out\n",
      "    classical_shadows_v0 @ N=10000, rep=0: completed 200/10000 shots\n",
      "    classical_shadows_v0 @ N=10000, rep=1: completed 400/10000 shots\n",
      "    classical_shadows_v0 @ N=10000, rep=2: completed 600/10000 shots\n",
      "    classical_shadows_v0 @ N=10000, rep=3: completed 700/10000 shots\n",
      "    classical_shadows_v0 @ N=10000, rep=4: completed 500/10000 shots\n",
      "    classical_shadows_v0 @ N=10000, rep=5: completed 400/10000 shots\n",
      "    classical_shadows_v0 @ N=10000, rep=6: completed 400/10000 shots\n",
      "    classical_shadows_v0 @ N=10000, rep=7: completed 400/10000 shots\n",
      "    classical_shadows_v0 @ N=10000, rep=8: completed 300/10000 shots\n",
      "    classical_shadows_v0 @ N=10000, rep=9: completed 300/10000 shots\n",
      "    direct_grouped @ N=10000, rep=0: completed 303/10000 shots\n",
      "    direct_grouped @ N=10000, rep=1: completed 606/10000 shots\n",
      "    direct_grouped @ N=10000, rep=2: completed 606/10000 shots\n",
      "    direct_grouped @ N=10000, rep=3: completed 909/10000 shots\n",
      "    direct_grouped @ N=10000, rep=4: completed 606/10000 shots\n",
      "    direct_grouped @ N=10000, rep=5: completed 606/10000 shots\n",
      "    direct_grouped @ N=10000, rep=6: completed 606/10000 shots\n",
      "    direct_grouped @ N=10000, rep=7: completed 606/10000 shots\n",
      "    direct_grouped @ N=10000, rep=8: completed 606/10000 shots\n",
      "    direct_grouped @ N=10000, rep=9: completed 606/10000 shots\n",
      "    direct_optimized @ N=10000, rep=0: completed 591/10000 shots\n",
      "    direct_optimized @ N=10000, rep=1: completed 1182/10000 shots\n",
      "    direct_optimized @ N=10000, rep=2: completed 1182/10000 shots\n",
      "    direct_optimized @ N=10000, rep=3: completed 1805/10000 shots\n",
      "    direct_optimized @ N=10000, rep=4: completed 1182/10000 shots\n",
      "    direct_optimized @ N=10000, rep=5: completed 1182/10000 shots\n",
      "    direct_optimized @ N=10000, rep=6: completed 1182/10000 shots\n",
      "    direct_optimized @ N=10000, rep=7: completed 1182/10000 shots\n",
      "    direct_optimized @ N=10000, rep=8: completed 1182/10000 shots\n",
      "    direct_optimized @ N=10000, rep=9: completed 1182/10000 shots\n",
      "\n",
      "  TIMING BREAKDOWN (mean across replicates):\n",
      "  Protocol                         N   Total(s)    PreComp     AerSim   PostProc  HW Est(s)\n",
      "  ---------------------------------------------------------------------------------------------\n",
      "  shadows                      10000      1.244      0.002      1.152      0.085      0.001\n",
      "  grouped                      10000      1.382      0.001      1.344      0.033      0.002\n",
      "  optimized                    10000      1.344      0.001      1.282      0.054      0.004\n",
      "\n",
      "  SIMULATOR vs HARDWARE TIME:\n",
      "  Protocol                         N     AER(s)  HW Est(s)    Speedup\n",
      "  -------------------------------------------------------------------------\n",
      "  shadows                      10000      1.152     0.0013     884.5x\n",
      "  grouped                      10000      1.344     0.0019     715.3x\n",
      "  optimized                    10000      1.282     0.0037     348.9x\n",
      "\n",
      "  NOTE: Speedup > 1 means AER simulation is SLOWER than real HW would be.\n",
      "        Real HW benefits from massive parallelism across shots.\n",
      "\n",
      "====================================================================================================\n",
      "KEY INSIGHT: est_quantum_hw_s shows the true cost of each protocol on hardware.\n",
      "             Shadows may have fewer settings but deeper measurement circuits.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TIMING BREAKDOWN AND TIMEOUT ANALYSIS\n",
    "# =============================================================================\n",
    "# New columns in LongFormRow:\n",
    "#   time_total_s        - Total wall-clock time\n",
    "#   time_pre_compute_s  - initialize() + next_plan() time\n",
    "#   time_aer_simulate_s - Just backend.run() / simulation time\n",
    "#   time_post_process_s - update() + finalize() time\n",
    "#   est_quantum_hw_s    - Estimated real hardware time (from HardwareTimingProfile)\n",
    "#   timed_out           - Whether the protocol run timed out\n",
    "#   n_shots_completed   - Actual shots completed if timed out\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"TIMING BREAKDOWN ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for run_key, run_data in all_results.items():\n",
    "    bench_result = run_data['result']\n",
    "    cid = run_data['circuit_id']\n",
    "    long_form = bench_result.long_form_results\n",
    "\n",
    "    if not long_form:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{run_key}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    # Check for timeouts\n",
    "    timed_out_rows = [r for r in long_form if r.timed_out]\n",
    "    if timed_out_rows:\n",
    "        # Count unique (protocol, N, replicate) combinations that timed out\n",
    "        timed_out_combos = {(r.protocol_id, r.N_total, r.replicate_id) for r in timed_out_rows}\n",
    "        print(f\"\\n  TIMEOUTS: {len(timed_out_combos)} protocol runs timed out\")\n",
    "        for protocol_id, n_total, rep in sorted(timed_out_combos):\n",
    "            # Find the n_shots_completed for this combo\n",
    "            combo_rows = [r for r in timed_out_rows\n",
    "                          if r.protocol_id == protocol_id and r.N_total == n_total and r.replicate_id == rep]\n",
    "            shots = combo_rows[0].n_shots_completed if combo_rows and combo_rows[0].n_shots_completed else \"?\"\n",
    "            print(f\"    {protocol_id} @ N={n_total}, rep={rep}: completed {shots}/{n_total} shots\")\n",
    "    else:\n",
    "        print(f\"\\n  No timeouts (all runs completed within budget)\")\n",
    "\n",
    "    # Timing breakdown by protocol and N\n",
    "    print(f\"\\n  TIMING BREAKDOWN (mean across replicates):\")\n",
    "    print(f\"  {'Protocol':<25} {'N':>8} {'Total(s)':>10} {'PreComp':>10} {'AerSim':>10} {'PostProc':>10} {'HW Est(s)':>10}\")\n",
    "    print(f\"  {'-'*93}\")\n",
    "\n",
    "    by_pn = defaultdict(list)\n",
    "    for r in long_form:\n",
    "        by_pn[(r.protocol_id, r.N_total)].append(r)\n",
    "\n",
    "    for (protocol_id, n_total), rows in sorted(by_pn.items(), key=lambda x: (x[0][0], x[0][1])):\n",
    "        # Take one row per replicate (timing is per-run, same for all observables in a run)\n",
    "        seen_reps = set()\n",
    "        unique_rows = []\n",
    "        for r in rows:\n",
    "            if r.replicate_id not in seen_reps:\n",
    "                seen_reps.add(r.replicate_id)\n",
    "                unique_rows.append(r)\n",
    "\n",
    "        def safe_mean(vals):\n",
    "            clean = [v for v in vals if v is not None]\n",
    "            return np.mean(clean) if clean else None\n",
    "\n",
    "        total = safe_mean([r.time_total_s for r in unique_rows])\n",
    "        pre = safe_mean([r.time_pre_compute_s for r in unique_rows])\n",
    "        aer = safe_mean([r.time_aer_simulate_s for r in unique_rows])\n",
    "        post = safe_mean([r.time_post_process_s for r in unique_rows])\n",
    "        hw = safe_mean([r.est_quantum_hw_s for r in unique_rows])\n",
    "\n",
    "        def fmt(v):\n",
    "            return f\"{v:>10.3f}\" if v is not None else f\"{'N/A':>10}\"\n",
    "\n",
    "        short_p = protocol_id.replace('classical_shadows_v0', 'shadows').replace('direct_', '')\n",
    "        print(f\"  {short_p:<25} {n_total:>8} {fmt(total)} {fmt(pre)} {fmt(aer)} {fmt(post)} {fmt(hw)}\")\n",
    "\n",
    "    # Speedup: AER sim time vs estimated HW time\n",
    "    hw_rows = [r for r in long_form if r.est_quantum_hw_s is not None and r.time_aer_simulate_s is not None]\n",
    "    if hw_rows:\n",
    "        print(f\"\\n  SIMULATOR vs HARDWARE TIME:\")\n",
    "        print(f\"  {'Protocol':<25} {'N':>8} {'AER(s)':>10} {'HW Est(s)':>10} {'Speedup':>10}\")\n",
    "        print(f\"  {'-'*73}\")\n",
    "\n",
    "        for (protocol_id, n_total), rows in sorted(by_pn.items(), key=lambda x: (x[0][0], x[0][1])):\n",
    "            seen_reps = set()\n",
    "            unique_rows = []\n",
    "            for r in rows:\n",
    "                if r.replicate_id not in seen_reps and r.est_quantum_hw_s is not None:\n",
    "                    seen_reps.add(r.replicate_id)\n",
    "                    unique_rows.append(r)\n",
    "\n",
    "            if not unique_rows:\n",
    "                continue\n",
    "\n",
    "            aer = np.mean([r.time_aer_simulate_s for r in unique_rows if r.time_aer_simulate_s])\n",
    "            hw = np.mean([r.est_quantum_hw_s for r in unique_rows if r.est_quantum_hw_s])\n",
    "            speedup = aer / hw if hw > 0 else float('inf')\n",
    "\n",
    "            short_p = protocol_id.replace('classical_shadows_v0', 'shadows').replace('direct_', '')\n",
    "            print(f\"  {short_p:<25} {n_total:>8} {aer:>10.3f} {hw:>10.4f} {speedup:>9.1f}x\")\n",
    "\n",
    "        print(f\"\\n  NOTE: Speedup > 1 means AER simulation is SLOWER than real HW would be.\")\n",
    "        print(f\"        Real HW benefits from massive parallelism across shots.\")\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"KEY INSIGHT: est_quantum_hw_s shows the true cost of each protocol on hardware.\")\n",
    "print(\"             Shadows may have fewer settings but deeper measurement circuits.\")\n",
    "print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "kl7vef3yczh",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:33:59.063337Z",
     "iopub.status.busy": "2026-02-27T14:33:59.062668Z",
     "iopub.status.idle": "2026-02-27T14:33:59.108968Z",
     "shell.execute_reply": "2026-02-27T14:33:59.105046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "OBJECTIVE-LEVEL ANALYSIS (Weighted Suites Only)\n",
      "====================================================================================================\n",
      "\n",
      "No weighted suites found. Enable QAOA workload or Chemistry suites to see objective metrics.\n",
      "\n",
      "====================================================================================================\n",
      "KEY INSIGHT: For weighted objectives, what matters is the TOTAL error,\n",
      "             not individual observable errors. This may change which protocol wins!\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# OBJECTIVE-LEVEL ANALYSIS (Work Item 4: Task-Level Metrics)\n",
    "# =============================================================================\n",
    "# For suites with weighted objectives (QAOA cost, chemistry energy), compute\n",
    "# the error in the OBJECTIVE, not individual observables.\n",
    "#\n",
    "# This is the actual metric practitioners care about:\n",
    "#   - QAOA: C = Î£ (1 - âŸ¨ZZâŸ©) / 2   (MAX-CUT cost)\n",
    "#   - Chemistry: E = Î£ c_k âŸ¨P_kâŸ©   (ground state energy)\n",
    "\n",
    "from quartumse.analysis.objective_metrics import (\n",
    "    compute_objective_metrics,\n",
    "    format_objective_analysis,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"OBJECTIVE-LEVEL ANALYSIS (Weighted Suites Only)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Find weighted suites (handling both merged and non-merged)\n",
    "weighted_runs = []\n",
    "for run_key, run_data in all_results.items():\n",
    "    if run_data.get('merged'):\n",
    "        # Check each suite in merged results\n",
    "        for suite_name, suite in run_data['suites'].items():\n",
    "            if suite.objective == ObjectiveType.WEIGHTED_SUM and suite.weights:\n",
    "                weighted_runs.append((f\"{run_data['circuit_id']}__{suite_name}\", run_data, suite_name, suite))\n",
    "    else:\n",
    "        suite = run_data['suite']\n",
    "        if suite.objective == ObjectiveType.WEIGHTED_SUM and suite.weights:\n",
    "            weighted_runs.append((run_key, run_data, run_data['suite_name'], suite))\n",
    "\n",
    "if not weighted_runs:\n",
    "    print(\"\\nNo weighted suites found. Enable QAOA workload or Chemistry suites to see objective metrics.\")\n",
    "else:\n",
    "    print(f\"\\nFound {len(weighted_runs)} weighted suite(s):\")\n",
    "\n",
    "    for run_key, run_data, suite_name, suite in weighted_runs:\n",
    "        bench_result = run_data['result']\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"{run_key}\")\n",
    "        print(f\"  Objective type: {suite.suite_type.value}\")\n",
    "        print(f\"  Weighted observables: {len(suite.weights)}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        # Determine objective type for computation\n",
    "        obj_type = \"qaoa_cost\" if \"qaoa\" in run_key.lower() or \"cost\" in suite.name.lower() else \"weighted_sum\"\n",
    "\n",
    "        # Filter results if merged\n",
    "        if run_data.get('merged'):\n",
    "            suite_mapping = run_data['suite_mapping']\n",
    "            suite_obs_ids = {\n",
    "                obs_id for obs_id, suites in suite_mapping.items()\n",
    "                if suite_name in suites\n",
    "            }\n",
    "            long_form = [r for r in bench_result.long_form_results if r.observable_id in suite_obs_ids]\n",
    "        else:\n",
    "            long_form = bench_result.long_form_results\n",
    "\n",
    "        # Compute objective metrics\n",
    "        obj_analysis = compute_objective_metrics(\n",
    "            long_form_results=long_form,\n",
    "            weights=suite.weights,\n",
    "            objective_type=obj_type,\n",
    "            true_objective=None,  # Could add ground truth if available\n",
    "            target_epsilon=CONFIG.epsilon,\n",
    "            n_bootstrap=500,\n",
    "            seed=CONFIG.seed,\n",
    "        )\n",
    "\n",
    "        # Display formatted results\n",
    "        print(format_objective_analysis(obj_analysis))\n",
    "\n",
    "        # Store in results for later\n",
    "        if not run_data.get('merged'):\n",
    "            run_data['objective_analysis'] = obj_analysis\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"KEY INSIGHT: For weighted objectives, what matters is the TOTAL error,\")\n",
    "print(\"             not individual observable errors. This may change which protocol wins!\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "xfs9hf2jjt",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:33:59.125616Z",
     "iopub.status.busy": "2026-02-27T14:33:59.124372Z",
     "iopub.status.idle": "2026-02-27T14:33:59.156977Z",
     "shell.execute_reply": "2026-02-27T14:33:59.154869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "POST-HOC QUERYING BENCHMARK\n",
      "====================================================================================================\n",
      "\n",
      "No post-hoc suites found.\n",
      "Enable 'posthoc': True in SUITES_TO_RUN to run post-hoc benchmarks.\n",
      "\n",
      "Example configuration:\n",
      "  SUITES_TO_RUN = {\n",
      "      'workload': True,\n",
      "      'posthoc': True,  # <-- Enable this\n",
      "  }\n",
      "\n",
      "====================================================================================================\n",
      "KEY INSIGHT: Shadows' quantum cost is FIXED after acquisition.\n",
      "             Direct measurement cost GROWS with each new query round.\n",
      "             The more observables you query later, the more shadows saves.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# POST-HOC QUERYING BENCHMARK (Work Item 3)\n",
    "# =============================================================================\n",
    "# This simulates the core advantage of classical shadows:\n",
    "#   \"Measure once, decide observables later\"\n",
    "#\n",
    "# Cost accounting:\n",
    "#   - Shadows: quantum cost = ONE acquisition; all new queries are FREE\n",
    "#   - Direct: pay for each new basis not already measured\n",
    "#\n",
    "# This quantifies the \"option value\" of shadows.\n",
    "\n",
    "from quartumse.analysis.posthoc_benchmark import (\n",
    "    run_posthoc_benchmark_from_suite,\n",
    "    format_posthoc_result,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"POST-HOC QUERYING BENCHMARK\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Check if posthoc was skipped due to redundancy\n",
    "if posthoc_skipped:\n",
    "    print(\"\\nâš  POSTHOC ANALYSIS SKIPPED (redundant with stress - same or fewer observables)\")\n",
    "    print(\"  Posthoc adds value when it tests MORE observables than stress.\")\n",
    "    print(\"  To run posthoc, increase N_POSTHOC_OBSERVABLES or decrease N_STRESS_OBSERVABLES.\")\n",
    "    for cid, key, stress_obs, posthoc_obs in posthoc_skipped:\n",
    "        print(f\"\\n  Skipped: {cid}/{key}\")\n",
    "        print(f\"    Reason: posthoc ({posthoc_obs} obs) <= stress ({stress_obs} obs)\")\n",
    "\n",
    "# Find posthoc suites (checking both merged and non-merged results)\n",
    "posthoc_runs = []\n",
    "for run_key, run_data in all_results.items():\n",
    "    if run_data.get('merged'):\n",
    "        # Check if any merged suite is posthoc type\n",
    "        for suite_name, suite in run_data['suites'].items():\n",
    "            if suite.suite_type == SuiteType.POSTHOC:\n",
    "                posthoc_runs.append((f\"{run_data['circuit_id']}__{suite_name}\", suite))\n",
    "    else:\n",
    "        suite = run_data['suite']\n",
    "        if suite.suite_type == SuiteType.POSTHOC:\n",
    "            posthoc_runs.append((run_key, suite))\n",
    "\n",
    "# Also check for posthoc libraries in circuit definitions (even if not benchmarked)\n",
    "posthoc_available = []\n",
    "for cid, info in circuits.items():\n",
    "    for suite_name, suite in info.get('suites', {}).items():\n",
    "        if 'posthoc' in suite_name.lower() or suite.suite_type == SuiteType.POSTHOC:\n",
    "            posthoc_available.append((cid, suite_name, suite))\n",
    "\n",
    "if not posthoc_available and not posthoc_runs and not posthoc_skipped:\n",
    "    print(\"\\nNo post-hoc suites found.\")\n",
    "    print(\"Enable 'posthoc': True in SUITES_TO_RUN to run post-hoc benchmarks.\")\n",
    "    print(\"\\nExample configuration:\")\n",
    "    print(\"  SUITES_TO_RUN = {\")\n",
    "    print(\"      'workload': True,\")\n",
    "    print(\"      'posthoc': True,  # <-- Enable this\")\n",
    "    print(\"  }\")\n",
    "elif posthoc_available:\n",
    "    # Run post-hoc simulation on available posthoc suites\n",
    "    print(f\"\\nFound {len(posthoc_available)} post-hoc suite(s):\")\n",
    "\n",
    "    for cid, suite_name, suite in posthoc_available:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"POST-HOC SIMULATION: {cid}:{suite_name}\")\n",
    "        print(f\"  Library size: {suite.n_observables} observables\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        # Configure simulation\n",
    "        n_rounds = 5\n",
    "        obs_per_round = max(10, suite.n_observables // 10)  # ~10% per round\n",
    "\n",
    "        # Run simulation\n",
    "        result = run_posthoc_benchmark_from_suite(\n",
    "            posthoc_suite=suite,\n",
    "            n_rounds=n_rounds,\n",
    "            observables_per_round=obs_per_round,\n",
    "            shadows_shots=max(CONFIG.n_shots_grid),  # Use max shot budget\n",
    "            direct_shots_per_basis=100,  # Shots per basis for direct\n",
    "            seed=CONFIG.seed,\n",
    "        )\n",
    "\n",
    "        # Display results\n",
    "        print(format_posthoc_result(result))\n",
    "        print()\n",
    "\n",
    "        # Cumulative cost curves\n",
    "        print(\"\\nCUMULATIVE COST CURVES:\")\n",
    "        print(f\"{'Round':<8} {'Cum Shadows':>15} {'Cum Direct':>15} {'Cum Obs':>12} {'Savings':>10}\")\n",
    "        print(\"-\" * 65)\n",
    "\n",
    "        shadows = result.shadows_costs\n",
    "        direct = result.direct_costs\n",
    "\n",
    "        if shadows and direct:\n",
    "            for i in range(result.n_rounds):\n",
    "                savings = direct.cumulative_shots[i] / shadows.cumulative_shots[i] if shadows.cumulative_shots[i] > 0 else float('inf')\n",
    "                print(\n",
    "                    f\"{i:<8} {shadows.cumulative_shots[i]:>15,} {direct.cumulative_shots[i]:>15,} \"\n",
    "                    f\"{shadows.cumulative_observables_answered[i]:>12} {savings:>9.1f}x\"\n",
    "                )\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"KEY INSIGHT: Shadows' quantum cost is FIXED after acquisition.\")\n",
    "print(\"             Direct measurement cost GROWS with each new query round.\")\n",
    "print(\"             The more observables you query later, the more shadows saves.\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cross-circuit",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:33:59.162362Z",
     "iopub.status.busy": "2026-02-27T14:33:59.161897Z",
     "iopub.status.idle": "2026-02-27T14:33:59.231587Z",
     "shell.execute_reply": "2026-02-27T14:33:59.230365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "CROSS-CIRCUIT COMPARISON BY SUITE TYPE\n",
      "====================================================================================================\n",
      "\n",
      "================================================================================\n",
      "SUITE TYPE: WORKLOAD\n",
      "================================================================================\n",
      "Run Key                               Q   Obs  Comm?   Shadows SE   Grouped SE    Ratio     Winner\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "S-BELL-2__workload_pair_correlations   4     6     no       0.1432          inf     0.00x    Shadows\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "  WORKLOAD: Shadows wins 1/1 runs\n",
      "\n",
      "================================================================================\n",
      "SUITE TYPE: DIAGNOSTIC\n",
      "================================================================================\n",
      "Run Key                               Q   Obs  Comm?   Shadows SE   Grouped SE    Ratio     Winner\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "S-BELL-2__diagnostics_single_qubit    4     4    YES       0.0872          inf     0.00x    Shadows\n",
      "S-BELL-2__diagnostics_cross_pair      4     1    YES       0.1508          inf     0.00x    Shadows\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "  DIAGNOSTIC: Shadows wins 2/2 runs\n",
      "\n",
      "================================================================================\n",
      "SUITE TYPE: STRESS\n",
      "================================================================================\n",
      "Run Key                               Q   Obs  Comm?   Shadows SE   Grouped SE    Ratio     Winner\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "S-BELL-2__stress_random_1000          4    87     no       0.2565          inf     0.00x    Shadows\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "  STRESS: Shadows wins 1/1 runs\n",
      "\n",
      "====================================================================================================\n",
      "OVERALL SUMMARY\n",
      "====================================================================================================\n",
      "\n",
      "Total suite evaluations: 4\n",
      "Shadows wins overall: 4/4 (100.0%)\n",
      "Shadows wins on COMMUTING suites: 2/2 (100.0%)\n",
      "Shadows wins on NON-COMMUTING suites: 2/2 (100.0%)\n",
      "\n",
      "âœ“ MERGE OPTIMIZATION ACTIVE\n",
      "  S-BELL-2: 4 suites merged, 8 redundant obs eliminated\n",
      "\n",
      "KEY INSIGHT:\n",
      "  - For COMMUTING suites (e.g., QAOA cost), grouped measurement should dominate\n",
      "  - For NON-COMMUTING suites (e.g., stress), shadows may become competitive\n",
      "  - The crossover depends on K (number of observables) and locality distribution\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CROSS-CIRCUIT CONSOLIDATED COMPARISON (Suite-Aware)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"CROSS-CIRCUIT COMPARISON BY SUITE TYPE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "def compute_suite_summary(long_form_results, suite_mapping, suite_name, n_qubits, suite):\n",
    "    \"\"\"Compute summary stats for a specific suite from merged results.\"\"\"\n",
    "    # Filter to this suite's observables\n",
    "    suite_obs_ids = {\n",
    "        obs_id for obs_id, suites in suite_mapping.items() \n",
    "        if suite_name in suites\n",
    "    }\n",
    "    suite_results = [r for r in long_form_results if r.observable_id in suite_obs_ids]\n",
    "    \n",
    "    if not suite_results:\n",
    "        return None\n",
    "    \n",
    "    # Get max N\n",
    "    max_n = max(r.N_total for r in suite_results)\n",
    "    \n",
    "    # Compute mean SE by protocol at max N\n",
    "    by_protocol = defaultdict(list)\n",
    "    for r in suite_results:\n",
    "        if r.N_total == max_n and r.se is not None:\n",
    "            by_protocol[r.protocol_id].append(r.se)\n",
    "    \n",
    "    shadows_se = np.mean(by_protocol.get('classical_shadows_v0', [float('inf')]))\n",
    "    grouped_se = np.mean(by_protocol.get('direct_grouped', [float('inf')]))\n",
    "    \n",
    "    return {\n",
    "        'shadows_se': shadows_se,\n",
    "        'grouped_se': grouped_se,\n",
    "        'n_qubits': n_qubits,\n",
    "        'n_observables': suite.n_observables,\n",
    "        'suite': suite,\n",
    "    }\n",
    "\n",
    "# Build per-suite summaries (handling both merged and non-merged)\n",
    "suite_summaries = []  # List of (run_key, suite_name, summary_dict)\n",
    "\n",
    "for run_key, run_data in all_results.items():\n",
    "    bench_result = run_data['result']\n",
    "    cid = run_data['circuit_id']\n",
    "    n_qubits = run_data['n_qubits']\n",
    "    \n",
    "    if run_data.get('merged'):\n",
    "        # Split merged results by suite\n",
    "        suite_mapping = run_data['suite_mapping']\n",
    "        suites = run_data['suites']\n",
    "        \n",
    "        for suite_name, suite in suites.items():\n",
    "            summary = compute_suite_summary(\n",
    "                bench_result.long_form_results,\n",
    "                suite_mapping,\n",
    "                suite_name,\n",
    "                n_qubits,\n",
    "                suite\n",
    "            )\n",
    "            if summary:\n",
    "                suite_summaries.append((f\"{cid}__{suite_name}\", suite_name, summary))\n",
    "    else:\n",
    "        # Non-merged: use result summary directly\n",
    "        suite = run_data['suite']\n",
    "        summaries = bench_result.summary.get('protocol_summaries', {})\n",
    "        \n",
    "        shadows_se = summaries.get('classical_shadows_v0', {}).get('mean_se', float('inf'))\n",
    "        grouped_se = summaries.get('direct_grouped', {}).get('mean_se', float('inf'))\n",
    "        \n",
    "        summary = {\n",
    "            'shadows_se': shadows_se,\n",
    "            'grouped_se': grouped_se,\n",
    "            'n_qubits': n_qubits,\n",
    "            'n_observables': suite.n_observables,\n",
    "            'suite': suite,\n",
    "        }\n",
    "        suite_summaries.append((run_key, run_data['suite_name'], summary))\n",
    "\n",
    "# Group by suite type for analysis\n",
    "by_suite_type = defaultdict(list)\n",
    "for run_key, suite_name, summary in suite_summaries:\n",
    "    suite_type = summary['suite'].suite_type.value\n",
    "    by_suite_type[suite_type].append((run_key, summary))\n",
    "\n",
    "# Summary table for each suite type\n",
    "for suite_type, runs in by_suite_type.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SUITE TYPE: {suite_type.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"{'Run Key':<35} {'Q':>3} {'Obs':>5} {'Comm?':>6} {'Shadows SE':>12} {'Grouped SE':>12} {'Ratio':>8} {'Winner':>10}\")\n",
    "    print(\"-\" * 105)\n",
    "    \n",
    "    shadows_wins = 0\n",
    "    total_runs = 0\n",
    "    \n",
    "    for run_key, summary in runs:\n",
    "        suite = summary['suite']\n",
    "        n_qubits = summary['n_qubits']\n",
    "        \n",
    "        # Check commutation\n",
    "        comm = suite.commutation_analysis()\n",
    "        comm_str = \"YES\" if comm['fully_commuting'] else \"no\"\n",
    "        \n",
    "        shadows_se = summary['shadows_se']\n",
    "        grouped_se = summary['grouped_se']\n",
    "        \n",
    "        ratio = shadows_se / grouped_se if grouped_se > 0 else float('inf')\n",
    "        winner = 'Shadows' if ratio < 1 else 'Grouped'\n",
    "        \n",
    "        if ratio < 1:\n",
    "            shadows_wins += 1\n",
    "        total_runs += 1\n",
    "        \n",
    "        print(f\"{run_key:<35} {n_qubits:>3} {suite.n_observables:>5} {comm_str:>6} \"\n",
    "              f\"{shadows_se:>12.4f} {grouped_se:>12.4f} {ratio:>8.2f}x {winner:>10}\")\n",
    "    \n",
    "    print(\"-\" * 105)\n",
    "    print(f\"  {suite_type.upper()}: Shadows wins {shadows_wins}/{total_runs} runs\")\n",
    "\n",
    "# Overall summary\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"OVERALL SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "total_wins_shadows = 0\n",
    "total_runs = 0\n",
    "commuting_shadows_wins = 0\n",
    "commuting_total = 0\n",
    "noncommuting_shadows_wins = 0\n",
    "noncommuting_total = 0\n",
    "\n",
    "for run_key, suite_name, summary in suite_summaries:\n",
    "    suite = summary['suite']\n",
    "    comm = suite.commutation_analysis()\n",
    "    \n",
    "    shadows_se = summary['shadows_se']\n",
    "    grouped_se = summary['grouped_se']\n",
    "    \n",
    "    shadows_won = shadows_se < grouped_se\n",
    "    \n",
    "    total_runs += 1\n",
    "    if shadows_won:\n",
    "        total_wins_shadows += 1\n",
    "    \n",
    "    if comm['fully_commuting']:\n",
    "        commuting_total += 1\n",
    "        if shadows_won:\n",
    "            commuting_shadows_wins += 1\n",
    "    else:\n",
    "        noncommuting_total += 1\n",
    "        if shadows_won:\n",
    "            noncommuting_shadows_wins += 1\n",
    "\n",
    "print(f\"\\nTotal suite evaluations: {total_runs}\")\n",
    "print(f\"Shadows wins overall: {total_wins_shadows}/{total_runs} ({100*total_wins_shadows/total_runs:.1f}%)\")\n",
    "if commuting_total > 0:\n",
    "    print(f\"Shadows wins on COMMUTING suites: {commuting_shadows_wins}/{commuting_total} ({100*commuting_shadows_wins/commuting_total:.1f}%)\")\n",
    "if noncommuting_total > 0:\n",
    "    print(f\"Shadows wins on NON-COMMUTING suites: {noncommuting_shadows_wins}/{noncommuting_total} ({100*noncommuting_shadows_wins/noncommuting_total:.1f}%)\")\n",
    "\n",
    "# Show merge efficiency if applicable\n",
    "merged_runs = [r for r in all_results.values() if r.get('merged')]\n",
    "if merged_runs:\n",
    "    print(f\"\\nâœ“ MERGE OPTIMIZATION ACTIVE\")\n",
    "    for r in merged_runs:\n",
    "        cid = r['circuit_id']\n",
    "        n_suites = len(r['suites'])\n",
    "        overlap = circuits[cid]['overlap_count']\n",
    "        print(f\"  {cid}: {n_suites} suites merged, {overlap} redundant obs eliminated\")\n",
    "\n",
    "print(\"\\nKEY INSIGHT:\")\n",
    "print(\"  - For COMMUTING suites (e.g., QAOA cost), grouped measurement should dominate\")\n",
    "print(\"  - For NON-COMMUTING suites (e.g., stress), shadows may become competitive\")\n",
    "print(\"  - The crossover depends on K (number of observables) and locality distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "save-results",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:33:59.238037Z",
     "iopub.status.busy": "2026-02-27T14:33:59.237670Z",
     "iopub.status.idle": "2026-02-27T14:33:59.269567Z",
     "shell.execute_reply": "2026-02-27T14:33:59.265806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated results saved: benchmark_results\\consolidated_20260227_143359.json\n",
      "\n",
      "Summary:\n",
      "  Total runs: 1\n",
      "  Suites enabled: ['merged', 'workload', 'stress', 'commuting', 'posthoc', 'diagnostics']\n",
      "  Circuits: ['S-BELL-2']\n",
      "  Merge optimization: enabled\n",
      "\n",
      "  MERGED RUNS:\n",
      "    S-BELL-2: 4 suites merged, 8 redundant obs eliminated\n",
      "\n",
      "Individual run directories:\n",
      "  S-BELL-2__merged: benchmark_results\\S-BELL-2__merged_20260227_143006_39bb9b0a\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SAVE CONSOLIDATED RESULTS (with Suite Metadata)\n",
    "# =============================================================================\n",
    "\n",
    "output_dir = Path(CONFIG.output_base_dir)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "consolidated = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'n_runs': len(all_results),\n",
    "    'config': {\n",
    "        'mode': CONFIG.mode.value,\n",
    "        'n_shots_grid': CONFIG.n_shots_grid,\n",
    "        'n_replicates': CONFIG.n_replicates,\n",
    "        'epsilon': CONFIG.epsilon,\n",
    "    },\n",
    "    'suites_enabled': {k: v for k, v in SUITES_TO_RUN.items() if v},\n",
    "    'circuits_enabled': [k for k, v in CIRCUITS_TO_RUN.items() if v],\n",
    "    'merge_enabled': merge_enabled,\n",
    "    'runs': {},\n",
    "}\n",
    "\n",
    "for run_key, run_data in all_results.items():\n",
    "    bench_result = run_data['result']\n",
    "    cid = run_data['circuit_id']\n",
    "\n",
    "    if run_data.get('merged'):\n",
    "        # === MERGED: Store info about all suites in merge ===\n",
    "        suites = run_data['suites']\n",
    "        suite_metadata = {}\n",
    "        for suite_name, suite in suites.items():\n",
    "            comm = suite.commutation_analysis()\n",
    "            suite_metadata[suite_name] = {\n",
    "                'suite_type': suite.suite_type.value,\n",
    "                'objective': suite.objective.value,\n",
    "                'n_observables': suite.n_observables,\n",
    "                'fully_commuting': comm['fully_commuting'],\n",
    "                'n_commuting_groups': comm['n_commuting_groups'],\n",
    "                'has_weights': suite.weights is not None,\n",
    "                'description': suite.description,\n",
    "            }\n",
    "\n",
    "        consolidated['runs'][run_key] = {\n",
    "            'circuit_id': cid,\n",
    "            'suite_name': '_merged_',\n",
    "            'n_qubits': run_data['n_qubits'],\n",
    "            'merged': True,\n",
    "            'merged_suites': list(suites.keys()),\n",
    "            'overlap_eliminated': circuits[cid]['overlap_count'],\n",
    "            'suite_metadata': suite_metadata,\n",
    "            # Benchmark results\n",
    "            'run_id': bench_result.run_id,\n",
    "            'output_dir': str(bench_result.output_dir),\n",
    "            'summary': bench_result.summary,\n",
    "        }\n",
    "    else:\n",
    "        # === NON-MERGED: Single suite ===\n",
    "        suite = run_data['suite']\n",
    "        comm = suite.commutation_analysis()\n",
    "\n",
    "        consolidated['runs'][run_key] = {\n",
    "            'circuit_id': cid,\n",
    "            'suite_name': run_data['suite_name'],\n",
    "            'n_qubits': run_data['n_qubits'],\n",
    "            'merged': False,\n",
    "            # Suite metadata\n",
    "            'suite_metadata': {\n",
    "                run_data['suite_name']: {\n",
    "                    'suite_type': suite.suite_type.value,\n",
    "                    'objective': suite.objective.value,\n",
    "                    'n_observables': suite.n_observables,\n",
    "                    'fully_commuting': comm['fully_commuting'],\n",
    "                    'n_commuting_groups': comm['n_commuting_groups'],\n",
    "                    'has_weights': suite.weights is not None,\n",
    "                    'description': suite.description,\n",
    "                }\n",
    "            },\n",
    "            # Benchmark results\n",
    "            'run_id': bench_result.run_id,\n",
    "            'output_dir': str(bench_result.output_dir),\n",
    "            'summary': bench_result.summary,\n",
    "        }\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "consolidated_path = output_dir / f'consolidated_{timestamp}.json'\n",
    "with open(consolidated_path, 'w') as f:\n",
    "    json.dump(consolidated, f, indent=2, default=str)\n",
    "\n",
    "print(f\"Consolidated results saved: {consolidated_path}\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Total runs: {len(all_results)}\")\n",
    "print(f\"  Suites enabled: {list(consolidated['suites_enabled'].keys())}\")\n",
    "print(f\"  Circuits: {consolidated['circuits_enabled']}\")\n",
    "print(f\"  Merge optimization: {'enabled' if merge_enabled else 'disabled'}\")\n",
    "\n",
    "# Show merge info if applicable\n",
    "merged_runs = [r for r in all_results.values() if r.get('merged')]\n",
    "if merged_runs:\n",
    "    print(f\"\\n  MERGED RUNS:\")\n",
    "    for r in merged_runs:\n",
    "        cid = r['circuit_id']\n",
    "        n_suites = len(r['suites'])\n",
    "        overlap = circuits[cid]['overlap_count']\n",
    "        print(f\"    {cid}: {n_suites} suites merged, {overlap} redundant obs eliminated\")\n",
    "\n",
    "print(f\"\\nIndividual run directories:\")\n",
    "for run_key, run_data in all_results.items():\n",
    "    print(f\"  {run_key}: {run_data['result'].output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook provides **complete benchmarking** of classical shadows vs direct measurement:\n",
    "\n",
    "### Tasks Evaluated (Measurements Bible)\n",
    "\n",
    "| Task | Question | Output |\n",
    "|------|----------|--------|\n",
    "| 1 | Worst-case N* (all obs)? | N* per protocol |\n",
    "| 2 | Average N* (mean)? | N* per protocol |\n",
    "| 3 | SE distribution at fixed N? | mean, median, max |\n",
    "| 4 | Dominance (% wins)? | Winner + breakdown |\n",
    "| 5 | Optimal pilot fraction? | % of budget |\n",
    "| 6 | Bias-variance decomposition? | Bias2, Var, MSE |\n",
    "| 7 | Noise sensitivity? | (with sweep) |\n",
    "| 8 | Adaptive efficiency? | (from pilot) |\n",
    "\n",
    "### Enhanced Analysis\n",
    "\n",
    "- Power-law N* interpolation\n",
    "- K-S distribution tests\n",
    "- Bootstrap confidence intervals\n",
    "- Per-observable crossover analysis\n",
    "- Locality breakdown (k=1,2,3,...,n)\n",
    "- Cost-normalized metrics\n",
    "\n",
    "### Timing and Timeout Features\n",
    "\n",
    "- **Per-protocol timeout** (`timeout_per_protocol_s`): Stops slow protocols gracefully with partial data\n",
    "- **Fine-grained timing breakdown**: Pre-compute, AER simulation, post-processing phases\n",
    "- **Hardware time model** (`hw_timing_profile`): Estimates real-device execution time using gate/measurement timings (e.g., IBM Heron R2)\n",
    "- **Simulator vs hardware comparison**: Shows how AER wall time compares to estimated quantum hardware time\n",
    "\n",
    "### Obsolete Notebooks\n",
    "\n",
    "This notebook supersedes:\n",
    "- `benchmark_shadows_vs_baselines.ipynb`\n",
    "- `notebook_j_full_publication_benchmark_ghz_shadows_v0.ipynb`\n",
    "- `notebook_k_locality_benchmark.ipynb`\n",
    "- `notebook_l_random_bloch_benchmark.ipynb`\n",
    "- `notebook_l_comprehensive_benchmark.ipynb`\n",
    "- `notebook_benchmark_suite.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b72733-fdcc-4b5f-b011-0c44eaae4535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
