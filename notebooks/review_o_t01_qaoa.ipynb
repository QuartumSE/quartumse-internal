{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O-T01: QAOA MAX-CUT Experiment Review\n",
    "\n",
    "**Experiment ID:** O-T01  \n",
    "**Workstream:** Optimization  \n",
    "**Objective:** Demonstrate shot-frugal QAOA optimization using classical shadows for cost function estimation on 5-node ring graph MAX-CUT\n",
    "\n",
    "**Phase 1 Success Criteria:**\n",
    "- Approximation ratio ≥ 0.90\n",
    "- ≥20% reduction in optimizer steps vs. standard QAOA\n",
    "- Manifest and convergence data generated\n",
    "\n",
    "This notebook reviews the results from O-T01 trials, analyzes convergence behavior, and computes key metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "from quartumse.reporting.manifest import load_manifest\n",
    "from quartumse.reporting.report import generate_summary_report\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Convergence Data\n",
    "\n",
    "O-T01 generates convergence logs tracking cost function values per optimizer iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load convergence log (adjust trial ID as needed)\n",
    "data_dir = Path.cwd().parent / \"data\"\n",
    "convergence_log_path = data_dir / \"logs\" / \"o-t01-convergence.json\"  # or o-t01-trial-01-convergence.json\n",
    "\n",
    "if not convergence_log_path.exists():\n",
    "    # Try to find any O-T01 convergence log\n",
    "    log_files = list((data_dir / \"logs\").glob(\"o-t01*convergence.json\"))\n",
    "    if log_files:\n",
    "        convergence_log_path = log_files[0]\n",
    "        print(f\"Found convergence log: {convergence_log_path}\")\n",
    "    else:\n",
    "        print(\"No convergence log found. Run O-T01 experiment first.\")\n",
    "        convergence_data = None\n",
    "else:\n",
    "    with convergence_log_path.open(\"r\") as f:\n",
    "        convergence_data = json.load(f)\n",
    "    print(f\"Loaded: {convergence_log_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experiment Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if convergence_data:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"O-T01 EXPERIMENT OVERVIEW\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Experiment ID:      {convergence_data['experiment_id']}\")\n",
    "    print(f\"Trial ID:           {convergence_data.get('trial_id', 'N/A')}\")\n",
    "    print(f\"Backend:            {convergence_data['backend']}\")\n",
    "    print(f\"Shadow size:        {convergence_data['shadow_size']}\")\n",
    "    print(f\"Shadow version:     {convergence_data['shadow_version']}\")\n",
    "    print(f\"QAOA depth (p):     {convergence_data['p']}\")\n",
    "    print(f\"Optimizer:          {convergence_data['optimizer']}\")\n",
    "    print(f\"Random seed:        {convergence_data['seed']}\")\n",
    "    print()\n",
    "    print(\"FINAL RESULTS:\")\n",
    "    final = convergence_data['final_results']\n",
    "    print(f\"  Approximation ratio: {final['approx_ratio']:.4f} (target: ≥0.90)\")\n",
    "    print(f\"  Iterations:          {final['iterations']}\")\n",
    "    print(f\"  Total time:          {final['total_time']:.2f}s\")\n",
    "    print(f\"  Final params:        {final['final_params']}\")\n",
    "    print()\n",
    "    print(f\"Manifest: {convergence_data['manifest_path']}\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convergence Analysis\n",
    "\n",
    "Visualize how the QAOA cost function evolves during optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if convergence_data:\n",
    "    history = convergence_data['convergence_history']\n",
    "    \n",
    "    # Extract data\n",
    "    iterations = [h['iteration'] for h in history]\n",
    "    costs = [h['cost'] for h in history]\n",
    "    max_cuts = [h['max_cut_value'] for h in history]\n",
    "    ci_widths = [h['mean_ci_width'] for h in history]\n",
    "    \n",
    "    # Create convergence plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Plot 1: Cost function\n",
    "    axes[0, 0].plot(iterations, costs, 'b-', linewidth=2, marker='o', markersize=4)\n",
    "    axes[0, 0].set_xlabel('Iteration')\n",
    "    axes[0, 0].set_ylabel('Cost Function Value')\n",
    "    axes[0, 0].set_title('QAOA Cost Function Convergence')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: MAX-CUT value\n",
    "    axes[0, 1].plot(iterations, max_cuts, 'g-', linewidth=2, marker='s', markersize=4)\n",
    "    axes[0, 1].axhline(y=4.0, color='r', linestyle='--', label='Optimal (4)')\n",
    "    axes[0, 1].set_xlabel('Iteration')\n",
    "    axes[0, 1].set_ylabel('MAX-CUT Value')\n",
    "    axes[0, 1].set_title('MAX-CUT Solution Quality vs Iteration')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: CI width (shadow estimation quality)\n",
    "    axes[1, 0].plot(iterations, ci_widths, 'orange', linewidth=2, marker='^', markersize=4)\n",
    "    axes[1, 0].set_xlabel('Iteration')\n",
    "    axes[1, 0].set_ylabel('Mean CI Width')\n",
    "    axes[1, 0].set_title('Shadow Estimation Quality (CI Width)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Approximation ratio\n",
    "    approx_ratios = [mc / 4.0 for mc in max_cuts]  # Optimal = 4\n",
    "    axes[1, 1].plot(iterations, approx_ratios, 'm-', linewidth=2, marker='D', markersize=4)\n",
    "    axes[1, 1].axhline(y=0.90, color='r', linestyle='--', label='Target (0.90)')\n",
    "    axes[1, 1].set_xlabel('Iteration')\n",
    "    axes[1, 1].set_ylabel('Approximation Ratio')\n",
    "    axes[1, 1].set_title('Approximation Ratio vs Iteration')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nConvergence Statistics:\")\n",
    "    print(f\"  Total iterations:        {len(history)}\")\n",
    "    print(f\"  Best MAX-CUT achieved:   {max(max_cuts):.4f}\")\n",
    "    print(f\"  Final approximation:     {approx_ratios[-1]:.4f}\")\n",
    "    print(f\"  Mean CI width:           {np.mean(ci_widths):.4f}\")\n",
    "    print(f\"  Std CI width:            {np.std(ci_widths):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Inspect Final Manifest\n",
    "\n",
    "The manifest contains the final optimized circuit and provenance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if convergence_data:\n",
    "    manifest_path = Path(convergence_data['manifest_path'])\n",
    "    \n",
    "    if manifest_path.exists():\n",
    "        manifest = load_manifest(manifest_path)\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"MANIFEST OVERVIEW\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Manifest ID:        {manifest.manifest_id}\")\n",
    "        print(f\"Timestamp:          {manifest.timestamp}\")\n",
    "        print(f\"Backend:            {manifest.backend}\")\n",
    "        print(f\"Circuit depth:      {manifest.circuit_depth}\")\n",
    "        print(f\"Circuit hash:       {manifest.circuit_fingerprint[:16]}...\")\n",
    "        print(f\"Shadow size:        {manifest.shadow_config.get('shadow_size', 'N/A')}\")\n",
    "        print(f\"Shadow version:     {manifest.shadow_config.get('version', 'N/A')}\")\n",
    "        print()\n",
    "        print(f\"Observables measured: {len(manifest.observables)}\")\n",
    "        for obs_name in list(manifest.observables.keys())[:5]:  # Show first 5\n",
    "            obs = manifest.observables[obs_name]\n",
    "            print(f\"  {obs_name}: {obs['expectation_value']:.4f} ± CI: {obs['ci_95']}\")\n",
    "        print(\"=\" * 70)\n",
    "    else:\n",
    "        print(f\"Manifest not found: {manifest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Backend Calibration Data\n",
    "\n",
    "Review the quantum hardware properties at execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if convergence_data and manifest_path.exists():\n",
    "    backend_props = manifest.backend_properties\n",
    "    \n",
    "    if backend_props:\n",
    "        print(\"=\" * 70)\n",
    "        print(\"BACKEND CALIBRATION DATA\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Backend name:       {backend_props.get('backend_name', 'N/A')}\")\n",
    "        print(f\"Calibration time:   {backend_props.get('calibration_timestamp', 'N/A')}\")\n",
    "        print()\n",
    "        \n",
    "        # Qubit properties\n",
    "        qubits = backend_props.get('qubits', [])\n",
    "        if qubits:\n",
    "            print(\"Qubit Properties (first 5 qubits):\")\n",
    "            print(f\"{'Qubit':<8} {'T1 (μs)':<12} {'T2 (μs)':<12} {'Readout Error':<15}\")\n",
    "            print(\"-\" * 50)\n",
    "            for i, q in enumerate(qubits[:5]):\n",
    "                t1 = q.get('T1', 0) * 1e6  # Convert to μs\n",
    "                t2 = q.get('T2', 0) * 1e6\n",
    "                ro_err = q.get('readout_error', 0)\n",
    "                print(f\"{i:<8} {t1:<12.2f} {t2:<12.2f} {ro_err:<15.4f}\")\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "    else:\n",
    "        print(\"No backend properties found (simulator backend).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Shot Efficiency Analysis\n",
    "\n",
    "Compare shadow-based QAOA to standard measurement-based QAOA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if convergence_data:\n",
    "    shadow_size = convergence_data['shadow_size']\n",
    "    iterations = convergence_data['final_results']['iterations']\n",
    "    \n",
    "    # Shadow-based shots\n",
    "    shadow_total_shots = shadow_size * iterations\n",
    "    \n",
    "    # Standard QAOA baseline (from literature/assumptions)\n",
    "    # Typically: 1000 shots/iteration, 60-80 iterations\n",
    "    standard_shots_per_iter = 1000\n",
    "    standard_iterations = 60  # Baseline estimate\n",
    "    standard_total_shots = standard_shots_per_iter * standard_iterations\n",
    "    \n",
    "    # Compute metrics\n",
    "    shot_reduction = (1 - shadow_total_shots / standard_total_shots) * 100\n",
    "    step_reduction = (1 - iterations / standard_iterations) * 100\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"SHOT EFFICIENCY COMPARISON\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Metric':<30} {'Standard QAOA':<20} {'Shadow QAOA':<20}\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Shots per iteration':<30} {standard_shots_per_iter:<20} {shadow_size:<20}\")\n",
    "    print(f\"{'Iterations to convergence':<30} {standard_iterations:<20} {iterations:<20}\")\n",
    "    print(f\"{'Total shots':<30} {standard_total_shots:<20} {shadow_total_shots:<20}\")\n",
    "    print()\n",
    "    print(f\"Shot reduction:        {shot_reduction:>6.1f}%\")\n",
    "    print(f\"Step reduction:        {step_reduction:>6.1f}% (target: ≥20%)\")\n",
    "    print()\n",
    "    \n",
    "    # Success criteria\n",
    "    approx_ratio = convergence_data['final_results']['approx_ratio']\n",
    "    approx_pass = approx_ratio >= 0.90\n",
    "    step_pass = step_reduction >= 20.0\n",
    "    \n",
    "    print(\"Phase 1 Success Criteria:\")\n",
    "    print(f\"  Approx Ratio ≥ 0.90:   {'✓ PASS' if approx_pass else '✗ FAIL'} ({approx_ratio:.4f})\")\n",
    "    print(f\"  Step Reduction ≥ 20%:  {'✓ PASS' if step_pass else '✗ FAIL'} ({step_reduction:.1f}%)\")\n",
    "    print(f\"  Manifest Generated:    ✓ PASS\")\n",
    "    print(f\"  Convergence Logged:    ✓ PASS\")\n",
    "    print()\n",
    "    \n",
    "    if approx_pass and step_pass:\n",
    "        print(\"✅ O-T01 PASSED - Phase 1 optimization workstream validated!\")\n",
    "    else:\n",
    "        print(\"⚠️  O-T01 PARTIAL PASS - Review convergence and consider parameter tuning\")\n",
    "    \n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multi-Trial Comparison (Optional)\n",
    "\n",
    "If multiple trials were run, compare their convergence behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple trials if available\n",
    "log_files = list((data_dir / \"logs\").glob(\"o-t01-trial-*-convergence.json\"))\n",
    "\n",
    "if len(log_files) > 1:\n",
    "    print(f\"Found {len(log_files)} trials. Loading all...\")\n",
    "    \n",
    "    trials_data = []\n",
    "    for log_file in log_files:\n",
    "        with log_file.open(\"r\") as f:\n",
    "            trial = json.load(f)\n",
    "            trials_data.append(trial)\n",
    "    \n",
    "    # Compare final results\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"MULTI-TRIAL COMPARISON\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Trial':<10} {'Approx Ratio':<15} {'Iterations':<15} {'Total Time':<15}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    approx_ratios = []\n",
    "    for trial in trials_data:\n",
    "        trial_id = trial.get('trial_id', 'N/A')\n",
    "        final = trial['final_results']\n",
    "        approx_ratios.append(final['approx_ratio'])\n",
    "        print(f\"{trial_id:<10} {final['approx_ratio']:<15.4f} \"\n",
    "              f\"{final['iterations']:<15} {final['total_time']:<15.2f}\")\n",
    "    \n",
    "    print()\n",
    "    print(f\"Mean approx ratio:     {np.mean(approx_ratios):.4f} ± {np.std(approx_ratios):.4f}\")\n",
    "    print(f\"Min/Max:               {np.min(approx_ratios):.4f} / {np.max(approx_ratios):.4f}\")\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"Only one trial found. Run multiple trials for statistical comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results\n",
    "\n",
    "Save summary for Phase 1 gate review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if convergence_data:\n",
    "    # Create summary report\n",
    "    summary = {\n",
    "        \"experiment_id\": \"O-T01\",\n",
    "        \"workstream\": \"Optimization\",\n",
    "        \"backend\": convergence_data['backend'],\n",
    "        \"shadow_size\": shadow_size,\n",
    "        \"final_results\": convergence_data['final_results'],\n",
    "        \"phase1_criteria\": {\n",
    "            \"approx_ratio_pass\": approx_pass,\n",
    "            \"step_reduction_pass\": step_pass,\n",
    "            \"overall_pass\": approx_pass and step_pass,\n",
    "        },\n",
    "        \"shot_efficiency\": {\n",
    "            \"shadow_total_shots\": shadow_total_shots,\n",
    "            \"standard_baseline_shots\": standard_total_shots,\n",
    "            \"shot_reduction_percent\": shot_reduction,\n",
    "            \"step_reduction_percent\": step_reduction,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    output_path = data_dir.parent / \"results\" / \"o-t01-summary.json\"\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with output_path.open(\"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n✅ Summary exported to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "**If O-T01 PASSED:**\n",
    "- Include in Phase 1 gate review as optimization workstream validation\n",
    "- Plan O-T02 (larger graphs, p=2-3)\n",
    "- Draft Shadow-VQE patent claims\n",
    "\n",
    "**If O-T01 needs improvement:**\n",
    "- Increase shadow_size (300 → 500)\n",
    "- Try different optimizer (SLSQP vs COBYLA)\n",
    "- Run additional trials for statistical confidence\n",
    "- Try p=2 ansatz for better approximation ratio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
