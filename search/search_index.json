{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"QuartumSE Documentation","text":"<p>Welcome to the QuartumSE documentation site. This MkDocs-powered hub follows the same narrative as the repository:</p> <ol> <li>Install &amp; verify the SDK locally.</li> <li>Run baseline experiments on Aer or IBM Runtime.</li> <li>Automate campaigns with reporting and provenance capture.</li> <li>Dig into architecture and theory as you extend the platform.</li> </ol> <p>Use the navigation to jump directly to tutorials, how-to guides, explanation notes, and operational runbooks. Each section is kept intentionally focused so new contributors can follow a linear path from installation to production-grade experiments.</p> <p>Looking for API details? Head to the Reference section. Need the strategic context? See the Roadmap and Project Bible.</p>"},{"location":"archive/","title":"Archive","text":"<p>Historical documentation and experiment starter scripts have been removed as of October 2025 to streamline the repository and improve navigation for new users.</p>"},{"location":"archive/#what-was-removed","title":"What was removed","text":""},{"location":"archive/#documentation-archives","title":"Documentation Archives","text":"<ul> <li><code>docs/archive/bootstrap_summary_20251020.md</code> - Bootstrap phase summary</li> <li><code>docs/archive/status_report_20251022.md</code> - Phase 1 status report</li> <li><code>docs/archive/strategic_analysis_20251021.md</code> - Strategic analysis</li> </ul>"},{"location":"archive/#experiment-starter-scripts","title":"Experiment Starter Scripts","text":"<ul> <li><code>experiments/archive/benchmarking/B_T01_rb_starter.py</code> - Randomized benchmarking starter</li> <li><code>experiments/archive/chemistry/C_T01_h2_vqe_starter.py</code> - H\u2082 VQE starter</li> <li><code>experiments/archive/metrology/M_T01_ghz_phase_starter.py</code> - GHZ phase metrology starter</li> <li><code>experiments/archive/optimization/O_T01_maxcut_starter.py</code> - MaxCut optimization starter</li> </ul>"},{"location":"archive/#archived-notebooks","title":"Archived Notebooks","text":"<ul> <li><code>notebooks/archive/preliminary_smoke_test.ipynb</code> - Early smoke test (superseded by <code>notebooks/comprehensive_test_suite.ipynb</code>)</li> <li><code>notebooks/archive/review_smoke_test_results.ipynb</code> - Smoke test analysis</li> <li><code>notebooks/archive/s_t01_ghz_classical_shadows.ipynb</code> - Old S-T01 notebook</li> </ul>"},{"location":"archive/#accessing-archived-content","title":"Accessing archived content","text":"<p>All removed files remain accessible in the Git history. To retrieve archived content:</p> <p>View list of archived files: <pre><code>git show fa5e756 --name-only --diff-filter=D\n</code></pre></p> <p>Restore a specific archived file to your working directory: <pre><code># Example: restore the bootstrap summary\ngit show fa5e756:docs/archive/bootstrap_summary_20251020.md &gt; bootstrap_summary.md\n</code></pre></p> <p>Check out the repository state before archive removal: <pre><code>git checkout fa5e756^  # One commit before removal\n</code></pre></p> <p>Browse archived files on GitHub: Visit the commit directly: fa5e756</p>"},{"location":"archive/#current-documentation-structure","title":"Current documentation structure","text":"<p>For up-to-date documentation, see:</p> <ul> <li>Documentation index - Complete navigation guide</li> <li>Tutorials - Getting started guides</li> <li>How-to guides - Task-oriented walkthroughs</li> <li>Explanation - Deep dives into architecture and theory</li> <li>Strategy - Project roadmap and planning</li> </ul>"},{"location":"archive/#superseding-resources","title":"Superseding resources","text":"<p>Content from archived materials has been integrated into current documentation:</p> <ul> <li>Bootstrap &amp; status reports \u2192 Phase 1 Task Checklist</li> <li>Strategic analysis \u2192 Project Bible and Roadmap</li> <li>Starter experiments \u2192 Shadow experiments directory in repository root (<code>experiments/shadows/</code>)</li> <li>Old notebooks \u2192 Current notebooks in repository root (<code>notebooks/</code>) with comprehensive test suite</li> </ul> <p>If you need specific information from archived files that isn't covered in current docs, please open a discussion or file an issue.</p>"},{"location":"explanation/architecture/","title":"Architecture","text":"<p>An overview of the QuartumSE system architecture will be provided here.</p>"},{"location":"explanation/manifest-schema/","title":"QuartumSE Data Storage Conventions","text":"<p>This document explains the data directory structure and when to use each directory. By default, <code>ShadowEstimator</code> writes manifests and Parquet files under <code>./data</code> unless you override <code>data_dir</code>.</p>"},{"location":"explanation/manifest-schema/#directory-overview","title":"Directory Overview","text":"<pre><code>QuartumSE/\n\u251c\u2500\u2500 data/                  # Production experiment data\n\u251c\u2500\u2500 validation_data/       # Phase 1 validation &amp; smoke tests\n\u251c\u2500\u2500 demo_data/             # Notebook demos &amp; tutorials\n\u251c\u2500\u2500 notebook_data/         # Interactive notebook experimentation\n\u2514\u2500\u2500 experiments/validation/archived_runs/  # Archived validation results\n</code></pre>"},{"location":"explanation/manifest-schema/#when-to-use-each-directory","title":"When to Use Each Directory","text":""},{"location":"explanation/manifest-schema/#data-production-experiments","title":"<code>data/</code> - Production Experiments","text":"<p>Use for: - Final, production-quality experiments - Data intended for publication or reports - Long-term archival - Experiments in workstreams C/O/B/M (Chemistry, Optimization, Benchmarking, Metrology)</p> <p>Examples: <pre><code>estimator = ShadowEstimator(backend=\"ibm:ibm_torino\", data_dir=\"data\")\n</code></pre></p> <p>Retention: Keep indefinitely, archive carefully</p>"},{"location":"explanation/manifest-schema/#validation_data-phase-1-validation-testing","title":"<code>validation_data/</code> - Phase 1 Validation &amp; Testing","text":"<p>Use for: - Hardware validation experiments (S-T01, S-T02, etc.) - Smoke tests on IBM hardware - SSR verification experiments - Phase 1 exit criteria validation - Shadow experiment scripts (<code>experiments/shadows/*/run_*.py</code>)</p> <p>Scripts/notebooks that use this: - <code>experiments/shadows/preliminary_test/run_smoke_test.py</code> - <code>experiments/validation/hardware_validation.py</code> - <code>experiments/shadows/extended_ghz/run_ghz_extended.py</code> - <code>experiments/shadows/parallel_bell_pairs/run_bell_pairs.py</code> - Hardware sections of <code>notebooks/comprehensive_test_suite.ipynb</code></p> <p>Examples: <pre><code>estimator = ShadowEstimator(backend=\"ibm:ibm_torino\", data_dir=\"validation_data\")\n</code></pre></p> <p>Retention: - Keep during Phase 1 validation period - Archive successful runs to <code>experiments/validation/archived_runs/</code> - Move final validation results to <code>data/</code> for publication</p>"},{"location":"explanation/manifest-schema/#demo_data-demos-tutorials","title":"<code>demo_data/</code> - Demos &amp; Tutorials","text":"<p>Use for: - Notebook demonstrations - Quickstart examples - Tutorial walkthroughs - Non-critical testing</p> <p>Notebooks that use this: - <code>notebooks/quickstart_shot_persistence.ipynb</code> - <code>notebooks/comprehensive_test_suite.ipynb</code> - <code>notebooks/noise_aware_shadows_demo.ipynb</code></p> <p>Examples: <pre><code>estimator = ShadowEstimator(backend=AerSimulator(), data_dir=\"demo_data\")\n</code></pre></p> <p>Retention: Ephemeral - safe to delete at any time</p>"},{"location":"explanation/manifest-schema/#notebook_data-interactive-notebooks","title":"<code>notebook_data/</code> - Interactive Notebooks","text":"<p>Use for: - Jupyter notebook experimentation - Development and debugging - Exploratory data analysis - One-off interactive tests</p> <p>Examples: <pre><code>estimator = ShadowEstimator(backend=\"ibm:ibm_torino\", data_dir=\"notebook_data\")\n</code></pre></p> <p>Retention: Ephemeral - safe to delete at any time</p>"},{"location":"explanation/manifest-schema/#directory-structure","title":"Directory Structure","text":"<p>All data directories follow the same subdirectory structure:</p> <pre><code>{data_dir}/\n\u251c\u2500\u2500 manifests/          # Provenance manifests (JSON)\n\u2502   \u2514\u2500\u2500 {experiment_id}.json\n\u251c\u2500\u2500 shots/              # Raw measurement data (Parquet)\n\u2502   \u2514\u2500\u2500 {experiment_id}.parquet\n\u251c\u2500\u2500 reports/            # Generated reports (HTML/PDF)\n\u2502   \u2514\u2500\u2500 {experiment_id}_report.html\n\u2514\u2500\u2500 calibrations/       # MEM confusion matrices (optional)\n    \u2514\u2500\u2500 {experiment_id}_confusion.json\n</code></pre> <p>See <code>data/README.md</code> in the repository for detailed schema documentation.</p>"},{"location":"explanation/manifest-schema/#git-tracking","title":"Git Tracking","text":"<p>All data directories are git-ignored except for: - \u2705 <code>README.md</code> files (documentation) - \u2705 <code>.gitkeep</code> files (preserve empty directories) - \u274c JSON manifests (ignored) - \u274c Parquet shot data (ignored) - \u274c HTML/PDF reports (ignored)</p> <p>Reason: Experimental data files are large and change frequently. Only code and documentation are version-controlled.</p>"},{"location":"explanation/manifest-schema/#quick-commands","title":"Quick Commands","text":""},{"location":"explanation/manifest-schema/#create-all-directories","title":"Create all directories:","text":"<pre><code>mkdir -p data/{manifests,shots,reports,calibrations}\nmkdir -p validation_data/{manifests,shots,reports,calibrations}\nmkdir -p demo_data\nmkdir -p notebook_data\n</code></pre>"},{"location":"explanation/manifest-schema/#clean-validation-data","title":"Clean validation data:","text":"<pre><code>rm -rf validation_data/{manifests,shots,reports,calibrations}/*\n</code></pre>"},{"location":"explanation/manifest-schema/#clean-demonotebook-data","title":"Clean demo/notebook data:","text":"<pre><code>rm -rf demo_data/* notebook_data/*\n</code></pre>"},{"location":"explanation/manifest-schema/#list-all-experiments-by-directory","title":"List all experiments by directory:","text":"<pre><code>ls -lh data/manifests/           # Production\nls -lh validation_data/manifests/ # Validation\nls -lh demo_data/manifests/      # Demos\n</code></pre>"},{"location":"explanation/manifest-schema/#check-total-data-usage","title":"Check total data usage:","text":"<pre><code>du -sh data/ validation_data/ demo_data/ notebook_data/\n</code></pre>"},{"location":"explanation/manifest-schema/#storage-estimates","title":"Storage Estimates","text":""},{"location":"explanation/manifest-schema/#phase-1-6-validation-experiments","title":"Phase 1 (6 validation experiments):","text":"<ul> <li>validation_data/: ~1.6 MB</li> <li>data/: ~0 MB (not used yet)</li> </ul>"},{"location":"explanation/manifest-schema/#phase-2-production-workloads","title":"Phase 2+ (Production workloads):","text":"<ul> <li>data/: ~50-100 MB per workstream (C/O/B/M)</li> <li>validation_data/: Archived after Phase 1</li> </ul>"},{"location":"explanation/manifest-schema/#per-experiment","title":"Per Experiment:","text":"<ul> <li>Manifest: ~10 KB</li> <li>Shot data (500 shots, 3 qubits): ~50-100 KB</li> <li>Report: ~50 KB</li> <li>Total per experiment: ~100-200 KB</li> </ul>"},{"location":"explanation/manifest-schema/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Always specify <code>data_dir</code> explicitly in scripts:    <pre><code># Good\nestimator = ShadowEstimator(..., data_dir=\"validation_data\")\n\n# Bad (default may change)\nestimator = ShadowEstimator(...)\n</code></pre></p> </li> <li> <p>Use appropriate directory for purpose:</p> </li> <li>Production \u2192 <code>data/</code></li> <li>Validation/testing \u2192 <code>validation_data/</code></li> <li>Demos \u2192 <code>demo_data/</code></li> <li> <p>Notebooks \u2192 <code>notebook_data/</code></p> </li> <li> <p>Archive validation results after Phase 1:    <pre><code>cp validation_data/manifests/final_validation.json \\\n   experiments/validation/archived_runs/results_final.txt\n</code></pre></p> </li> <li> <p>Clean temporary directories regularly:    <pre><code># Weekly cleanup\nrm -rf demo_data/* notebook_data/*\n</code></pre></p> </li> <li> <p>Check storage usage before long experiment runs:    <pre><code>df -h .  # Check available disk space\ndu -sh validation_data/  # Check current usage\n</code></pre></p> </li> </ol>"},{"location":"explanation/manifest-schema/#faq","title":"FAQ","text":"<p>Q: Which directory should I use for the preliminary smoke test? A: <code>validation_data/</code> - it's part of Phase 1 validation.</p> <p>Q: Can I move experiments between directories? A: Yes! Manifests and shot data are self-contained. Just copy/move the files: <pre><code>mv validation_data/manifests/{id}.json data/manifests/\nmv validation_data/shots/{id}.parquet data/shots/\n</code></pre></p> <p>Q: What if I accidentally delete a data directory? A: All directories auto-create subdirectories when needed. Just re-run your experiment or manually recreate: <pre><code>mkdir -p validation_data/{manifests,shots,reports,calibrations}\n</code></pre></p> <p>Q: How do I back up my validation data? A: Copy the entire directory: <pre><code>cp -r validation_data/ validation_data_backup_$(date +%Y%m%d)\n</code></pre></p> <p>Q: Why are Parquet files ignored by git? A: They're binary files that can be large (MBs) and change frequently. Git is optimized for text files (code, docs).</p> <p>Last Updated: 2025-10-22 QuartumSE Version: 0.1.0</p>"},{"location":"explanation/shadows-theory/","title":"Shadows Theory","text":"<p>Background theory and rationale for QuartumSE shadow experiments will be described on this page.</p>"},{"location":"how-to/generate-report/","title":"Generate Experiment Reports","text":"<p>QuartumSE can generate self-contained HTML reports from saved manifests, providing human-readable experiment summaries with full provenance details.</p>"},{"location":"how-to/generate-report/#overview","title":"Overview","text":"<p>Report contents: - Experiment metadata (ID, timestamp, versions) - Circuit visualization and fingerprint - Backend calibration snapshot - Observable estimates with confidence intervals - Shot data diagnostics (basis distribution, bitstring histogram) - Mitigation configuration (MEM, ZNE settings) - Resource usage (shots, execution time)</p> <p>Formats: - HTML (default) - Self-contained, viewable in any browser - PDF (future) - Requires <code>weasyprint</code> (not yet implemented)</p>"},{"location":"how-to/generate-report/#quick-start","title":"Quick Start","text":""},{"location":"how-to/generate-report/#generate-html-report-cli","title":"Generate HTML Report (CLI)","text":"<p>Unix/macOS: <pre><code>quartumse report data/manifests/a3f2b1c4-5678-90ab-cdef-1234567890ab.json \\\n  --output reports/experiment_report.html\n</code></pre></p> <p>Windows: <pre><code>quartumse report data/manifests/a3f2b1c4-5678-90ab-cdef-1234567890ab.json `\n  --output reports/experiment_report.html\n</code></pre></p> <p>Output: <pre><code>Generating report from data/manifests/a3f2b1c4-5678-90ab-cdef-1234567890ab.json...\nReport saved to reports/experiment_report.html\n</code></pre></p> <p>Open in browser:</p> <p>Unix/macOS: <pre><code>open reports/experiment_report.html\n</code></pre></p> <p>Windows: <pre><code>Start-Process reports/experiment_report.html\n</code></pre></p> <p>Linux: <pre><code>xdg-open reports/experiment_report.html\n</code></pre></p>"},{"location":"how-to/generate-report/#using-python-api","title":"Using Python API","text":""},{"location":"how-to/generate-report/#basic-report-generation","title":"Basic Report Generation","text":"<pre><code>from quartumse.reporting import ReportGenerator\n\n# Load manifest and generate report\nreport = ReportGenerator.from_manifest_file(\n    \"data/manifests/a3f2b1c4-5678-90ab-cdef-1234567890ab.json\"\n)\n\n# Save as HTML\nreport.to_html(\"reports/experiment_report.html\")\n\nprint(\"Report generated successfully!\")\n</code></pre>"},{"location":"how-to/generate-report/#customizing-report-content","title":"Customizing Report Content","text":"<pre><code>from quartumse.reporting import ReportGenerator\nfrom pathlib import Path\n\nmanifest_path = \"data/manifests/a3f2b1c4-5678-90ab-cdef-1234567890ab.json\"\n\n# Create report with custom title\nreport = ReportGenerator.from_manifest_file(manifest_path)\nreport.title = \"GHZ State Validation - Phase 1\"\nreport.description = \"Classical shadows v0 baseline on 3-qubit GHZ state\"\n\n# Add custom metadata\nreport.add_metadata(\"Experiment Group\", \"Phase 1 Validation\")\nreport.add_metadata(\"Researcher\", \"QuartumSE Team\")\nreport.add_metadata(\"Status\", \"PASSED \u2713\")\n\n# Generate output\noutput_path = Path(\"reports/ghz_phase1_report.html\")\noutput_path.parent.mkdir(parents=True, exist_ok=True)\nreport.to_html(str(output_path))\n\nprint(f\"Custom report saved: {output_path}\")\n</code></pre>"},{"location":"how-to/generate-report/#batch-report-generation","title":"Batch Report Generation","text":"<p>Generate reports for all experiments in a directory:</p> <p>Unix/macOS: <pre><code>for manifest in data/manifests/*.json; do\n  base=$(basename \"$manifest\" .json)\n  quartumse report \"$manifest\" --output \"reports/${base}_report.html\"\n  echo \"Generated: reports/${base}_report.html\"\ndone\n</code></pre></p> <p>Windows (PowerShell): <pre><code>Get-ChildItem data/manifests/*.json | ForEach-Object {\n  $base = $_.BaseName\n  quartumse report $_.FullName --output \"reports/${base}_report.html\"\n  Write-Host \"Generated: reports/${base}_report.html\"\n}\n</code></pre></p> <p>Python script: <pre><code>from pathlib import Path\nfrom quartumse.reporting import ReportGenerator\n\nmanifest_dir = Path(\"data/manifests\")\nreport_dir = Path(\"reports\")\nreport_dir.mkdir(parents=True, exist_ok=True)\n\nfor manifest_path in sorted(manifest_dir.glob(\"*.json\")):\n    try:\n        report = ReportGenerator.from_manifest_file(str(manifest_path))\n\n        output_name = f\"{manifest_path.stem}_report.html\"\n        output_path = report_dir / output_name\n\n        report.to_html(str(output_path))\n        print(f\"\u2713 Generated: {output_name}\")\n\n    except Exception as e:\n        print(f\"\u2717 Failed: {manifest_path.name} - {e}\")\n\nprint(f\"\\nTotal reports generated: {len(list(report_dir.glob('*.html')))}\")\n</code></pre></p>"},{"location":"how-to/generate-report/#report-structure","title":"Report Structure","text":""},{"location":"how-to/generate-report/#section-1-experiment-overview","title":"Section 1: Experiment Overview","text":"<ul> <li>Experiment ID: Unique UUID for traceability</li> <li>Created: ISO timestamp</li> <li>Backend: Device name and qubit count</li> <li>Shadow Version: v0 (baseline), v1 (noise-aware), etc.</li> <li>Shadow Size: Number of random measurements</li> <li>Execution Time: Wall-clock time for quantum execution</li> </ul>"},{"location":"how-to/generate-report/#section-2-circuit-details","title":"Section 2: Circuit Details","text":"<ul> <li>Num Qubits: Circuit width</li> <li>Depth: Gate depth</li> <li>Gate Counts: Breakdown by gate type (H, CNOT, etc.)</li> <li>Circuit Hash: SHA-256 fingerprint for reproducibility</li> <li>Circuit Visualization: (if available)</li> </ul>"},{"location":"how-to/generate-report/#section-3-observable-results","title":"Section 3: Observable Results","text":"<p>Table with columns: - Observable: Pauli string (e.g., <code>ZII</code>, <code>ZZZ</code>) - Expectation Value: Estimated mean - Variance: Estimation variance - 95% CI: Confidence interval bounds - CI Width: Interval width (precision measure)</p>"},{"location":"how-to/generate-report/#section-4-shot-data-diagnostics","title":"Section 4: Shot Data Diagnostics","text":"<p>Measurement Basis Distribution: - Histogram showing X/Y/Z measurement frequencies per qubit - Should be uniform (~33% each) for random Clifford shadows</p> <p>Top Bitstrings: - Most frequent measurement outcomes - Useful for debugging unexpected distributions</p> <p>Qubit Marginals: - Per-qubit P(|0\u27e9) probabilities - Should be ~0.5 for maximally entangled states</p>"},{"location":"how-to/generate-report/#section-5-mitigation-configuration","title":"Section 5: Mitigation Configuration","text":"<ul> <li>Techniques: MEM, ZNE, etc.</li> <li>MEM Confusion Matrix Path: (if applicable)</li> <li>MEM Shots per State: Calibration budget</li> <li>Qubits Calibrated: Indices of calibrated qubits</li> </ul>"},{"location":"how-to/generate-report/#section-6-backend-calibration","title":"Section 6: Backend Calibration","text":"<ul> <li>Calibration Timestamp: When device properties were captured</li> <li>T1 Times: (if available) Decay times per qubit</li> <li>T2 Times: (if available) Dephasing times per qubit</li> <li>Readout Errors: (if available) Measurement error rates</li> <li>Properties Hash: SHA-256 of full calibration JSON</li> </ul>"},{"location":"how-to/generate-report/#section-7-provenance","title":"Section 7: Provenance","text":"<ul> <li>QuartumSE Version: Package version used</li> <li>Qiskit Version: Qiskit version used</li> <li>Python Version: Python interpreter version</li> <li>Random Seed: (if set) For reproducibility</li> <li>Tags: User-defined searchable tags</li> </ul>"},{"location":"how-to/generate-report/#report-output-locations","title":"Report Output Locations","text":""},{"location":"how-to/generate-report/#default-behavior","title":"Default Behavior","text":"<p>When using the experiment API (<code>estimator.estimate(save_manifest=True)</code>), no report is auto-generated. Use the CLI or Python API to generate reports from saved manifests. If you ran experiments with a custom <code>--data-dir</code>, substitute that path for the default <code>data/</code> directory referenced below.</p>"},{"location":"how-to/generate-report/#recommended-structure","title":"Recommended Structure","text":"<pre><code>quartumse/\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 manifests/           # JSON manifests\n\u2502   \u2502   \u251c\u2500\u2500 a3f2b1c4-....json\n\u2502   \u2502   \u2514\u2500\u2500 b5e8f9d2-....json\n\u2502   \u251c\u2500\u2500 shots/               # Parquet shot data\n\u2502   \u2502   \u251c\u2500\u2500 a3f2b1c4-....parquet\n\u2502   \u2502   \u2514\u2500\u2500 b5e8f9d2-....parquet\n\u2502   \u2514\u2500\u2500 mem/                 # MEM confusion matrices\n\u2502       \u251c\u2500\u2500 a3f2b1c4-....npz\n\u2502       \u2514\u2500\u2500 b5e8f9d2-....npz\n\u2514\u2500\u2500 reports/                 # HTML reports (gitignored)\n    \u251c\u2500\u2500 a3f2b1c4-...._report.html\n    \u2514\u2500\u2500 b5e8f9d2-...._report.html\n</code></pre>"},{"location":"how-to/generate-report/#advanced-programmatic-report-analysis","title":"Advanced: Programmatic Report Analysis","text":"<p>Extract key metrics from reports for comparison:</p> <pre><code>import json\nfrom pathlib import Path\nimport pandas as pd\n\ndef extract_metrics_from_manifest(manifest_path):\n    \"\"\"Extract key metrics from manifest JSON.\"\"\"\n    with open(manifest_path, 'r') as f:\n        manifest = json.load(f)\n\n    metrics = {\n        'experiment_id': manifest['experiment_id'],\n        'backend': manifest['backend']['backend_name'],\n        'shadow_size': manifest['shadows']['shadow_size'],\n        'shadow_version': manifest['shadows']['version'],\n        'num_qubits': manifest['circuit']['num_qubits'],\n        'execution_time': manifest.get('resource_usage', {}).get('quantum_execution_seconds', None),\n    }\n\n    # Extract observable results\n    for obs_str, obs_data in manifest.get('results_summary', {}).items():\n        metrics[f'obs_{obs_str}_expectation'] = obs_data.get('expectation_value')\n        metrics[f'obs_{obs_str}_ci_width'] = obs_data.get('ci_width')\n\n    return metrics\n\n# Process all manifests\nmanifest_dir = Path(\"data/manifests\")\nall_metrics = [extract_metrics_from_manifest(p) for p in manifest_dir.glob(\"*.json\")]\n\n# Convert to DataFrame for analysis\ndf = pd.DataFrame(all_metrics)\n\n# Compare by backend\nprint(\"\\nMetrics by Backend:\")\nprint(df.groupby('backend')['shadow_size'].agg(['mean', 'min', 'max', 'count']))\n\n# Compare by shadow version\nprint(\"\\nMetrics by Shadow Version:\")\nprint(df.groupby('shadow_version')['execution_time'].agg(['mean', 'median', 'std']))\n</code></pre>"},{"location":"how-to/generate-report/#pdf-reports-future","title":"PDF Reports (Future)","text":"<p>PDF generation is planned for Phase 2. It will require the <code>weasyprint</code> package:</p> <p>Installation (when implemented): <pre><code>pip install quartumse[reporting]\n</code></pre></p> <p>Usage (planned API): <pre><code>from quartumse.reporting import ReportGenerator\n\nreport = ReportGenerator.from_manifest_file(\"data/manifests/experiment.json\")\nreport.to_pdf(\"reports/experiment_report.pdf\")  # Not yet implemented\n</code></pre></p> <p>Current workaround: 1. Generate HTML report 2. Open in browser 3. Print to PDF using browser's print dialog</p>"},{"location":"how-to/generate-report/#troubleshooting","title":"Troubleshooting","text":"<p>\"Manifest file not found\" - Check path is correct (absolute or relative) - Verify experiment completed and saved manifest - Use <code>ls data/manifests/</code> to list available manifests</p> <p>\"cannot import name 'generate_html_report'\" - Use <code>ReportGenerator</code> class instead (new API) - Old function name removed in favor of class-based API - Update code: <code>ReportGenerator.from_manifest_file(path).to_html(output)</code></p> <p>\"Shot data file not found\" - Report includes shot diagnostics if shot data exists - Gracefully degrades if shot data missing (shows warning) - Check <code>manifest['shot_data_path']</code> points to valid Parquet file</p> <p>\"Template not found\" - Report templates bundled with package - If error persists, reinstall: <code>pip install --force-reinstall quartumse</code></p> <p>\"Report HTML not rendering properly\" - Open in modern browser (Chrome, Firefox, Safari, Edge) - Check for JavaScript errors in browser console - Verify HTML file wasn't corrupted during generation</p> <p>\"Report generation slow (&gt;5 seconds)\" - Check shot data file size (should be &lt;10MB for typical experiments) - Verify no network I/O (all files should be local) - Report generation should complete in &lt;1 second normally</p>"},{"location":"how-to/generate-report/#related","title":"Related","text":"<ul> <li>Run S-T01 GHZ - Generate manifests worth reporting</li> <li>Replay from Manifest - Re-analyze before reporting</li> <li>Manifest Schema - Full manifest specification</li> </ul>"},{"location":"how-to/replay-from-manifest/","title":"Replay from Manifest","text":"<p>QuartumSE's \"measure once, ask later\" capability lets you compute new observable estimates from saved measurement data without re-executing on quantum hardware.</p>"},{"location":"how-to/replay-from-manifest/#overview","title":"Overview","text":"<p>Why replay? - Zero hardware cost - No additional quantum shots needed - Instant results - Compute new observables in seconds - Reproducibility - Same data, different analysis - Exploration - Test hypotheses without waiting for hardware queue</p> <p>What's replayable: - Shadow measurement outcomes (bitstrings + bases) - MEM confusion matrices (for v1 noise-aware shadows) - Backend calibration snapshots - Circuit fingerprints and random seeds - Output directory is configurable; if you ran experiments with   <code>--data-dir=/path/to/artifacts</code> the manifest and shot data live underneath   that directory instead of the default <code>data/</code> tree.</p>"},{"location":"how-to/replay-from-manifest/#quick-start","title":"Quick Start","text":""},{"location":"how-to/replay-from-manifest/#basic-replay-python-api","title":"Basic Replay (Python API)","text":"<pre><code>from quartumse import ShadowEstimator\nfrom quartumse.shadows.core import Observable\n\n# Original experiment saved manifest to: data/manifests/a3f2b1c4...json\n\n# Create estimator (backend not used during replay)\nestimator = ShadowEstimator(backend=\"aer_simulator\")\n\n# Define NEW observables (different from original run)\nnew_observables = [\n    Observable(\"XX\", coefficient=1.0),\n    Observable(\"YY\", coefficient=1.0),\n    Observable(\"ZZ\", coefficient=1.0),\n]\n\n# Replay from saved manifest\nresult = estimator.replay_from_manifest(\n    manifest_path=\"data/manifests/a3f2b1c4-5678-90ab-cdef-1234567890ab.json\",\n    observables=new_observables\n)\n\n# Access results (same structure as estimate())\nfor obs_str, data in result.observables.items():\n    exp_val = data['expectation_value']\n    variance = data['variance']\n    ci = data['ci_95']\n    ci_width = data['ci_width']\n\n    print(f\"{obs_str}:\")\n    print(f\"  Value: {exp_val:.4f} \u00b1 {np.sqrt(variance):.4f}\")\n    print(f\"  95% CI: [{ci[0]:.3f}, {ci[1]:.3f}] (width: {ci_width:.3f})\")\n</code></pre> <p>Output: <pre><code>1.0*XX:\n  Value: 0.9844 \u00b1 0.0312\n  95% CI: [0.923, 1.046] (width: 0.123)\n1.0*YY:\n  Value: 0.9922 \u00b1 0.0289\n  95% CI: [0.936, 1.048] (width: 0.113)\n1.0*ZZ:\n  Value: 1.0039 \u00b1 0.0156\n  95% CI: [0.973, 1.035] (width: 0.061)\n</code></pre></p>"},{"location":"how-to/replay-from-manifest/#finding-manifests","title":"Finding Manifests","text":""},{"location":"how-to/replay-from-manifest/#list-saved-experiments","title":"List saved experiments","text":"<p>Unix/macOS: <pre><code>ls -lt data/manifests/ | head -10\n</code></pre></p> <p>Windows: <pre><code>Get-ChildItem data/manifests/ | Sort-Object LastWriteTime -Descending | Select-Object -First 10\n</code></pre></p>"},{"location":"how-to/replay-from-manifest/#inspect-manifest-metadata","title":"Inspect manifest metadata","text":"<pre><code>import json\n\nmanifest_path = \"data/manifests/a3f2b1c4-5678-90ab-cdef-1234567890ab.json\"\n\nwith open(manifest_path, 'r') as f:\n    manifest = json.load(f)\n\nprint(f\"Experiment ID: {manifest['experiment_id']}\")\nprint(f\"Created: {manifest['created_at']}\")\nprint(f\"Backend: {manifest['backend']['backend_name']}\")\nprint(f\"Shadow size: {manifest['shadows']['shadow_size']}\")\nprint(f\"Circuit qubits: {manifest['circuit']['num_qubits']}\")\nprint(f\"Original observables: {[obs['pauli'] for obs in manifest['observables']]}\")\n</code></pre> <p>Output: <pre><code>Experiment ID: a3f2b1c4-5678-90ab-cdef-1234567890ab\nCreated: 2025-10-29T14:32:15.789012\nBackend: aer_simulator\nShadow size: 256\nCircuit qubits: 3\nOriginal observables: ['ZII', 'ZZI', 'ZZZ']\n</code></pre></p>"},{"location":"how-to/replay-from-manifest/#complete-replay-example","title":"Complete Replay Example","text":""},{"location":"how-to/replay-from-manifest/#step-1-run-original-experiment","title":"Step 1: Run Original Experiment","text":"<pre><code>from qiskit import QuantumCircuit\nfrom qiskit_aer import AerSimulator\nfrom quartumse import ShadowEstimator\nfrom quartumse.shadows import ShadowConfig\nfrom quartumse.shadows.core import Observable\n\n# Create GHZ state\ncircuit = QuantumCircuit(3)\ncircuit.h(0)\ncircuit.cx(0, 1)\ncircuit.cx(0, 2)\n\n# Original observables (Z-type stabilizers)\noriginal_obs = [\n    Observable(\"ZII\"),\n    Observable(\"ZZI\"),\n    Observable(\"ZZZ\"),\n]\n\n# Run experiment with manifest saving\nconfig = ShadowConfig(shadow_size=256, random_seed=42)\nestimator = ShadowEstimator(backend=AerSimulator(), shadow_config=config)\n\nresult = estimator.estimate(\n    circuit=circuit,\n    observables=original_obs,\n    save_manifest=True  # Important!\n)\n\nprint(f\"Manifest saved: {result.manifest_path}\")\nprint(f\"Shot data saved: {result.shot_data_path}\")\n</code></pre>"},{"location":"how-to/replay-from-manifest/#step-2-replay-with-new-observables-daysweeks-later","title":"Step 2: Replay with New Observables (Days/Weeks Later)","text":"<pre><code># No hardware needed! Can run offline with saved data\n\nfrom quartumse import ShadowEstimator\nfrom quartumse.shadows.core import Observable\n\n# Define new observables (X/Y type for comparison)\nnew_observables = [\n    Observable(\"XII\"),  # X on qubit 0\n    Observable(\"XXI\"),  # X on qubits 0-1\n    Observable(\"XXX\"),  # X on all qubits\n]\n\n# Replay (backend argument ignored during replay)\nestimator = ShadowEstimator(backend=\"aer_simulator\")\n\nreplayed = estimator.replay_from_manifest(\n    manifest_path=\"data/manifests/a3f2b1c4-5678-90ab-cdef-1234567890ab.json\",\n    observables=new_observables\n)\n\n# Compare with analytical expectations for GHZ\nghz_x_expectations = {\n    \"1.0*XII\": 0.0,   # Single X \u2192 0\n    \"1.0*XXI\": 0.0,   # Two X's \u2192 0\n    \"1.0*XXX\": 1.0,   # All X's \u2192 1\n}\n\nprint(\"\\nReplayed Results:\")\nprint(f\"{'Observable':&lt;15} {'Estimated':&lt;12} {'Expected':&lt;12} {'Error'}\")\nprint(\"-\" * 55)\n\nfor obs_str, data in replayed.observables.items():\n    exp_val = data['expectation_value']\n    expected = ghz_x_expectations[obs_str]\n    error = abs(exp_val - expected)\n\n    print(f\"{obs_str:&lt;15} {exp_val:&gt;11.4f} {expected:&gt;11.4f} {error:&gt;9.4f}\")\n</code></pre> <p>Output: <pre><code>Replayed Results:\nObservable      Estimated    Expected    Error\n-------------------------------------------------------\n1.0*XII             0.0156      0.0000    0.0156\n1.0*XXI            -0.0234      0.0000    0.0234\n1.0*XXX             0.9922      1.0000    0.0078\n</code></pre></p>"},{"location":"how-to/replay-from-manifest/#replay-with-noise-aware-shadows-v1-mem","title":"Replay with Noise-Aware Shadows (v1 + MEM)","text":"<p>For experiments using MEM, the replay automatically loads the confusion matrix from the manifest.</p> <pre><code>from quartumse import ShadowEstimator\nfrom quartumse.shadows import ShadowConfig\nfrom quartumse.shadows.config import ShadowVersion\nfrom quartumse.shadows.core import Observable\nfrom quartumse.reporting.manifest import MitigationConfig\n\n# Original experiment (v1 with MEM)\nconfig_v1 = ShadowConfig(\n    version=ShadowVersion.V1_NOISE_AWARE,\n    shadow_size=256,\n    random_seed=42,\n    apply_inverse_channel=True\n)\n\nmit_config = MitigationConfig(\n    techniques=[],  # Populated automatically\n    parameters={\"mem_shots\": 512}\n)\n\nestimator_v1 = ShadowEstimator(\n    backend=\"aer_simulator\",\n    shadow_config=config_v1,\n    mitigation_config=mit_config\n)\n\n# Run and save\nresult_v1 = estimator_v1.estimate(circuit, observables=original_obs, save_manifest=True)\n\n# --- Later: Replay with MEM applied ---\n\n# Replay loads confusion matrix path from manifest\nreplayed_v1 = estimator_v1.replay_from_manifest(\n    manifest_path=result_v1.manifest_path,\n    observables=new_observables\n)\n\n# Noise correction automatically applied during replay!\nprint(f\"Confusion matrix loaded from: {result_v1.mitigation_confusion_matrix_path}\")\n</code></pre> <p>Note: The confusion matrix file must still exist at the path recorded in the manifest. If files have been moved, replay will fail with a <code>FileNotFoundError</code>.</p>"},{"location":"how-to/replay-from-manifest/#advanced-programmatic-replay-loop","title":"Advanced: Programmatic Replay Loop","text":"<p>Batch-process multiple manifests to compare different observables:</p> <pre><code>from pathlib import Path\nfrom quartumse import ShadowEstimator\nfrom quartumse.shadows.core import Observable\n\n# Define observable set to test across all experiments\ntest_observables = [\n    Observable(\"XXX\"),\n    Observable(\"YYY\"),\n    Observable(\"ZZZ\"),\n]\n\nestimator = ShadowEstimator(backend=\"aer_simulator\")\nresults_table = []\n\n# Replay all manifests in directory\nmanifest_dir = Path(\"data/manifests\")\nfor manifest_path in sorted(manifest_dir.glob(\"*.json\")):\n    try:\n        replayed = estimator.replay_from_manifest(\n            manifest_path=str(manifest_path),\n            observables=test_observables\n        )\n\n        # Extract experiment metadata\n        import json\n        with open(manifest_path) as f:\n            manifest = json.load(f)\n\n        exp_id = manifest['experiment_id']\n        backend = manifest['backend']['backend_name']\n        shadow_size = manifest['shadows']['shadow_size']\n\n        # Store results\n        for obs_str, data in replayed.observables.items():\n            results_table.append({\n                'experiment_id': exp_id,\n                'backend': backend,\n                'shadow_size': shadow_size,\n                'observable': obs_str,\n                'expectation': data['expectation_value'],\n                'ci_width': data['ci_width'],\n            })\n\n        print(f\"\u2713 Replayed: {manifest_path.name}\")\n\n    except Exception as e:\n        print(f\"\u2717 Failed: {manifest_path.name} - {e}\")\n\n# Convert to DataFrame for analysis\nimport pandas as pd\ndf = pd.DataFrame(results_table)\nprint(\"\\nReplayed Results Summary:\")\nprint(df.groupby(['observable', 'backend'])['expectation'].agg(['mean', 'std', 'count']))\n</code></pre>"},{"location":"how-to/replay-from-manifest/#replay-validation","title":"Replay Validation","text":"<p>Verify that replay produces identical results to original run:</p> <pre><code># Original run\nresult_original = estimator.estimate(circuit, observables=original_obs, save_manifest=True)\n\n# Replay with SAME observables\nresult_replay = estimator.replay_from_manifest(\n    manifest_path=result_original.manifest_path,\n    observables=original_obs  # Same as original\n)\n\n# Compare\nprint(\"\\nReplay Validation:\")\nprint(f\"{'Observable':&lt;15} {'Original':&lt;12} {'Replayed':&lt;12} {'Match'}\")\nprint(\"-\" * 55)\n\nfor obs_str in result_original.observables.keys():\n    orig_val = result_original.observables[obs_str]['expectation_value']\n    replay_val = result_replay.observables[obs_str]['expectation_value']\n    match = \"\u2713\" if abs(orig_val - replay_val) &lt; 1e-10 else \"\u2717\"\n\n    print(f\"{obs_str:&lt;15} {orig_val:&gt;11.6f} {replay_val:&gt;11.6f} {match:&gt;7}\")\n</code></pre> <p>Expected output: <pre><code>Replay Validation:\nObservable      Original    Replayed    Match\n-------------------------------------------------------\n1.0*ZII           0.003906    0.003906      \u2713\n1.0*ZZI           0.996094    0.996094      \u2713\n1.0*ZZZ          -0.007812   -0.007812      \u2713\n</code></pre></p>"},{"location":"how-to/replay-from-manifest/#troubleshooting","title":"Troubleshooting","text":"<p>\"Manifest file not found\" - Check path is correct (absolute or relative to current directory) - Verify manifest was saved during original run (<code>save_manifest=True</code>) - Use <code>Path(manifest_path).resolve()</code> to see absolute path</p> <p>\"Shot data file not found\" - Manifest contains path to Parquet file with measurement outcomes - Ensure shot data file hasn't been deleted or moved - Check <code>manifest['shot_data_path']</code> for expected location</p> <p>\"Confusion matrix file not found\" - For v1 noise-aware shadows with MEM - Check <code>manifest['mitigation']['confusion_matrix_path']</code> - Ensure MEM calibration file still exists at recorded path - Re-run MEM calibration if needed (see MEM v1 Guide)</p> <p>\"Different results between original and replay\" - Should be bit-identical if observables are the same - Check random seed is recorded in manifest - Verify no floating-point precision issues (compare within tolerance)</p> <p>\"Replay slower than expected\" - Replay should complete in &lt;1 second for typical shadow sizes - Check Parquet file isn't corrupted (try loading with pandas) - Verify no network I/O (all files should be local)</p>"},{"location":"how-to/replay-from-manifest/#related","title":"Related","text":"<ul> <li>Run S-T01 GHZ - Generate manifests worth replaying</li> <li>Generate Report - Create HTML reports from replayed results</li> <li>Manifest Schema - Full manifest specification</li> </ul>"},{"location":"how-to/run-automated-pipeline/","title":"Automated Experiment Pipeline (Phase-1)","text":"<p>The Phase-1 pipeline automates the reproducible baseline \u2192 shadows v0 \u2192 shadows v1 runs, aggregates metrics, and emits artefacts that can be replayed later. Use this guide when you need to run, extend, or debug the <code>experiments/pipeline</code> package.</p>"},{"location":"how-to/run-automated-pipeline/#metadata-schema","title":"Metadata schema","text":"<p><code>experiments/pipeline/metadata_schema.py</code> defines the structured metadata that every pipeline run consumes. Provide the fields below in YAML or JSON (see <code>experiments/shadows/examples/extended_ghz/experiment_metadata.yaml</code> for a template):</p> Field Type Purpose <code>experiment</code> string Human-readable experiment name that is echoed in manifests and reports. <code>context</code> string One-paragraph background describing why the run exists. <code>aims</code> list[string] Bullet points for the primary questions the run answers. <code>success_criteria</code> list[string] Quantitative exit checks (used to infer default targets). <code>methods</code> list[string] High-level procedure summary for provenance. <code>budget.total_shots</code> int Equal-budget anchor: total shots to spend per approach (baseline, v0, v1). <code>budget.calibration.shots_per_state</code> int Shots to allocate to each computational-basis state during MEM calibration. <code>budget.calibration.total</code> int Total calibration shots (must equal <code>shots_per_state * 2^n</code>). <code>budget.v0_shadow_size</code> int Measurement budget for the Phase-1 shadows v0 reference. <code>budget.v1_shadow_size</code> int Measurement budget for the Phase-1 shadows v1 + MEM run (not including calibration shots). <code>device</code> string Default backend descriptor (e.g. <code>aer_simulator</code> or <code>ibm:ibm_brisbane</code>). <code>discussion_template</code> string Markdown template pre-populated in the generated HTML report. <code>num_qubits</code> int (optional) Override for inferred qubit count (normally derived from the calibration budget). <code>targets</code> map[string, number] (optional) Explicit metric thresholds (<code>ssr_average</code>, <code>ci_coverage</code>, etc.). <code>ground_truth</code> mapping (optional) Observable \u2192 expectation pairs for MAE/CI/SSR calculations. <p>Tip: Leave <code>targets</code> blank if the success criteria already specify SSR/CI thresholds\u2014<code>run_full_pipeline.py</code> automatically parses numbers from those strings.</p>"},{"location":"how-to/run-automated-pipeline/#phase-1-equal-budget-rules","title":"Phase-1 equal-budget rules","text":"<p>Phase-1 comparisons assume every approach consumes the same total shot budget and distributes resources uniformly across observables:</p> <ul> <li>Stage 1 (direct Pauli baseline) divides <code>budget.total_shots</code> evenly across the   stabiliser observables using <code>_allocate_shots</code> in   <code>experiments/pipeline/_runners.py</code>.</li> <li>Stage 2 (<code>ShadowVersion.V0_BASELINE</code>) records the exact <code>budget.v0_shadow_size</code>   measurements with mitigation disabled.</li> <li>Stage 3 (<code>ShadowVersion.V1_NOISE_AWARE</code>) spends <code>budget.v1_shadow_size</code> on   measurement shots and reuses calibration snapshots so that   <code>calibration.total + v1_shadow_size = budget.total_shots</code>.</li> <li>The analysis layer (<code>experiments/pipeline/analyzer.py</code>) uses the equal-budget   metrics from <code>src/quartumse/utils/metrics.py</code> (<code>compute_mae</code>, <code>compute_ci_coverage</code>,   and <code>compute_ssr_equal_budget</code>) that treat each observable with uniform weight.</li> </ul> <p>Violating the equal-budget assumption (for example, by changing the shot allocator or by skipping calibration reuse) invalidates SSR/CI comparisons, so keep the metadata and runner defaults aligned when you extend the pipeline.</p>"},{"location":"how-to/run-automated-pipeline/#calibration-reuse-and-refresh-windows","title":"Calibration reuse and refresh windows","text":"<p>The pipeline and CLI share the <code>ReadoutCalibrationManager</code> so that measurement error mitigation (MEM) snapshots are only regenerated when required:</p> <p>Unix/macOS: <pre><code># Reuse cached confusion matrices unless forced or stale\nquartumse calibrate-readout \\\n  --backend ibm:ibm_brisbane \\\n  --qubit 0 --qubit 1 --qubit 2 --qubit 3 \\\n  --shots 256 \\\n  --output-dir validation_data/calibrations \\\n  --max-age-hours 6\n</code></pre></p> <p>Windows: <pre><code># Reuse cached confusion matrices unless forced or stale\nquartumse calibrate-readout `\n  --backend ibm:ibm_brisbane `\n  --qubit 0 --qubit 1 --qubit 2 --qubit 3 `\n  --shots 256 `\n  --output-dir validation_data/calibrations `\n  --max-age-hours 6\n</code></pre></p> <p>Key behaviours (<code>src/quartumse/cli.py</code>):</p> <ul> <li>Reuse by default: <code>ensure_calibration</code> returns cached matrices and marks the   manifest as <code>\"reused\": true</code> when the existing artefact matches the qubit set and   backend descriptor.</li> <li><code>--max-age-hours</code>: Provide a float to refresh calibrations that are older than   the allowed window. Pass <code>--force</code> to ignore age checks entirely.</li> <li>Manifest trail: Each calibration writes <code>&lt;confusion&gt;.manifest.json</code> alongside   the <code>.npz</code>, recording backend version, shot counts, and reuse flags for provenance.</li> </ul> <p>The automated pipeline (<code>experiments/pipeline/executor.py</code>) points its calibration manager at <code>&lt;output&gt;/calibrations/</code> so reruns in the same directory automatically reuse MEM artefacts as long as the age/force constraints permit.</p>"},{"location":"how-to/run-automated-pipeline/#running-the-cli-pipeline","title":"Running the CLI pipeline","text":"<p>Use the <code>run_full_pipeline.py</code> entrypoint to execute the three stages, verify artefacts, and render a report.</p>"},{"location":"how-to/run-automated-pipeline/#simulator-aer","title":"Simulator (Aer)","text":"<p>Unix/macOS: <pre><code>python -m experiments.pipeline.run_full_pipeline \\\n  --metadata experiments/shadows/examples/extended_ghz/experiment_metadata.yaml \\\n  --output validation_data/pipeline_runs/ghz4_aer \\\n  --backend aer_simulator\n</code></pre></p> <p>Windows: <pre><code>python -m experiments.pipeline.run_full_pipeline `\n  --metadata experiments/shadows/examples/extended_ghz/experiment_metadata.yaml `\n  --output validation_data/pipeline_runs/ghz4_aer `\n  --backend aer_simulator\n</code></pre></p> <ul> <li>Produces manifests under <code>validation_data/pipeline_runs/ghz4_aer/manifests/</code>.</li> <li>Stores calibration artefacts in <code>validation_data/pipeline_runs/ghz4_aer/calibrations/</code>.</li> <li>Writes the result digest (<code>result_hash.txt</code>), analysis summary, and HTML report to the   same directory.</li> </ul>"},{"location":"how-to/run-automated-pipeline/#ibm-quantum-hardware","title":"IBM Quantum hardware","text":"<p>Unix/macOS: <pre><code>export QISKIT_IBM_TOKEN=\"&lt;your-runtime-token&gt;\"\npython -m experiments.pipeline.run_full_pipeline \\\n  --metadata experiments/shadows/examples/extended_ghz/experiment_metadata.yaml \\\n  --output data/pipeline_runs/ghz4_kyoto \\\n  --backend ibm:ibm_kyoto\n</code></pre></p> <p>Windows (PowerShell): <pre><code>$env:QISKIT_IBM_TOKEN=\"&lt;your-runtime-token&gt;\"\npython -m experiments.pipeline.run_full_pipeline `\n  --metadata experiments/shadows/examples/extended_ghz/experiment_metadata.yaml `\n  --output data/pipeline_runs/ghz4_kyoto `\n  --backend ibm:ibm_kyoto\n</code></pre></p> <p>Windows (Command Prompt): <pre><code>set QISKIT_IBM_TOKEN=&lt;your-runtime-token&gt;\npython -m experiments.pipeline.run_full_pipeline ^\n  --metadata experiments/shadows/examples/extended_ghz/experiment_metadata.yaml ^\n  --output data/pipeline_runs/ghz4_kyoto ^\n  --backend ibm:ibm_kyoto\n</code></pre></p> <ul> <li>Set <code>QISKIT_RUNTIME_API_TOKEN</code>/<code>QISKIT_IBM_CHANNEL</code>/<code>QISKIT_IBM_INSTANCE</code> if your hub   requires them (see <code>quartumse connect ibm</code> hints in <code>src/quartumse/cli.py</code>).</li> <li>Hardware runs honour the same equal-budget accounting\u2014MEM calibration shots are   deducted from the total and reused when possible.</li> <li>The output directory is Git-ignored; move final manifests to <code>data/manifests/</code> when   publishing results.</li> </ul> <p>To override the backend encoded in the metadata file, pass a different <code>--backend</code> value. Omit the flag to use <code>metadata.device</code> as-is.</p>"},{"location":"how-to/run-automated-pipeline/#artefacts-and-replay-workflow","title":"Artefacts and replay workflow","text":"<p>After a pipeline run completes, inspect the output directory:</p> <p>Unix/macOS: <pre><code>ls -R validation_data/pipeline_runs/ghz4_aer\ncat validation_data/pipeline_runs/ghz4_aer/report_*.html | head\n</code></pre></p> <p>Windows: <pre><code>Get-ChildItem -Recurse validation_data/pipeline_runs/ghz4_aer\nGet-Content validation_data/pipeline_runs/ghz4_aer/report_*.html | Select-Object -First 10\n</code></pre></p> <p>You should see:</p> <ul> <li><code>manifests/</code> \u2013 baseline, v0, and v1 JSON manifests (Stage 1\u20133).</li> <li><code>calibrations/</code> \u2013 MEM confusion matrices plus <code>.manifest.json</code> metadata (only when   Phase-1 runs require mitigation).</li> <li><code>analysis_&lt;hash&gt;.json</code> \u2013 Aggregated metrics (<code>ssr_average</code>, <code>ci_coverage</code>, MAE) and   target evaluation flags.</li> <li><code>report_&lt;hash&gt;.html</code> \u2013 Full Phase-1 report ready for review or screenshots.</li> <li><code>result_hash.txt</code> \u2013 Stable digest derived from the manifest payloads.</li> </ul> <p>Replaying artefacts does not require backend access:</p> <p>Unix/macOS: <pre><code># Regenerate the HTML report after editing metadata or narrative sections\nquartumse report validation_data/pipeline_runs/ghz4_aer/manifests/&lt;manifest&gt;.json \\\n  --output validation_data/pipeline_runs/ghz4_aer/replay_report.html\n\n# Programmatic replay: recompute observables from saved manifests\npython - &lt;&lt;'PY'\nfrom quartumse.estimator import ShadowEstimator\nfrom quartumse.reporting.manifest import ProvenanceManifest\n\nmanifest_path = \"validation_data/pipeline_runs/ghz4_aer/manifests/&lt;manifest&gt;.json\"\nmanifest = ProvenanceManifest.from_json(manifest_path)\nestimator = ShadowEstimator.replay_from_manifest(manifest)\nprint(estimator)\nPY\n</code></pre></p> <p>Windows: <pre><code># Regenerate the HTML report after editing metadata or narrative sections\nquartumse report validation_data/pipeline_runs/ghz4_aer/manifests/&lt;manifest&gt;.json `\n  --output validation_data/pipeline_runs/ghz4_aer/replay_report.html\n\n# Programmatic replay: recompute observables from saved manifests\npython -c \"from quartumse.estimator import ShadowEstimator; from quartumse.reporting.manifest import ProvenanceManifest; manifest_path = 'validation_data/pipeline_runs/ghz4_aer/manifests/&lt;manifest&gt;.json'; manifest = ProvenanceManifest.from_json(manifest_path); estimator = ShadowEstimator.replay_from_manifest(manifest); print(estimator)\"\n</code></pre></p> <p>The verifier stage (<code>experiments/pipeline/verifier.py</code>) checks that shot files and MEM confusion matrices still exist and match their checksums. If you relocate artefacts, update <code>manifest.schema.shot_data_path</code> or keep the directory layout intact so replay continues to pass.</p> <p>Need more automation? Extend <code>experiments/pipeline/executor.py</code> with new stages, but keep the metadata schema and equal-budget invariants intact so downstream analysis and reports remain comparable.</p>"},{"location":"how-to/run-mem-v1/","title":"Run MEM (v1)","text":"<p>Procedures for configuring and executing MEM (v1) runs will be documented here.</p>"},{"location":"how-to/run-st01-ghz/","title":"Run S-T01 GHZ Experiment","text":"<p>The S-T01/S-T02 experiments validate classical shadows on GHZ states, measuring Shot-Savings Ratio (SSR) and confidence interval (CI) coverage against Phase 1 exit criteria.</p>"},{"location":"how-to/run-st01-ghz/#overview","title":"Overview","text":"<p>S-T01 (baseline): Classical shadows v0 without mitigation S-T02 (noise-aware): Classical shadows v1 with MEM calibration</p> <p>Both variants support: - GHZ states from 2-5 qubits - Configurable backends (Aer simulator or IBM Quantum hardware) - Automatic SSR calculation vs direct measurement baseline - Manifest + shot data persistence for replay</p>"},{"location":"how-to/run-st01-ghz/#quick-start","title":"Quick Start","text":""},{"location":"how-to/run-st01-ghz/#s-t01-baseline-on-simulator","title":"S-T01 (Baseline) on Simulator","text":"<p>Unix/macOS: <pre><code>python experiments/shadows/S_T01_ghz_baseline.py --backend aer_simulator --variant st01\n</code></pre></p> <p>Windows: <pre><code>python experiments/shadows/S_T01_ghz_baseline.py --backend aer_simulator --variant st01\n</code></pre></p> <p>Expected output: <pre><code>====================================================================================\nS-T01 GHZ Validation (classical shadows v0 baseline)\n====================================================================================\nBackend: aer_simulator\nShadow size: 256 per GHZ state\nBaseline shots: 1024 per observable\n====================================================================================\n\nTesting GHZ(2)...\nObservable            Shadows    Expected    Baseline    CI Width    SSR  In CI\n--------------------------------------------------------------------------------\n1.0*ZI                 0.0039      0.0000      0.0020      0.1800  1.45  \u2713\n1.0*IZ                -0.0078      0.0000     -0.0039      0.1756  1.38  \u2713\n1.0*ZZ                 0.9961      1.0000      0.9941      0.0488  5.32  \u2713\n\n============================================================\nMETRICS for GHZ(2)\n============================================================\nCI Coverage:         100.00% (target: \u226590%)\nSSR (estimated):     2.72\u00d7 (target: \u22651.2\u00d7)\nShadow size:         256\nBaseline shots:      1024\n\n[... similar output for GHZ(3), GHZ(4), GHZ(5) ...]\n\n================================================================================\nEXPERIMENT SUMMARY\n================================================================================\n\nQubits     CI Coverage    SSR        Status\n--------------------------------------------------\n2          100.00%        2.72       \u2713 PASS\n3          100.00%        3.14       \u2713 PASS\n4          100.00%        2.89       \u2713 PASS\n5          93.33%         2.45       \u2713 PASS\n\n================================================================================\n\u2713 EXPERIMENT PASSED - Phase 1 exit criteria met!\n================================================================================\n</code></pre></p> <p>Artifacts saved: - Manifests: <code>data/manifests/&lt;experiment_id&gt;.json</code> - Shot data: <code>data/shots/&lt;experiment_id&gt;.parquet</code> - Change the base directory with <code>--data-dir</code> (see Common flags)</p>"},{"location":"how-to/run-st01-ghz/#s-t02-noise-aware-with-mem","title":"S-T02 (Noise-Aware) with MEM","text":"<p>Unix/macOS: <pre><code>python experiments/shadows/S_T01_ghz_baseline.py --backend aer_simulator --variant st02\n</code></pre></p> <p>Windows: <pre><code>python experiments/shadows/S_T01_ghz_baseline.py --backend aer_simulator --variant st02\n</code></pre></p> <p>Key differences: - Runs MEM calibration before shadow measurements (8 basis states \u00d7 shots) - Applies inverse confusion matrix during reconstruction - Typically shows better SSR on noisy hardware (similar on ideal simulator)</p> <p>Expected output (additional MEM info): <pre><code>====================================================================================\nS-T02 GHZ Validation (classical shadows v1 + MEM)\n====================================================================================\n\nTesting GHZ(3)...\n  Step 1: MEM calibration (8 basis states \u00d7 512 shots = 4096 total)\n  Step 2: Shadow measurements (256 shots)\n  Step 3: Noise correction via confusion matrix\n\nConfusion matrix (3 qubits):\n[[0.998 0.002 ... 0.000]\n [0.001 0.996 ... 0.001]\n ...\n [0.000 0.001 ... 0.997]]\n\nObservable            Shadows    Expected    Baseline    CI Width    SSR  In CI\n--------------------------------------------------------------------------------\n...\n</code></pre></p>"},{"location":"how-to/run-st01-ghz/#running-on-ibm-quantum-hardware","title":"Running on IBM Quantum Hardware","text":""},{"location":"how-to/run-st01-ghz/#prerequisites","title":"Prerequisites","text":"<ol> <li>Set IBM credentials:</li> </ol> <p>Unix/macOS: <pre><code>export QISKIT_IBM_TOKEN=\"your_token_here\"\n# Optional: specify hub/group/project\nexport QISKIT_IBM_INSTANCE=\"ibm-q/open/main\"\n</code></pre></p> <p>Windows (PowerShell): <pre><code>$env:QISKIT_IBM_TOKEN=\"your_token_here\"\n# Optional: specify hub/group/project\n$env:QISKIT_IBM_INSTANCE=\"ibm-q/open/main\"\n</code></pre></p> <p>Windows (Command Prompt): <pre><code>set QISKIT_IBM_TOKEN=your_token_here\nrem Optional: specify hub/group/project\nset QISKIT_IBM_INSTANCE=ibm-q/open/main\n</code></pre></p> <ol> <li>Check remaining quota:</li> </ol> <p>All platforms: <pre><code>quartumse runtime-status --backend ibm:ibm_brisbane\n</code></pre></p>"},{"location":"how-to/run-st01-ghz/#run-on-hardware","title":"Run on Hardware","text":"<p>Unix/macOS: <pre><code>python experiments/shadows/S_T01_ghz_baseline.py \\\n  --backend ibm:ibm_brisbane \\\n  --variant st02\n</code></pre></p> <p>Windows: <pre><code>python experiments/shadows/S_T01_ghz_baseline.py `\n  --backend ibm:ibm_brisbane `\n  --variant st02\n</code></pre></p> <p>Note: Hardware runs may take 10-30 minutes depending on queue depth and shot counts.</p>"},{"location":"how-to/run-st01-ghz/#using-a-configuration-file","title":"Using a Configuration File","text":"<p>Create <code>config.yaml</code>:</p> <pre><code>backend:\n  provider: ibm\n  name: ibm_brisbane\n\nshadow_size: 512\nbaseline_shots: 2048\n\n# For S-T02 (MEM)\nmem_shots: 1024\nmem_qubits: [0, 1, 2, 3, 4]\n</code></pre> <p>Run with config:</p> <p>Unix/macOS: <pre><code>python experiments/shadows/S_T01_ghz_baseline.py \\\n  --config config.yaml \\\n  --variant st02\n</code></pre></p> <p>Windows: <pre><code>python experiments/shadows/S_T01_ghz_baseline.py `\n  --config config.yaml `\n  --variant st02\n</code></pre></p> <p>Override backend from command line:</p> <p>Unix/macOS: <pre><code>python experiments/shadows/S_T01_ghz_baseline.py \\\n  --config config.yaml \\\n  --backend ibm:ibmq_qasm_simulator \\\n  --variant st02\n</code></pre></p> <p>Windows: <pre><code>python experiments/shadows/S_T01_ghz_baseline.py `\n  --config config.yaml `\n  --backend ibm:ibmq_qasm_simulator `\n  --variant st02\n</code></pre></p>"},{"location":"how-to/run-st01-ghz/#understanding-the-output","title":"Understanding the Output","text":""},{"location":"how-to/run-st01-ghz/#metrics-explained","title":"Metrics Explained","text":"<p>CI Coverage - Percentage of observables where true value falls within 95% confidence interval - Target: \u226590% for Phase 1 validation - Typical: 93-100% on simulator, 85-95% on hardware</p> <p>SSR (Shot-Savings Ratio) - Ratio of baseline shots to shadow shots needed for equivalent precision - Formula: <code>SSR = (baseline_shots / shadow_size) \u00d7 (baseline_error / shadow_error)\u00b2</code> - Target: \u22651.2\u00d7 for Phase 1 validation - Typical: 2-7\u00d7 on simulator, 1.1-3\u00d7 on noisy hardware</p> <p>Status - \u2713 PASS: Both CI coverage \u226590% and SSR \u22651.2\u00d7 - \u2717 FAIL: One or more criteria not met</p>"},{"location":"how-to/run-st01-ghz/#observable-notation","title":"Observable Notation","text":"<ul> <li><code>ZI</code> = Z on qubit 0, Identity on qubit 1</li> <li><code>ZZ</code> = Z on both qubits</li> <li><code>ZZZ</code> = Z on all three qubits</li> </ul> <p>For GHZ states: - Even number of Z operators: expectation = +1 - Odd number of Z operators: expectation = 0</p>"},{"location":"how-to/run-st01-ghz/#troubleshooting","title":"Troubleshooting","text":"<p>\"Unable to resolve IBM backend\" - Ensure <code>QISKIT_IBM_TOKEN</code> is set - Check backend name is correct (use <code>quartumse runtime-status</code> to list) - Verify credentials have access to the specified backend</p> <p>\"ModuleNotFoundError: qiskit_ibm_runtime\" - Install runtime dependencies: <code>pip install quartumse[mitigation]</code></p> <p>\"Insufficient runtime quota\" - Check remaining quota: <code>quartumse runtime-status</code> - Wait for monthly reset or use simulator - Reduce shot counts in config file</p> <p>Poor SSR on hardware (&lt;1.2\u00d7) - Expected for very noisy backends - Try S-T02 variant with MEM (typically improves SSR by 20-40%) - Use backends with lower readout error rates</p> <p>Manifest not found during replay - Check <code>data/manifests/</code> directory exists - Verify experiment completed successfully (look for \"\u2713 EXPERIMENT PASSED\") - Use full path to manifest file</p>"},{"location":"how-to/run-st01-ghz/#next-steps","title":"Next Steps","text":"<ul> <li>Replay experiments: See Replay from Manifest</li> <li>Generate reports: See Generate Report</li> <li>Run custom experiments: Modify script or use notebooks</li> <li>Hardware validation: Follow IBM Runtime Runbook</li> </ul>"},{"location":"how-to/run-st01-ghz/#related","title":"Related","text":"<ul> <li>MEM v1 Guide - Details on measurement error mitigation</li> <li>Testing Guide - Automated test suite and markers</li> <li>Phase 1 Task Checklist - Exit criteria</li> </ul>"},{"location":"how-to/run-st01-ghz/#common-flags","title":"Common flags","text":"<p>The experiment script now shares the same CLI surface as other QuartumSE runs:</p> Flag Purpose Default <code>--backend</code> Override the backend descriptor (<code>aer_simulator</code>, <code>ibm:ibm_brisbane</code>, etc.) <code>aer_simulator</code> <code>--shadow-size</code> Number of classical shadow shots per GHZ size <code>500</code> (configurable via YAML) <code>--seed</code> Random seed used when sampling classical shadows <code>42</code> <code>--data-dir</code> Base directory for manifests, shot archives, and MEM data <code>data/</code> <p>All parameters can also be provided through the optional YAML config file. CLI flags always win over configuration values, making it easy to experiment with different shot budgets or output locations ad-hoc.</p>"},{"location":"how-to/run-tests/","title":"Run QuartumSE Tests","text":"<p>This guide explains how to exercise the automated test suites, when to run hardware checks, and which notebooks provide manual validation coverage.  It replaces the older <code>TESTING_GUIDE.md</code> marketing summary with a concise workflow reference.</p>"},{"location":"how-to/run-tests/#test-matrix-overview","title":"Test matrix overview","text":"Layer Marker(s) Purpose Unit (default) Fast logic tests for shadows, manifests, and utilities Integration <code>integration</code> Exercising estimator + storage pipelines on simulators Slow <code>slow</code> Longer-running variance/CI checks Hardware <code>hardware</code> Requires IBM Quantum credentials and quota <p>Tests use <code>pytest</code> markers so you can opt into the heavier scenarios as needed.</p>"},{"location":"how-to/run-tests/#running-the-suites","title":"Running the suites","text":"<p>Unix/macOS: <pre><code># Core unit tests (quick feedback)\npytest tests/unit -v\n\n# Fast integration matrix (skip slow + hardware markers)\npytest tests -m \"not slow and not hardware\" -v\n\n# Include slow scenarios (still skip hardware)\npytest tests -m \"not hardware\" -v --durations=20\n\n# Hardware runs (requires QISKIT_IBM_TOKEN, see ../ops/runtime_runbook.md)\npytest tests -m hardware -v\n</code></pre></p> <p>Windows: <pre><code># Core unit tests (quick feedback)\npytest tests/unit -v\n\n# Fast integration matrix (skip slow + hardware markers)\npytest tests -m \"not slow and not hardware\" -v\n\n# Include slow scenarios (still skip hardware)\npytest tests -m \"not hardware\" -v --durations=20\n\n# Hardware runs (requires QISKIT_IBM_TOKEN, see ../ops/runtime_runbook.md)\npytest tests -m hardware -v\n</code></pre></p> <p>Enable coverage reporting (mirrors the CI configuration) when preparing releases:</p> <p>Unix/macOS: <pre><code>pytest --cov --cov-report=term-missing --cov-report=xml --cov-report=html\n</code></pre></p> <p>Windows: <pre><code>pytest --cov --cov-report=term-missing --cov-report=xml --cov-report=html\n</code></pre></p> <p>This writes <code>coverage.xml</code> for Codecov uploads and an <code>htmlcov/</code> directory for annotated source review.</p>"},{"location":"how-to/run-tests/#manual-validation-notebooks","title":"Manual validation notebooks","text":"<p>Three curated notebooks cover the major user journeys:</p> <ul> <li><code>notebooks/quickstart_shot_persistence.ipynb</code> \u2013 GHZ classical shadows demo   with manifest + Parquet replay.</li> <li><code>notebooks/noise_aware_shadows_demo.ipynb</code> \u2013 MEM-enhanced (v1) workflow and   confusion-matrix diagnostics.</li> <li><code>notebooks/comprehensive_test_suite.ipynb</code> \u2013 End-to-end path combining CLI,   replay, and reporting.</li> </ul> <p>The notebooks folder now contains only the actively maintained tutorials so new users can focus on the recommended path. Historical experiments have been retired from version control to keep the repo lightweight.</p>"},{"location":"how-to/run-tests/#experiment-scripts","title":"Experiment scripts","text":"<p>The active experiment scripts are under <code>experiments/shadows/</code> and <code>experiments/validation/</code>.  Legacy scaffolds were removed during the repo cleanup, so everything under <code>experiments/</code> is production-supported. The S\u2011T01 GHZ baseline remains the canonical CLI example:</p> <p>Unix/macOS: <pre><code>python experiments/shadows/S_T01_ghz_baseline.py --backend aer_simulator\n</code></pre></p> <p>Windows: <pre><code>python experiments/shadows/S_T01_ghz_baseline.py --backend aer_simulator\n</code></pre></p> <p>Pass <code>--backend ibm:&lt;device&gt;</code> to exercise the IBM Runtime integration.  Hardware runs automatically persist manifests and shot data under <code>data/</code>.</p>"},{"location":"how-to/run-tests/#hardware-readiness-checklist","title":"Hardware readiness checklist","text":"<p>Before running the <code>hardware</code> test marker or the CLI against real backends:</p> <ol> <li>Export <code>QISKIT_IBM_TOKEN</code> (and optional instance overrides).</li> <li>Ensure <code>qiskit-ibm-runtime</code> is installed (<code>pip install qiskit-ibm-runtime</code> or <code>pip install quartumse[mitigation]</code>).</li> <li>Confirm remaining quota via <code>quartumse runtime-status</code>.</li> <li>Schedule runs inside the free-tier 10 minute window.  See the    IBM Runtime runbook for quota guidance and    webhook notifications.</li> </ol>"},{"location":"how-to/run-tests/#troubleshooting-tips","title":"Troubleshooting tips","text":"<ul> <li>Missing optional dependencies \u2013 install <code>quartumse[dev,mitigation]</code> to   enable MEM notebooks and tests.</li> <li>Runtime quota errors \u2013 rerun on the Aer simulator or wait for the next   monthly reset; manifests still capture simulated evidence.</li> <li>Inconsistent notebook output \u2013 clear previous artifacts under   <code>notebook_data/</code> or supply a unique <code>data_dir</code> when instantiating   <code>ShadowEstimator</code>.</li> </ul> <p>For a broader program view, pair this document with the updated Project Bible and Roadmap.</p>"},{"location":"ops/ci_expansion_guide/","title":"CI Matrix Expansion Guide","text":"<p>This guide explains how to expand the GitHub Actions CI matrix from the reduced configuration (Phase 1-2) to full multi-platform testing when the repository becomes public.</p>"},{"location":"ops/ci_expansion_guide/#current-state-phase-1-2","title":"Current State (Phase 1-2)","text":"<p>Configuration: Reduced matrix File: <code>.github/workflows/ci.yml</code> Jobs: 1 (Ubuntu + Python 3.11 only) Reason: Private repository + cost optimization</p> <pre><code>matrix:\n  os: [ubuntu-latest]\n  python-version: [\"3.11\"]\n</code></pre> <p>What's tested: - \u2705 Code formatting (black, ruff) - \u2705 Type checking (mypy) - \u2705 Core unit tests on Python 3.11 - \u2705 Coverage reporting to Codecov</p> <p>What's NOT tested: - \u274c Windows compatibility - \u274c macOS compatibility - \u274c Python 3.10, 3.12, 3.13 edge cases</p>"},{"location":"ops/ci_expansion_guide/#when-to-expand","title":"When to Expand","text":"<p>Trigger: Repository becomes public (planned for Phase 3)</p> <p>Phase 3 Checklist Item: - Internal validation complete - SSR \u2265 1.5\u00d7 achieved - Ready for external contributors - No secrets in Git history - \u2192 Make repo public - \u2192 Expand CI matrix</p> <p>Why wait until Phase 3: - Phase 1-2: Private repo, cost-sensitive, core team only - Phase 3+: Public repo, unlimited Actions, external contributors need cross-platform validation</p>"},{"location":"ops/ci_expansion_guide/#expansion-steps","title":"Expansion Steps","text":""},{"location":"ops/ci_expansion_guide/#step-1-verify-repository-is-public","title":"Step 1: Verify Repository is Public","text":"<p>Check visibility: <pre><code># Visit repo settings\nopen https://github.com/QuartumSE/quartumse/settings\n\n# Or check with gh CLI\ngh repo view QuartumSE/quartumse --json visibility -q .visibility\n# Should output: \"public\"\n</code></pre></p> <p>Confirm unlimited Actions: - Go to: https://github.com/settings/billing - Public repos show: \"GitHub Actions: Unlimited\" \u2705</p>"},{"location":"ops/ci_expansion_guide/#step-2-edit-ci-workflow","title":"Step 2: Edit CI Workflow","text":"<p>File: <code>.github/workflows/ci.yml</code></p> <p>Find the matrix section (around line 14):</p> <pre><code>matrix:\n  # REDUCED MATRIX: Keeping private repo during Phase 1-2\n  # ...\n  os: [ubuntu-latest]\n  python-version: [\"3.11\"]\n  #\n  # EXPAND WHEN REPO GOES PUBLIC (Phase 3+):\n  # ...\n</code></pre> <p>Replace with full matrix:</p> <pre><code>matrix:\n  os: [ubuntu-latest, macos-latest, windows-latest]\n  python-version: [\"3.10\", \"3.11\", \"3.12\", \"3.13\"]\n</code></pre> <p>Remove all the comment blocks about reduced/expanded matrix.</p>"},{"location":"ops/ci_expansion_guide/#step-3-test-the-expansion","title":"Step 3: Test the Expansion","text":"<p>Create a test PR:</p> <pre><code># Create a branch\ngit checkout -b ci/expand-matrix\n\n# Edit .github/workflows/ci.yml (apply Step 2 changes)\n\n# Commit\ngit add .github/workflows/ci.yml\ngit commit -m \"Expand CI matrix to full platform coverage\n\nRepository is now public, enabling full cross-platform testing:\n- 3 operating systems (Ubuntu, macOS, Windows)\n- 4 Python versions (3.10, 3.11, 3.12, 3.13)\n- Total: 12 test jobs per run\n\nThis provides comprehensive validation for external contributors\nand ensures QuartumSE works across all supported environments.\"\n\n# Push and create PR\ngit push -u origin ci/expand-matrix\ngh pr create --title \"Expand CI matrix for public repo\" --body \"Restores full cross-platform testing now that repo is public. See docs/ops/ci_expansion_guide.md\"\n</code></pre> <p>Watch the PR checks: - All 12 jobs should run - Expect some Windows/macOS-specific issues initially - Fix any platform-specific failures before merging</p>"},{"location":"ops/ci_expansion_guide/#step-4-fix-platform-specific-issues","title":"Step 4: Fix Platform-Specific Issues","text":"<p>Common issues when expanding to full matrix:</p>"},{"location":"ops/ci_expansion_guide/#windows-path-issues","title":"Windows Path Issues","text":"<pre><code># Before (Unix-only)\npath = \"data/manifests/file.json\"\n\n# After (cross-platform)\nfrom pathlib import Path\npath = Path(\"data\") / \"manifests\" / \"file.json\"\n</code></pre>"},{"location":"ops/ci_expansion_guide/#macos-line-ending-issues","title":"macOS Line Ending Issues","text":"<pre><code># In CI workflow, normalize line endings\n- name: Normalize line endings (macOS)\n  if: runner.os == 'macOS'\n  run: |\n    find . -name \"*.py\" -exec dos2unix {} \\;\n</code></pre>"},{"location":"ops/ci_expansion_guide/#python-313-compatibility","title":"Python 3.13 Compatibility","text":"<pre><code># Check for deprecated features removed in 3.13\n# Update dependencies if needed\npip install --upgrade qiskit qiskit-aer\n</code></pre>"},{"location":"ops/ci_expansion_guide/#step-5-update-documentation","title":"Step 5: Update Documentation","text":"<p>Update references mentioning reduced matrix:</p> <ol> <li> <p>CHANGELOG.md: <pre><code>## [Unreleased]\n### Changed\n- Expanded CI matrix to full platform coverage (12 jobs) now that repository is public\n</code></pre></p> </li> <li> <p>README.md badges: <pre><code>[![CI](https://github.com/quartumse/quartumse/workflows/CI/badge.svg)](https://github.com/quartumse/quartumse/actions)\n</code></pre>    Badge will now show \"12 passing\" instead of \"1 passing\"</p> </li> <li> <p>CONTRIBUTING.md:    Add note about cross-platform testing:    <pre><code>## Testing\n\nPull requests are tested on:\n- Ubuntu, macOS, Windows\n- Python 3.10, 3.11, 3.12, 3.13\n\nEnsure your changes work on all platforms before submitting.\n</code></pre></p> </li> </ol>"},{"location":"ops/ci_expansion_guide/#step-6-monitor-actions-usage","title":"Step 6: Monitor Actions Usage","text":"<p>Even with unlimited minutes, monitor for efficiency:</p> <pre><code># Check Actions usage\ngh api /repos/QuartumSE/quartumse/actions/runs \\\n  --jq '.workflow_runs[] | select(.name==\"CI\") | {id, status, conclusion, duration: .run_duration_ms}'\n\n# View workflow run times\ngh run list --workflow=ci.yml --limit 10\n</code></pre> <p>Optimization tips if runs are slow: - Use <code>fail-fast: true</code> to cancel remaining jobs on first failure - Cache pip dependencies with <code>actions/cache</code> - Run expensive checks (mypy, integration tests) only on one platform</p>"},{"location":"ops/ci_expansion_guide/#rollback-procedure","title":"Rollback Procedure","text":"<p>If full matrix causes issues, temporarily rollback:</p> <p>Quick rollback: <pre><code>matrix:\n  os: [ubuntu-latest]  # Rollback to single platform\n  python-version: [\"3.11\"]\n</code></pre></p> <p>Fix issues offline: - Test problematic platforms locally - Fix compatibility issues - Re-expand when ready</p>"},{"location":"ops/ci_expansion_guide/#expected-results","title":"Expected Results","text":""},{"location":"ops/ci_expansion_guide/#before-expansion-current","title":"Before Expansion (Current)","text":"<p><pre><code>\u2705 test (ubuntu-latest, 3.11)\n</code></pre> Time: ~3 minutes Coverage: Core functionality only</p>"},{"location":"ops/ci_expansion_guide/#after-expansion-phase-3","title":"After Expansion (Phase 3+)","text":"<p><pre><code>\u2705 test (ubuntu-latest, 3.10)\n\u2705 test (ubuntu-latest, 3.11)\n\u2705 test (ubuntu-latest, 3.12)\n\u2705 test (ubuntu-latest, 3.13)\n\u2705 test (macos-latest, 3.10)\n\u2705 test (macos-latest, 3.11)\n\u2705 test (macos-latest, 3.12)\n\u2705 test (macos-latest, 3.13)\n\u2705 test (windows-latest, 3.10)\n\u2705 test (windows-latest, 3.11)\n\u2705 test (windows-latest, 3.12)\n\u2705 test (windows-latest, 3.13)\n</code></pre> Time: ~8-10 minutes (parallel execution) Coverage: Full cross-platform validation</p>"},{"location":"ops/ci_expansion_guide/#validation-checklist","title":"Validation Checklist","text":"<p>After expansion, verify:</p> <ul> <li>[ ] All 12 jobs complete successfully</li> <li>[ ] Coverage reports upload correctly (Ubuntu 3.11 job)</li> <li>[ ] No platform-specific test failures</li> <li>[ ] Codecov badge shows correct coverage</li> <li>[ ] CI badge shows \"12 passing\"</li> <li>[ ] PR checks show all jobs</li> <li>[ ] No excessive Actions usage warnings</li> <li>[ ] Windows path handling works</li> <li>[ ] macOS-specific issues resolved</li> <li>[ ] Python 3.10-3.13 all pass</li> </ul>"},{"location":"ops/ci_expansion_guide/#cost-analysis","title":"Cost Analysis","text":""},{"location":"ops/ci_expansion_guide/#private-repo-current","title":"Private Repo (Current)","text":"<pre><code>Matrix: 1 job\nDuration: 3 min\nCost per run: 3 minutes (Ubuntu 1\u00d7)\nMonthly estimate: ~100-300 minutes\nStatus: Within 2,000 min free tier\n</code></pre>"},{"location":"ops/ci_expansion_guide/#public-repo-after-expansion","title":"Public Repo (After Expansion)","text":"<pre><code>Matrix: 12 jobs\nDuration: 3-4 min per job (parallel)\nCost per run: 0 minutes (unlimited for public)\nMonthly estimate: Unlimited \u2705\nStatus: Free forever\n</code></pre> <p>Key takeaway: Expansion is cost-free once repo is public!</p>"},{"location":"ops/ci_expansion_guide/#related-documentation","title":"Related Documentation","text":"<ul> <li>Phase 1 Task Checklist</li> <li>Roadmap - Phase 3 milestones</li> <li>CI Workflow - Current configuration</li> <li>GitHub Actions Pricing</li> </ul>"},{"location":"ops/ci_expansion_guide/#questions","title":"Questions?","text":"<p>When should I expand? \u2192 When repo becomes public (Phase 3+)</p> <p>Can I expand before repo is public? \u2192 Not recommended (cost ~$20-50/month for private repos)</p> <p>What if some jobs fail after expansion? \u2192 Normal! Fix platform-specific issues and re-run</p> <p>Do I need to change anything else? \u2192 Just update docs mentioning \"reduced matrix\" or \"Ubuntu only\"</p> <p>How do I test locally before expanding? \u2192 Use <code>tox</code> with multiple Python versions, test on VM for other OSes</p> <p>Last updated: 2025-10-30 Next review: Phase 3 (Internal Validation) - Target Mar 2026</p>"},{"location":"ops/runtime_runbook/","title":"IBM Runtime Operations Runbook","text":"<p>This runbook tracks IBM Quantum free-tier runtime usage and provides quick recovery paths when the quota is depleted.</p>"},{"location":"ops/runtime_runbook/#free-tier-quota-snapshot","title":"Free-tier quota snapshot","text":"<ul> <li>Monthly allocation: 600 seconds (10 minutes) of wall-clock runtime on physical devices per calendar month under the IBM Quantum Free/Open plan.</li> <li>Concurrency limits: Up to 5 pending jobs and 1 running job per account/instance at a time. Excess submissions are rejected until the queue drains.</li> <li>Reset schedule: Allocation resets at 00:00 UTC on the first day of each month. Unused minutes do not roll over.</li> </ul>"},{"location":"ops/runtime_runbook/#checking-remaining-runtime","title":"Checking remaining runtime","text":""},{"location":"ops/runtime_runbook/#via-ibm-quantum-portal","title":"Via IBM Quantum portal","text":"<ol> <li>Sign in to https://quantum.ibm.com.</li> <li>Open My Account \u2192 Usage and select the active hub/group/project.</li> <li>Review the Runtime usage panel for remaining seconds, refresh date, and pending job caps.</li> </ol>"},{"location":"ops/runtime_runbook/#via-quartumse-cli-preferred-for-automation","title":"Via QuartumSE CLI (preferred for automation)","text":"<pre><code>quartumse runtime-status --backend ibm:ibmq_brisbane --instance ibm-q/open/main\n</code></pre> <p>Dependency: Ensure <code>qiskit-ibm-runtime</code> is installed (<code>pip install qiskit-ibm-runtime</code>).</p> <p>Key behaviours:</p> <ul> <li>The command queries queue depth, quota consumption, and refresh date using the IBM Runtime API. \u3010F:src/quartumse/utils/runtime_monitor.py\u2020L44-L193\u3011</li> <li>Pass <code>--json</code> for machine-readable output (suitable for CI dashboards).</li> <li>Provide credentials via standard environment variables (<code>QISKIT_IBM_TOKEN</code>, <code>QISKIT_IBM_CHANNEL</code>, <code>QISKIT_IBM_INSTANCE</code>) or CLI overrides.</li> </ul>"},{"location":"ops/runtime_runbook/#notifications","title":"Notifications","text":"<ul> <li>Set <code>QUARTUMSE_SLACK_WEBHOOK</code> (or pass <code>--slack-webhook</code>) to push the status summary into project chat. Use <code>--dry-run</code> during testing to avoid posting. \u3010F:src/quartumse/cli.py\u2020L119-L213\u3011</li> <li>The webhook payload includes queue depth, quota usage, and the next reset date for quick triage.</li> </ul>"},{"location":"ops/runtime_runbook/#fallback-backends-when-quota-is-exhausted","title":"Fallback backends when quota is exhausted","text":"Scenario Immediate action Notes Free-tier minutes depleted mid-sprint Switch estimator config to <code>ibm:ibmq_qasm_simulator</code> or <code>aer_simulator</code> for continued functional work. Simulator runs do not consume runtime quota but still validate integration paths. Hardware-specific regression blocking validation Use <code>qiskit.providers.fake_provider</code> fake backends to reproduce calibration-dependent logic without hardware access. Capture manifests to document the simulated evidence until hardware minutes refresh. Queue cap reached (max pending jobs) Pause new submissions, monitor <code>quartumse runtime-status --json</code> until <code>pendingJobs &lt; maxPendingJobs</code>. CLI returns job caps from the active instance, mirroring portal data."},{"location":"ops/runtime_runbook/#operational-cadence","title":"Operational cadence","text":"<ul> <li>Monthly review: First business day of each month, review the runtime usage dashboard, confirm remaining free-tier minutes, and update fallback readiness in this runbook.</li> <li>Weekly spot-check (Mondays): Run <code>quartumse runtime-status --json</code> against the primary hardware backend and capture output in the team notebook to watch queue health trends.</li> </ul>"},{"location":"ops/runtime_runbook/#incident-response-tips","title":"Incident response tips","text":"<ol> <li>If quota hits zero before reset, pivot planned hardware executions to simulator-only experiments and reschedule hardware runs after the reset date.</li> <li>When backlog persists beyond 24 hours, escalate in the team comms channel with the webhook payload and consider re-prioritising experiments toward simulator coverage.</li> <li>Document any quota-related delays in <code>STATUS_REPORT.md</code> for visibility during phase reviews.</li> </ol>"},{"location":"reference/cli/","title":"CLI","text":"<p>Usage: quartumse [OPTIONS] COMMAND [ARGS]...                                  </p> <p>Quantum measurement optimization toolkit                                      </p> <p>+- Options -------------------------------------------------------------------+ | --install-completion          Install completion for the current shell.     | | --show-completion             Show completion for the current shell, to     | |                               copy it or customize the installation.        | | --help                        Show this message and exit.                   | +-----------------------------------------------------------------------------+ +- Commands ------------------------------------------------------------------+ | version             Show QuartumSE version.                                 | | run                 Validate configuration and resolve experiment backend.  | | calibrate-readout   Calibrate readout confusion matrices and persist        | |                     metadata.                                               | | report              Generate report from manifest.                          | | benchmark           Run benchmark suite.                                    | | runtime-status      Report IBM queue depth and runtime quota usage.         | +-----------------------------------------------------------------------------+</p>"},{"location":"reference/observable-notation/","title":"Observable Notation Reference","text":"<p>QuartumSE uses Pauli strings to specify quantum observables for expectation value estimation. This guide explains the notation, common patterns, and expected values for standard quantum states.</p>"},{"location":"reference/observable-notation/#pauli-string-syntax","title":"Pauli String Syntax","text":""},{"location":"reference/observable-notation/#basic-format","title":"Basic Format","text":"<p>An observable is written as a string of Pauli operators, one per qubit:</p> <pre><code>from quartumse.shadows.core import Observable\n\n# Single-qubit observables\nObservable(\"X\")     # X (Pauli-X) on qubit 0\nObservable(\"Y\")     # Y (Pauli-Y) on qubit 0\nObservable(\"Z\")     # Z (Pauli-Z) on qubit 0\nObservable(\"I\")     # I (Identity) on qubit 0\n\n# Multi-qubit observables\nObservable(\"ZII\")   # Z on qubit 0, Identity on qubits 1 and 2\nObservable(\"ZZI\")   # Z on qubits 0 and 1, Identity on qubit 2\nObservable(\"ZZZ\")   # Z on all three qubits\nObservable(\"XXX\")   # X on all three qubits\n</code></pre>"},{"location":"reference/observable-notation/#qubit-ordering","title":"Qubit Ordering","text":"<p>QuartumSE uses little-endian (Qiskit-style) qubit ordering: - Leftmost character = qubit 0 - Rightmost character = highest-index qubit</p> <pre><code># For a 3-qubit circuit\nObservable(\"XYZ\")\n# X on qubit 0\n# Y on qubit 1\n# Z on qubit 2\n</code></pre>"},{"location":"reference/observable-notation/#coefficients","title":"Coefficients","text":"<p>Observables can have multiplicative coefficients:</p> <pre><code>Observable(\"ZZ\", coefficient=0.5)   # 0.5 \u00d7 Z\u2080Z\u2081\nObservable(\"XX\", coefficient=-1.0)  # -1.0 \u00d7 X\u2080X\u2081\n</code></pre> <p>Output format: Results use <code>{coefficient}*{pauli_string}</code> notation: <pre><code>result.observables.keys()\n# Returns: ['1.0*ZII', '1.0*ZZI', '1.0*ZZZ']\n</code></pre></p>"},{"location":"reference/observable-notation/#pauli-operator-properties","title":"Pauli Operator Properties","text":""},{"location":"reference/observable-notation/#eigenvalues","title":"Eigenvalues","text":"<p>All Pauli operators have eigenvalues \u00b11:</p> Operator Eigenstate Eigenvalue X |+\u27e9 = (|0\u27e9 + |1\u27e9)/\u221a2 +1 X |-\u27e9 = (|0\u27e9 - |1\u27e9)/\u221a2 -1 Y |i+\u27e9 = (|0\u27e9 + i|1\u27e9)/\u221a2 +1 Y |i-\u27e9 = (|0\u27e9 - i|1\u27e9)/\u221a2 -1 Z |0\u27e9 +1 Z |1\u27e9 -1"},{"location":"reference/observable-notation/#commutation-relations","title":"Commutation Relations","text":"<ul> <li>Observables commute if they share qubits only on I or matching Pauli operators</li> <li>Observables anticommute if they differ on an odd number of qubits</li> </ul> <pre><code># Commuting observables (can measure simultaneously)\nObservable(\"ZII\") and Observable(\"ZZI\")  # \u2713 commute\nObservable(\"XII\") and Observable(\"YZZ\")  # \u2713 commute (different qubits)\n\n# Anticommuting observables (cannot measure simultaneously)\nObservable(\"XII\") and Observable(\"ZII\")  # \u2717 anticommute (differ on qubit 0)\nObservable(\"ZZ\") and Observable(\"XZ\")    # \u2717 anticommute (differ on qubit 0)\n</code></pre>"},{"location":"reference/observable-notation/#expected-values-for-common-states","title":"Expected Values for Common States","text":""},{"location":"reference/observable-notation/#computational-basis-states","title":"Computational Basis States","text":"<p>|00\u27e9 state: <pre><code>Observable(\"ZI\"): +1.0   # Z\u2080 = +1 (qubit 0 is |0\u27e9)\nObservable(\"IZ\"): +1.0   # Z\u2081 = +1 (qubit 1 is |0\u27e9)\nObservable(\"ZZ\"): +1.0   # Z\u2080Z\u2081 = (+1)(+1) = +1\nObservable(\"XI\"):  0.0   # X\u2080 = 0 (|0\u27e9 is equal superposition of X eigenstates)\nObservable(\"XX\"):  0.0   # X\u2080X\u2081 = 0\n</code></pre></p> <p>|11\u27e9 state: <pre><code>Observable(\"ZI\"): -1.0   # Z\u2080 = -1 (qubit 0 is |1\u27e9)\nObservable(\"IZ\"): -1.0   # Z\u2081 = -1 (qubit 1 is |1\u27e9)\nObservable(\"ZZ\"): +1.0   # Z\u2080Z\u2081 = (-1)(-1) = +1\nObservable(\"XI\"):  0.0   # X\u2080 = 0\nObservable(\"XX\"):  0.0   # X\u2080X\u2081 = 0\n</code></pre></p>"},{"location":"reference/observable-notation/#bell-states","title":"Bell States","text":"<p>|\u03a6\u207a\u27e9 = (|00\u27e9 + |11\u27e9)/\u221a2 (Bell state): <pre><code>Observable(\"ZI\"):  0.0   # Equal |0\u27e9 and |1\u27e9 on qubit 0\nObservable(\"IZ\"):  0.0   # Equal |0\u27e9 and |1\u27e9 on qubit 1\nObservable(\"ZZ\"): +1.0   # Correlated: both qubits have same parity\nObservable(\"XX\"): +1.0   # Both qubits in X-basis |+\u27e9\nObservable(\"YY\"): -1.0   # Y correlation\nObservable(\"XY\"):  0.0   # No XY correlation\n</code></pre></p> <p>|\u03a8\u207b\u27e9 = (|01\u27e9 - |10\u27e9)/\u221a2 (singlet state): <pre><code>Observable(\"ZI\"):  0.0\nObservable(\"IZ\"):  0.0\nObservable(\"ZZ\"): -1.0   # Anti-correlated\nObservable(\"XX\"): -1.0\nObservable(\"YY\"): -1.0\nObservable(\"XZ\"):  0.0\n</code></pre></p>"},{"location":"reference/observable-notation/#ghz-states","title":"GHZ States","text":"<p>|GHZ(3)\u27e9 = (|000\u27e9 + |111\u27e9)/\u221a2:</p> <p>GHZ states are stabilized by even-parity Z operators:</p> <pre><code># Single-qubit Z observables \u2192 0 (equal superposition)\nObservable(\"ZII\"):  0.0\nObservable(\"IZI\"):  0.0\nObservable(\"IIZ\"):  0.0\n\n# Two-qubit Z observables \u2192 +1 (even parity stabilizers)\nObservable(\"ZZI\"): +1.0\nObservable(\"ZIZ\"): +1.0\nObservable(\"IZZ\"): +1.0\n\n# Three-qubit Z observables \u2192 -1 (odd parity)\nObservable(\"ZZZ\"): -1.0\n\n# X observables\nObservable(\"XXX\"): +1.0  # All qubits in |+\u27e9 superposition\nObservable(\"XII\"):  0.0  # Single X \u2192 0\nObservable(\"XXI\"):  0.0  # Two X's \u2192 0\n</code></pre> <p>Rule for GHZ: - Even number of Z operators \u2192 +1 - Odd number of Z operators \u2192 0 (for single Z) or -1 (for all Z)</p> <p>|GHZ(4)\u27e9 = (|0000\u27e9 + |1111\u27e9)/\u221a2: <pre><code>Observable(\"ZIII\"):  0.0\nObservable(\"ZZII\"): +1.0\nObservable(\"ZZZI\"): +1.0\nObservable(\"ZZZZ\"): +1.0  # Even number (4) of Z's\nObservable(\"XXXX\"): +1.0\n</code></pre></p>"},{"location":"reference/observable-notation/#w-states","title":"W States","text":"<p>|W(3)\u27e9 = (|001\u27e9 + |010\u27e9 + |100\u27e9)/\u221a3:</p> <pre><code>Observable(\"ZII\"): -1/3  # Two |0\u27e9 components, one |1\u27e9\nObservable(\"IZI\"): -1/3\nObservable(\"IIZ\"): -1/3\nObservable(\"ZZZ\"): -1/3  # Mix of even/odd parities\nObservable(\"XXX\"):  1/3  # Partial correlation\n</code></pre>"},{"location":"reference/observable-notation/#hamiltonian-observables","title":"Hamiltonian Observables","text":"<p>Many quantum algorithms estimate Hamiltonian energy:</p>"},{"location":"reference/observable-notation/#ising-model-1d-chain","title":"Ising Model (1D chain)","text":"<pre><code># H = \u03a3\u1d62 J\u1d62Z\u1d62Z\u1d62\u208a\u2081 + \u03a3\u1d62h\u1d62Z\u1d62\n# For 3 qubits with J=-1.0, h=0.5:\n\nObservable(\"ZZI\", coefficient=-1.0)  # Z\u2080Z\u2081 interaction\nObservable(\"IZZ\", coefficient=-1.0)  # Z\u2081Z\u2082 interaction\nObservable(\"ZII\", coefficient=0.5)   # Z\u2080 field\nObservable(\"IZI\", coefficient=0.5)   # Z\u2081 field\nObservable(\"IIZ\", coefficient=0.5)   # Z\u2082 field\n\n# Total energy = sum of all observable expectation values\n</code></pre>"},{"location":"reference/observable-notation/#molecular-hamiltonians-vqe","title":"Molecular Hamiltonians (VQE)","text":"<pre><code># H\u2082 molecule (example coefficients)\nObservable(\"II\", coefficient=-0.8105)    # Identity term\nObservable(\"ZI\", coefficient=0.1721)     # Z\u2080 term\nObservable(\"IZ\", coefficient=0.1721)     # Z\u2081 term\nObservable(\"ZZ\", coefficient=-0.2279)    # Z\u2080Z\u2081 correlation\nObservable(\"XX\", coefficient=0.1809)     # XX exchange\nObservable(\"YY\", coefficient=0.1809)     # YY exchange\n</code></pre>"},{"location":"reference/observable-notation/#interpreting-results","title":"Interpreting Results","text":""},{"location":"reference/observable-notation/#confidence-intervals","title":"Confidence Intervals","text":"<p>QuartumSE reports 95% confidence intervals around expectation values:</p> <pre><code>result.observables[\"1.0*ZZZ\"]\n# {\n#     'expectation_value': -0.9922,\n#     'variance': 0.0156,\n#     'ci_95': (-1.0353, -0.9491),\n#     'ci_width': 0.0862\n# }\n</code></pre> <p>Interpretation: - Expectation value: -0.9922 (close to theoretical -1.0 for GHZ) - Variance: 0.0156 (measurement uncertainty) - 95% CI: [-1.0353, -0.9491] (true value likely in this range) - CI width: 0.0862 (precision measure; smaller is better)</p>"},{"location":"reference/observable-notation/#comparing-to-theory","title":"Comparing to Theory","text":"<p>Example: GHZ(3) validation</p> <pre><code># Theoretical expectations\ntheory = {\n    \"1.0*ZII\":  0.0,\n    \"1.0*ZZI\": +1.0,\n    \"1.0*ZZZ\": -1.0,\n}\n\n# Experimental results\nfor obs_str, data in result.observables.items():\n    estimated = data['expectation_value']\n    expected = theory[obs_str]\n    ci = data['ci_95']\n\n    # Check if theory is within confidence interval\n    in_ci = ci[0] &lt;= expected &lt;= ci[1]\n    status = \"\u2713\" if in_ci else \"\u2717\"\n\n    print(f\"{obs_str:10} Est: {estimated:+.4f}  \"\n          f\"Theory: {expected:+.4f}  {status}\")\n</code></pre> <p>Output: <pre><code>1.0*ZII    Est: +0.0039  Theory: +0.0000  \u2713\n1.0*ZZI    Est: +0.9961  Theory: +1.0000  \u2713\n1.0*ZZZ    Est: -0.9922  Theory: -1.0000  \u2713\n</code></pre></p>"},{"location":"reference/observable-notation/#common-patterns","title":"Common Patterns","text":""},{"location":"reference/observable-notation/#entanglement-witnesses","title":"Entanglement Witnesses","text":"<p>CHSH Inequality: <pre><code># S = |\u27e8XX\u27e9 + \u27e8XY\u27e9 + \u27e8YX\u27e9 - \u27e8YY\u27e9|\n# Classical limit: S \u2264 2\n# Quantum (Bell state): S = 2\u221a2 \u2248 2.828\n\nObservable(\"XX\")  # \u27e8XX\u27e9\nObservable(\"XY\")  # \u27e8XY\u27e9\nObservable(\"YX\")  # \u27e8YX\u27e9\nObservable(\"YY\")  # \u27e8YY\u27e9\n</code></pre></p>"},{"location":"reference/observable-notation/#fidelity-estimation","title":"Fidelity Estimation","text":"<p>Overlap with target state |\u03c8\u27e9: <pre><code># F = \u27e8\u03c8|\u03c1|\u03c8\u27e9 = \u03a3\u1d62 \u27e8P\u1d62\u27e9 / 2\u207f\n# where P\u1d62 are stabilizer observables\n\n# For GHZ(3):\nobservables = [\n    Observable(\"ZZI\"),  # Stabilizer 1\n    Observable(\"IZZ\"),  # Stabilizer 2\n]\n# F \u2248 (1 + \u27e8ZZI\u27e9 + \u27e8IZZ\u27e9 + \u27e8ZZI\u27e9\u27e8IZZ\u27e9) / 4\n</code></pre></p>"},{"location":"reference/observable-notation/#symmetry-testing","title":"Symmetry Testing","text":"<p>Check parity symmetry: <pre><code># Even parity: should be +1 or -1\nObservable(\"ZZZZ\")\n\n# If result \u2248 0, state lacks definite parity\n# (e.g., equal mixture of even/odd states)\n</code></pre></p>"},{"location":"reference/observable-notation/#further-reading","title":"Further Reading","text":"<ul> <li>Qiskit Observable Tutorial: qiskit.org/documentation/tutorials/operators</li> <li>Pauli Operator Algebra: See Nielsen &amp; Chuang, Chapter 2</li> <li>Classical Shadows Theory: Huang, Kueng, Preskill (2020)</li> <li>QuartumSE Architecture: docs/explanation/shadows-theory.md</li> </ul>"},{"location":"reference/observable-notation/#quick-reference","title":"Quick Reference","text":"Observable Name Measures <code>I</code> Identity Always +1 <code>X</code> Pauli-X X-basis projection <code>Y</code> Pauli-Y Y-basis projection <code>Z</code> Pauli-Z Computational basis projection <code>ZZ</code> Z-correlation Parity between two qubits <code>XX</code> X-correlation X-basis entanglement <code>ZZZ</code> 3-qubit parity Stabilizer for GHZ states <p>Tip: When debugging, start with Z observables (<code>ZI</code>, <code>ZZ</code>, etc.) since they measure in the computational basis and are easier to interpret from bitstring histograms.</p>"},{"location":"reference/api/","title":"API Reference","text":"<p>QuartumSE - Quantum Measurement Optimization &amp; Observability Platform</p> <p>A vendor-neutral framework for running quantum experiments with: - Classical shadows for shot-efficient observable estimation - Rigorous error mitigation and confidence intervals - Full provenance tracking and reproducibility - Cross-platform backend support (IBM, AWS, and more)</p> <p>License: Apache 2.0</p>"},{"location":"reference/api/#quartumse.ClassicalShadows","title":"<code>ClassicalShadows</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for classical shadows implementations.</p> <p>Different versions (v0-v4) subclass this to provide specific algorithms.</p> Source code in <code>src/quartumse/shadows/core.py</code> <pre><code>class ClassicalShadows(ABC):\n    \"\"\"\n    Abstract base class for classical shadows implementations.\n\n    Different versions (v0-v4) subclass this to provide specific algorithms.\n    \"\"\"\n\n    def __init__(self, config: Any):\n        self.config = config\n        self.shadow_data: np.ndarray | None = None\n        self.measurement_bases: np.ndarray | None = None\n        self.measurement_outcomes: np.ndarray | None = None\n\n    @abstractmethod\n    def generate_measurement_circuits(\n        self, base_circuit: QuantumCircuit, num_shadows: int\n    ) -&gt; list[QuantumCircuit]:\n        \"\"\"\n        Generate randomized measurement circuits for shadows protocol.\n\n        Args:\n            base_circuit: The state preparation circuit\n            num_shadows: Number of random measurements\n\n        Returns:\n            List of circuits with randomized measurements appended\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def reconstruct_classical_shadow(\n        self, measurement_outcomes: np.ndarray, measurement_bases: np.ndarray\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Reconstruct classical shadow snapshots from measurement data.\n\n        Args:\n            measurement_outcomes: Binary outcomes (0/1) for each measurement\n            measurement_bases: Which basis was measured for each qubit\n\n        Returns:\n            Array of shadow snapshots (density matrix representations)\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def estimate_observable(\n        self, observable: Observable, shadow_data: np.ndarray | None = None\n    ) -&gt; ShadowEstimate:\n        \"\"\"\n        Estimate expectation value of an observable using shadow data.\n\n        Args:\n            observable: The observable to estimate\n            shadow_data: Pre-computed shadow snapshots (or use self.shadow_data)\n\n        Returns:\n            Estimate with confidence interval\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def estimate_shadow_size_needed(self, observable: Observable, target_precision: float) -&gt; int:\n        \"\"\"Estimate the number of shadows required for a desired precision.\"\"\"\n\n        raise NotImplementedError\n\n    def estimate_multiple_observables(\n        self, observables: list[Observable]\n    ) -&gt; dict[str, ShadowEstimate]:\n        \"\"\"\n        Estimate multiple observables from the same shadow data.\n\n        This is the key advantage: one shadow dataset, many observables.\n        \"\"\"\n        if self.shadow_data is None:\n            raise ValueError(\"No shadow data available. Run generate_measurement_circuits first.\")\n\n        results = {}\n        for obs in observables:\n            estimate = self.estimate_observable(obs)\n            results[str(obs)] = estimate\n\n        return results\n\n    def compute_variance_bound(self, observable: Observable, shadow_size: int) -&gt; float:\n        \"\"\"\n        Theoretical variance bound for the shadow estimator.\n\n        Useful for shot allocation and adaptive strategies.\n        \"\"\"\n        # Default implementation (subclasses can override)\n        # For random local Clifford: Var \u2264 4^k / M, where k = support size\n        support_size = sum(1 for p in observable.pauli_string if p != \"I\")\n        return float(4**support_size) / float(shadow_size)\n\n    def compute_confidence_interval(\n        self, mean: float, variance: float, n_samples: int, confidence: float = 0.95\n    ) -&gt; tuple[float, float]:\n        \"\"\"Compute confidence interval using normal approximation.\"\"\"\n        from scipy import stats\n\n        std_error = np.sqrt(variance / n_samples)\n        z_score = float(stats.norm.ppf((1 + confidence) / 2))\n\n        ci_lower = mean - z_score * std_error\n        ci_upper = mean + z_score * std_error\n\n        return (ci_lower, ci_upper)\n</code></pre>"},{"location":"reference/api/#quartumse.ClassicalShadows.compute_confidence_interval","title":"<code>compute_confidence_interval(mean, variance, n_samples, confidence=0.95)</code>","text":"<p>Compute confidence interval using normal approximation.</p> Source code in <code>src/quartumse/shadows/core.py</code> <pre><code>def compute_confidence_interval(\n    self, mean: float, variance: float, n_samples: int, confidence: float = 0.95\n) -&gt; tuple[float, float]:\n    \"\"\"Compute confidence interval using normal approximation.\"\"\"\n    from scipy import stats\n\n    std_error = np.sqrt(variance / n_samples)\n    z_score = float(stats.norm.ppf((1 + confidence) / 2))\n\n    ci_lower = mean - z_score * std_error\n    ci_upper = mean + z_score * std_error\n\n    return (ci_lower, ci_upper)\n</code></pre>"},{"location":"reference/api/#quartumse.ClassicalShadows.compute_variance_bound","title":"<code>compute_variance_bound(observable, shadow_size)</code>","text":"<p>Theoretical variance bound for the shadow estimator.</p> <p>Useful for shot allocation and adaptive strategies.</p> Source code in <code>src/quartumse/shadows/core.py</code> <pre><code>def compute_variance_bound(self, observable: Observable, shadow_size: int) -&gt; float:\n    \"\"\"\n    Theoretical variance bound for the shadow estimator.\n\n    Useful for shot allocation and adaptive strategies.\n    \"\"\"\n    # Default implementation (subclasses can override)\n    # For random local Clifford: Var \u2264 4^k / M, where k = support size\n    support_size = sum(1 for p in observable.pauli_string if p != \"I\")\n    return float(4**support_size) / float(shadow_size)\n</code></pre>"},{"location":"reference/api/#quartumse.ClassicalShadows.estimate_multiple_observables","title":"<code>estimate_multiple_observables(observables)</code>","text":"<p>Estimate multiple observables from the same shadow data.</p> <p>This is the key advantage: one shadow dataset, many observables.</p> Source code in <code>src/quartumse/shadows/core.py</code> <pre><code>def estimate_multiple_observables(\n    self, observables: list[Observable]\n) -&gt; dict[str, ShadowEstimate]:\n    \"\"\"\n    Estimate multiple observables from the same shadow data.\n\n    This is the key advantage: one shadow dataset, many observables.\n    \"\"\"\n    if self.shadow_data is None:\n        raise ValueError(\"No shadow data available. Run generate_measurement_circuits first.\")\n\n    results = {}\n    for obs in observables:\n        estimate = self.estimate_observable(obs)\n        results[str(obs)] = estimate\n\n    return results\n</code></pre>"},{"location":"reference/api/#quartumse.ClassicalShadows.estimate_observable","title":"<code>estimate_observable(observable, shadow_data=None)</code>  <code>abstractmethod</code>","text":"<p>Estimate expectation value of an observable using shadow data.</p> <p>Parameters:</p> Name Type Description Default <code>observable</code> <code>Observable</code> <p>The observable to estimate</p> required <code>shadow_data</code> <code>ndarray | None</code> <p>Pre-computed shadow snapshots (or use self.shadow_data)</p> <code>None</code> <p>Returns:</p> Type Description <code>ShadowEstimate</code> <p>Estimate with confidence interval</p> Source code in <code>src/quartumse/shadows/core.py</code> <pre><code>@abstractmethod\ndef estimate_observable(\n    self, observable: Observable, shadow_data: np.ndarray | None = None\n) -&gt; ShadowEstimate:\n    \"\"\"\n    Estimate expectation value of an observable using shadow data.\n\n    Args:\n        observable: The observable to estimate\n        shadow_data: Pre-computed shadow snapshots (or use self.shadow_data)\n\n    Returns:\n        Estimate with confidence interval\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/api/#quartumse.ClassicalShadows.estimate_shadow_size_needed","title":"<code>estimate_shadow_size_needed(observable, target_precision)</code>  <code>abstractmethod</code>","text":"<p>Estimate the number of shadows required for a desired precision.</p> Source code in <code>src/quartumse/shadows/core.py</code> <pre><code>@abstractmethod\ndef estimate_shadow_size_needed(self, observable: Observable, target_precision: float) -&gt; int:\n    \"\"\"Estimate the number of shadows required for a desired precision.\"\"\"\n\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/api/#quartumse.ClassicalShadows.generate_measurement_circuits","title":"<code>generate_measurement_circuits(base_circuit, num_shadows)</code>  <code>abstractmethod</code>","text":"<p>Generate randomized measurement circuits for shadows protocol.</p> <p>Parameters:</p> Name Type Description Default <code>base_circuit</code> <code>QuantumCircuit</code> <p>The state preparation circuit</p> required <code>num_shadows</code> <code>int</code> <p>Number of random measurements</p> required <p>Returns:</p> Type Description <code>list[QuantumCircuit]</code> <p>List of circuits with randomized measurements appended</p> Source code in <code>src/quartumse/shadows/core.py</code> <pre><code>@abstractmethod\ndef generate_measurement_circuits(\n    self, base_circuit: QuantumCircuit, num_shadows: int\n) -&gt; list[QuantumCircuit]:\n    \"\"\"\n    Generate randomized measurement circuits for shadows protocol.\n\n    Args:\n        base_circuit: The state preparation circuit\n        num_shadows: Number of random measurements\n\n    Returns:\n        List of circuits with randomized measurements appended\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/api/#quartumse.ClassicalShadows.reconstruct_classical_shadow","title":"<code>reconstruct_classical_shadow(measurement_outcomes, measurement_bases)</code>  <code>abstractmethod</code>","text":"<p>Reconstruct classical shadow snapshots from measurement data.</p> <p>Parameters:</p> Name Type Description Default <code>measurement_outcomes</code> <code>ndarray</code> <p>Binary outcomes (0/1) for each measurement</p> required <code>measurement_bases</code> <code>ndarray</code> <p>Which basis was measured for each qubit</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of shadow snapshots (density matrix representations)</p> Source code in <code>src/quartumse/shadows/core.py</code> <pre><code>@abstractmethod\ndef reconstruct_classical_shadow(\n    self, measurement_outcomes: np.ndarray, measurement_bases: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"\n    Reconstruct classical shadow snapshots from measurement data.\n\n    Args:\n        measurement_outcomes: Binary outcomes (0/1) for each measurement\n        measurement_bases: Which basis was measured for each qubit\n\n    Returns:\n        Array of shadow snapshots (density matrix representations)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/api/#quartumse.Estimator","title":"<code>Estimator</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for quantum observable estimators.</p> <p>Provides unified interface for different estimation strategies: - Classical shadows (various versions) - Direct measurement - Grouped Pauli measurement</p> Source code in <code>src/quartumse/estimator/base.py</code> <pre><code>class Estimator(ABC):\n    \"\"\"\n    Abstract base class for quantum observable estimators.\n\n    Provides unified interface for different estimation strategies:\n    - Classical shadows (various versions)\n    - Direct measurement\n    - Grouped Pauli measurement\n    \"\"\"\n\n    def __init__(self, backend: Any, config: Any | None = None) -&gt; None:\n        self.backend = backend\n        self.config = config\n\n    @abstractmethod\n    def estimate(\n        self,\n        circuit: QuantumCircuit,\n        observables: list[Observable],\n        target_precision: float | None = None,\n    ) -&gt; EstimationResult:\n        \"\"\"\n        Estimate expectation values of observables.\n\n        Args:\n            circuit: State preparation circuit\n            observables: List of observables to estimate\n            target_precision: Desired precision (optional)\n\n        Returns:\n            Estimation results with confidence intervals\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def estimate_shots_needed(self, observables: list[Observable], target_precision: float) -&gt; int:\n        \"\"\"\n        Estimate number of shots needed for target precision.\n\n        Used for cost estimation and shot allocation.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/api/#quartumse.Estimator.estimate","title":"<code>estimate(circuit, observables, target_precision=None)</code>  <code>abstractmethod</code>","text":"<p>Estimate expectation values of observables.</p> <p>Parameters:</p> Name Type Description Default <code>circuit</code> <code>QuantumCircuit</code> <p>State preparation circuit</p> required <code>observables</code> <code>list[Observable]</code> <p>List of observables to estimate</p> required <code>target_precision</code> <code>float | None</code> <p>Desired precision (optional)</p> <code>None</code> <p>Returns:</p> Type Description <code>EstimationResult</code> <p>Estimation results with confidence intervals</p> Source code in <code>src/quartumse/estimator/base.py</code> <pre><code>@abstractmethod\ndef estimate(\n    self,\n    circuit: QuantumCircuit,\n    observables: list[Observable],\n    target_precision: float | None = None,\n) -&gt; EstimationResult:\n    \"\"\"\n    Estimate expectation values of observables.\n\n    Args:\n        circuit: State preparation circuit\n        observables: List of observables to estimate\n        target_precision: Desired precision (optional)\n\n    Returns:\n        Estimation results with confidence intervals\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/api/#quartumse.Estimator.estimate_shots_needed","title":"<code>estimate_shots_needed(observables, target_precision)</code>  <code>abstractmethod</code>","text":"<p>Estimate number of shots needed for target precision.</p> <p>Used for cost estimation and shot allocation.</p> Source code in <code>src/quartumse/estimator/base.py</code> <pre><code>@abstractmethod\ndef estimate_shots_needed(self, observables: list[Observable], target_precision: float) -&gt; int:\n    \"\"\"\n    Estimate number of shots needed for target precision.\n\n    Used for cost estimation and shot allocation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/api/#quartumse.ProvenanceManifest","title":"<code>ProvenanceManifest</code>","text":"<p>High-level interface for creating and managing provenance manifests.</p> Source code in <code>src/quartumse/reporting/manifest.py</code> <pre><code>class ProvenanceManifest:\n    \"\"\"\n    High-level interface for creating and managing provenance manifests.\n    \"\"\"\n\n    def __init__(self, schema: ManifestSchema):\n        self.schema = schema\n\n    @classmethod\n    def create(\n        cls,\n        experiment_id: str,\n        circuit_fingerprint: CircuitFingerprint,\n        backend_snapshot: BackendSnapshot,\n        **kwargs: Any,\n    ) -&gt; \"ProvenanceManifest\":\n        \"\"\"Create a new manifest with required fields.\"\"\"\n        schema = ManifestSchema(\n            experiment_id=experiment_id,\n            circuit=circuit_fingerprint,\n            backend=backend_snapshot,\n            **kwargs,\n        )\n        return cls(schema)\n\n    def to_json(self, path: str | Path | None = None) -&gt; str:\n        \"\"\"Export manifest as JSON.\"\"\"\n        json_str = self.schema.model_dump_json(indent=2)\n\n        if path:\n            Path(path).write_text(json_str)\n\n        return json_str\n\n    @classmethod\n    def from_json(cls, path: str | Path) -&gt; \"ProvenanceManifest\":\n        \"\"\"Load manifest from JSON file.\"\"\"\n        json_data = Path(path).read_text()\n        schema = ManifestSchema.model_validate_json(json_data)\n        return cls(schema)\n\n    def add_tag(self, tag: str) -&gt; None:\n        \"\"\"Add a searchable tag.\"\"\"\n        if tag not in self.schema.tags:\n            self.schema.tags.append(tag)\n\n    def update_results(self, results: dict[str, Any]) -&gt; None:\n        \"\"\"Update the results summary.\"\"\"\n        self.schema.results_summary.update(results)\n\n    def validate(self, *, require_shot_file: bool = True) -&gt; bool:\n        \"\"\"Validate the manifest schema and ensure referenced artifacts exist.\"\"\"\n\n        if require_shot_file:\n            shot_path = Path(self.schema.shot_data_path)\n            if not shot_path.exists():\n                raise FileNotFoundError(f\"Shot data referenced by manifest is missing: {shot_path}\")\n\n        return True\n\n    def __repr__(self) -&gt; str:\n        return (\n            f\"ProvenanceManifest(id={self.schema.experiment_id}, \"\n            f\"backend={self.schema.backend.backend_name}, \"\n            f\"created={self.schema.created_at.isoformat()})\"\n        )\n</code></pre>"},{"location":"reference/api/#quartumse.ProvenanceManifest.add_tag","title":"<code>add_tag(tag)</code>","text":"<p>Add a searchable tag.</p> Source code in <code>src/quartumse/reporting/manifest.py</code> <pre><code>def add_tag(self, tag: str) -&gt; None:\n    \"\"\"Add a searchable tag.\"\"\"\n    if tag not in self.schema.tags:\n        self.schema.tags.append(tag)\n</code></pre>"},{"location":"reference/api/#quartumse.ProvenanceManifest.create","title":"<code>create(experiment_id, circuit_fingerprint, backend_snapshot, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a new manifest with required fields.</p> Source code in <code>src/quartumse/reporting/manifest.py</code> <pre><code>@classmethod\ndef create(\n    cls,\n    experiment_id: str,\n    circuit_fingerprint: CircuitFingerprint,\n    backend_snapshot: BackendSnapshot,\n    **kwargs: Any,\n) -&gt; \"ProvenanceManifest\":\n    \"\"\"Create a new manifest with required fields.\"\"\"\n    schema = ManifestSchema(\n        experiment_id=experiment_id,\n        circuit=circuit_fingerprint,\n        backend=backend_snapshot,\n        **kwargs,\n    )\n    return cls(schema)\n</code></pre>"},{"location":"reference/api/#quartumse.ProvenanceManifest.from_json","title":"<code>from_json(path)</code>  <code>classmethod</code>","text":"<p>Load manifest from JSON file.</p> Source code in <code>src/quartumse/reporting/manifest.py</code> <pre><code>@classmethod\ndef from_json(cls, path: str | Path) -&gt; \"ProvenanceManifest\":\n    \"\"\"Load manifest from JSON file.\"\"\"\n    json_data = Path(path).read_text()\n    schema = ManifestSchema.model_validate_json(json_data)\n    return cls(schema)\n</code></pre>"},{"location":"reference/api/#quartumse.ProvenanceManifest.to_json","title":"<code>to_json(path=None)</code>","text":"<p>Export manifest as JSON.</p> Source code in <code>src/quartumse/reporting/manifest.py</code> <pre><code>def to_json(self, path: str | Path | None = None) -&gt; str:\n    \"\"\"Export manifest as JSON.\"\"\"\n    json_str = self.schema.model_dump_json(indent=2)\n\n    if path:\n        Path(path).write_text(json_str)\n\n    return json_str\n</code></pre>"},{"location":"reference/api/#quartumse.ProvenanceManifest.update_results","title":"<code>update_results(results)</code>","text":"<p>Update the results summary.</p> Source code in <code>src/quartumse/reporting/manifest.py</code> <pre><code>def update_results(self, results: dict[str, Any]) -&gt; None:\n    \"\"\"Update the results summary.\"\"\"\n    self.schema.results_summary.update(results)\n</code></pre>"},{"location":"reference/api/#quartumse.ProvenanceManifest.validate","title":"<code>validate(*, require_shot_file=True)</code>","text":"<p>Validate the manifest schema and ensure referenced artifacts exist.</p> Source code in <code>src/quartumse/reporting/manifest.py</code> <pre><code>def validate(self, *, require_shot_file: bool = True) -&gt; bool:\n    \"\"\"Validate the manifest schema and ensure referenced artifacts exist.\"\"\"\n\n    if require_shot_file:\n        shot_path = Path(self.schema.shot_data_path)\n        if not shot_path.exists():\n            raise FileNotFoundError(f\"Shot data referenced by manifest is missing: {shot_path}\")\n\n    return True\n</code></pre>"},{"location":"reference/api/#quartumse.Report","title":"<code>Report</code>","text":"<p>Container for experiment report data.</p> Source code in <code>src/quartumse/reporting/report.py</code> <pre><code>class Report:\n    \"\"\"Container for experiment report data.\"\"\"\n\n    def __init__(\n        self,\n        manifest: ProvenanceManifest,\n        plots: dict[str, Any] | None = None,\n        shot_diagnostics: ShotDataDiagnostics | None = None,\n    ):\n        self.manifest = manifest\n        self.plots = plots or {}\n        self.shot_diagnostics = shot_diagnostics\n\n    def to_html(self, output_path: str | Path | None = None) -&gt; str:\n        \"\"\"Generate HTML report.\"\"\"\n        template = Template(HTML_TEMPLATE)\n        metrics_context = normalise_metrics_for_report(\n            self.manifest.schema.results_summary.get(\"metrics\")\n            if isinstance(self.manifest.schema.results_summary, dict)\n            else None\n        )\n        html = template.render(\n            manifest=self.manifest.schema,\n            now=datetime.now(timezone.utc).isoformat(),\n            shot_diagnostics=self.shot_diagnostics.to_dict() if self.shot_diagnostics else None,\n            metrics=metrics_context,\n        )\n\n        if output_path:\n            Path(output_path).write_text(html, encoding=\"utf-8\")\n\n        return html\n\n    def to_pdf(self, output_path: str | Path) -&gt; None:\n        \"\"\"Generate PDF report (requires weasyprint).\"\"\"\n        try:\n            from weasyprint import HTML\n\n            html_content = self.to_html()\n            HTML(string=html_content).write_pdf(output_path)\n        except ImportError as err:\n            raise ImportError(\n                \"PDF generation requires weasyprint. Install with: pip install weasyprint\"\n            ) from err\n</code></pre>"},{"location":"reference/api/#quartumse.Report.to_html","title":"<code>to_html(output_path=None)</code>","text":"<p>Generate HTML report.</p> Source code in <code>src/quartumse/reporting/report.py</code> <pre><code>def to_html(self, output_path: str | Path | None = None) -&gt; str:\n    \"\"\"Generate HTML report.\"\"\"\n    template = Template(HTML_TEMPLATE)\n    metrics_context = normalise_metrics_for_report(\n        self.manifest.schema.results_summary.get(\"metrics\")\n        if isinstance(self.manifest.schema.results_summary, dict)\n        else None\n    )\n    html = template.render(\n        manifest=self.manifest.schema,\n        now=datetime.now(timezone.utc).isoformat(),\n        shot_diagnostics=self.shot_diagnostics.to_dict() if self.shot_diagnostics else None,\n        metrics=metrics_context,\n    )\n\n    if output_path:\n        Path(output_path).write_text(html, encoding=\"utf-8\")\n\n    return html\n</code></pre>"},{"location":"reference/api/#quartumse.Report.to_pdf","title":"<code>to_pdf(output_path)</code>","text":"<p>Generate PDF report (requires weasyprint).</p> Source code in <code>src/quartumse/reporting/report.py</code> <pre><code>def to_pdf(self, output_path: str | Path) -&gt; None:\n    \"\"\"Generate PDF report (requires weasyprint).\"\"\"\n    try:\n        from weasyprint import HTML\n\n        html_content = self.to_html()\n        HTML(string=html_content).write_pdf(output_path)\n    except ImportError as err:\n        raise ImportError(\n            \"PDF generation requires weasyprint. Install with: pip install weasyprint\"\n        ) from err\n</code></pre>"},{"location":"reference/api/#quartumse.ShadowConfig","title":"<code>ShadowConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for classical shadows estimation.</p> Source code in <code>src/quartumse/shadows/config.py</code> <pre><code>class ShadowConfig(BaseModel):\n    \"\"\"Configuration for classical shadows estimation.\"\"\"\n\n    # Core parameters\n    version: ShadowVersion = Field(\n        default=ShadowVersion.V0_BASELINE, description=\"Shadows algorithm version\"\n    )\n    shadow_size: int = Field(\n        default=1000, description=\"Number of random measurements (shadow size)\"\n    )\n    measurement_ensemble: MeasurementEnsemble = Field(\n        default=MeasurementEnsemble.RANDOM_LOCAL_CLIFFORD\n    )\n\n    # v1+ (noise-aware)\n    apply_inverse_channel: bool = Field(\n        default=False, description=\"Apply noise-aware inverse channel (v1+)\"\n    )\n    noise_model_path: str | None = Field(None, description=\"Path to serialized noise model\")\n\n    # v2+ (fermionic)\n    fermionic_mode: bool = Field(default=False, description=\"Enable fermionic shadows (v2+)\")\n    rdm_order: int = Field(default=1, description=\"RDM order for fermionic mode (1 or 2)\")\n\n    # v3+ (adaptive)\n    adaptive: bool = Field(default=False, description=\"Use adaptive measurement selection (v3+)\")\n    target_observables: list[str] | None = Field(\n        None, description=\"Observable strings for adaptive prioritization\"\n    )\n    derandomization_strategy: str | None = Field(\n        None, description=\"greedy, importance_sampling, etc.\"\n    )\n\n    # v4+ (robust)\n    bayesian_inference: bool = Field(\n        default=False, description=\"Enable Bayesian robust estimation (v4+)\"\n    )\n    bootstrap_samples: int = Field(default=1000, description=\"Bootstrap samples for CI (v4+)\")\n    confidence_level: float = Field(default=0.95, description=\"Confidence interval level\")\n\n    # General settings\n    random_seed: int | None = Field(None, description=\"Random seed for reproducibility\")\n    parallel_shots: bool = Field(\n        default=True, description=\"Execute shadow measurements in parallel batches\"\n    )\n    batch_size: int | None = Field(None, description=\"Batch size for parallel execution\")\n\n    # Variance reduction\n    median_of_means: bool = Field(\n        default=False, description=\"Use median-of-means estimator for robustness\"\n    )\n    num_groups: int = Field(default=10, description=\"Number of groups for median-of-means\")\n\n    # Advanced\n    custom_parameters: dict[str, Any] = Field(\n        default_factory=dict, description=\"Version-specific custom parameters\"\n    )\n\n    model_config = ConfigDict(use_enum_values=False)\n\n    def validate_version_compatibility(self) -&gt; None:\n        \"\"\"Validate that enabled features match the selected version.\"\"\"\n\n        # Warning: simplified validation\n        # In production, this would check feature availability\n        pass\n</code></pre>"},{"location":"reference/api/#quartumse.ShadowConfig.validate_version_compatibility","title":"<code>validate_version_compatibility()</code>","text":"<p>Validate that enabled features match the selected version.</p> Source code in <code>src/quartumse/shadows/config.py</code> <pre><code>def validate_version_compatibility(self) -&gt; None:\n    \"\"\"Validate that enabled features match the selected version.\"\"\"\n\n    # Warning: simplified validation\n    # In production, this would check feature availability\n    pass\n</code></pre>"},{"location":"reference/api/#quartumse.ShadowEstimator","title":"<code>ShadowEstimator</code>","text":"<p>               Bases: <code>Estimator</code></p> <p>Observable estimator using classical shadows.</p> <p>Automatically selects shadow version based on config and orchestrates: 1. Shadow measurement generation 2. Circuit execution 3. Shadow reconstruction 4. Observable estimation 5. Provenance tracking</p> Source code in <code>src/quartumse/estimator/shadow_estimator.py</code> <pre><code>class ShadowEstimator(Estimator):\n    \"\"\"\n    Observable estimator using classical shadows.\n\n    Automatically selects shadow version based on config and orchestrates:\n    1. Shadow measurement generation\n    2. Circuit execution\n    3. Shadow reconstruction\n    4. Observable estimation\n    5. Provenance tracking\n    \"\"\"\n\n    def __init__(\n        self,\n        backend: Backend | str,\n        shadow_config: ShadowConfig | None = None,\n        mitigation_config: MitigationConfig | None = None,\n        data_dir: str | Path | None = None,\n    ):\n        \"\"\"\n        Initialize shadow estimator.\n\n        Args:\n            backend: Qiskit backend or backend name (e.g., \"aer_simulator\")\n            shadow_config: Classical shadows configuration\n            mitigation_config: Error mitigation configuration\n            data_dir: Directory for storing shot data and manifests\n        \"\"\"\n        # Handle backend\n        self._backend_descriptor: str | None = None\n        self._backend_snapshot: BackendSnapshot | None = None\n\n        if isinstance(backend, str):\n            self._backend_descriptor = backend\n            if \":\" in backend:\n                resolved_backend, snapshot = resolve_backend(backend)\n                backend = resolved_backend\n                self._backend_snapshot = snapshot\n            elif backend == \"aer_simulator\":\n                backend = AerSimulator()\n                self._backend_snapshot = create_backend_snapshot(backend)\n            else:\n                raise ValueError(f\"Unknown backend string: {backend}\")\n        else:\n            self._backend_descriptor = getattr(backend, \"name\", None)\n\n        super().__init__(backend, shadow_config)\n\n        self._runtime_sampler: SamplerPrimitive | None = None\n        self._runtime_sampler_checked = False\n        self._use_runtime_sampler = is_ibm_runtime_backend(self.backend)\n\n        self.shadow_config = shadow_config or ShadowConfig.model_validate({})\n        self.mitigation_config = mitigation_config or MitigationConfig()\n        self.data_dir = Path(data_dir) if data_dir else Path(\"./data\")\n        self.data_dir.mkdir(parents=True, exist_ok=True)\n\n        self.measurement_error_mitigation: MeasurementErrorMitigation | None = None\n        self._mem_required = (\n            self.shadow_config.version == ShadowVersion.V1_NOISE_AWARE\n            or self.shadow_config.apply_inverse_channel\n            or (\"MEM\" in self.mitigation_config.techniques)\n        )\n        if self._mem_required:\n            self.measurement_error_mitigation = MeasurementErrorMitigation(self.backend)\n\n        # Initialize shadow implementation based on version\n        self.shadow_impl: ClassicalShadows = self._create_shadow_implementation()\n\n        # Initialize shot data writer\n        self.shot_data_writer = ShotDataWriter(self.data_dir)\n\n    def _get_runtime_sampler(self) -&gt; SamplerPrimitive | None:\n        \"\"\"Initialise (if necessary) and return the IBM Runtime sampler.\"\"\"\n\n        if not self._use_runtime_sampler:\n            return None\n\n        if not self._runtime_sampler_checked:\n            self._runtime_sampler = create_runtime_sampler(self.backend)\n            self._runtime_sampler_checked = True\n\n        return self._runtime_sampler\n\n    def _create_shadow_implementation(self) -&gt; ClassicalShadows:\n        \"\"\"Factory for shadow implementations.\"\"\"\n        version = self.shadow_config.version\n\n        if version == ShadowVersion.V0_BASELINE:\n            return RandomLocalCliffordShadows(self.shadow_config)\n        elif version == ShadowVersion.V1_NOISE_AWARE:\n            if self.measurement_error_mitigation is None:\n                self.measurement_error_mitigation = MeasurementErrorMitigation(self.backend)\n            return NoiseAwareRandomLocalCliffordShadows(\n                self.shadow_config, self.measurement_error_mitigation\n            )\n        elif version == ShadowVersion.V2_FERMIONIC:\n            # TODO: Implement v2\n            raise NotImplementedError(\"Shadows v2 (fermionic) not yet implemented\")\n        elif version == ShadowVersion.V3_ADAPTIVE:\n            # TODO: Implement v3\n            raise NotImplementedError(\"Shadows v3 (adaptive) not yet implemented\")\n        elif version == ShadowVersion.V4_ROBUST:\n            # TODO: Implement v4\n            raise NotImplementedError(\"Shadows v4 (robust) not yet implemented\")\n        else:\n            raise ValueError(f\"Unknown shadow version: {version}\")\n\n    def estimate(\n        self,\n        circuit: QuantumCircuit,\n        observables: list[Observable],\n        target_precision: float | None = None,\n        save_manifest: bool = True,\n    ) -&gt; EstimationResult:\n        \"\"\"\n        Estimate observables using classical shadows.\n\n        Workflow:\n        1. Generate shadow measurement circuits\n        2. Transpile and execute on backend\n        3. Reconstruct shadow snapshots\n        4. Estimate all observables\n        5. Generate provenance manifest\n        \"\"\"\n        experiment_id = str(uuid.uuid4())\n        start_time = time.time()\n\n        # Determine shadow size\n        if target_precision:\n            required_sizes = [\n                self.shadow_impl.estimate_shadow_size_needed(obs, target_precision)\n                for obs in observables\n            ]\n            shadow_size = max(required_sizes) if required_sizes else self.shadow_config.shadow_size\n            if shadow_size &lt;= 0:\n                raise ValueError(\"Shadow size estimation produced a non-positive value\")\n            self.shadow_config.shadow_size = shadow_size\n            self.shadow_impl.config.shadow_size = shadow_size\n        else:\n            shadow_size = self.shadow_config.shadow_size\n            self.shadow_impl.config.shadow_size = shadow_size\n\n        # Generate shadow measurement circuits\n        shadow_circuits = self.shadow_impl.generate_measurement_circuits(circuit, shadow_size)\n\n        # Calibrate measurement error mitigation if required\n        if isinstance(self.shadow_impl, NoiseAwareRandomLocalCliffordShadows):\n            mem_params = self.mitigation_config.parameters\n            mem_shots = int(mem_params.get(\"mem_shots\", 4096))\n            mem_qubits_param = mem_params.get(\"mem_qubits\")\n            if mem_qubits_param is None:\n                mem_qubits = list(range(circuit.num_qubits))\n            elif isinstance(mem_qubits_param, (list, tuple)):\n                mem_qubits = [int(q) for q in mem_qubits_param]\n            else:\n                mem_qubits = [int(mem_qubits_param)]\n\n            mem_force = bool(mem_params.get(\"mem_force_calibration\", False))\n            run_options = mem_params.get(\"mem_run_options\", {})\n            mem_confusion_path_str = self.mitigation_config.confusion_matrix_path\n\n            if mem_confusion_path_str and not mem_force:\n                try:\n                    self.shadow_impl.mem.load_confusion_matrix(mem_confusion_path_str)\n                    metadata = self.shadow_impl.mem.get_confusion_metadata()\n                    if isinstance(metadata.get(\"shots_per_state\"), (int, float)):\n                        mem_shots = int(metadata[\"shots_per_state\"])\n                        mem_params[\"mem_shots\"] = mem_shots\n                    if isinstance(metadata.get(\"qubits\"), (list, tuple)):\n                        mem_qubits = [int(q) for q in metadata[\"qubits\"]]\n                        mem_params[\"mem_qubits\"] = mem_qubits\n                except FileNotFoundError:\n                    LOGGER.warning(\n                        \"Configured confusion matrix %s not found; recalibrating.\",\n                        mem_confusion_path_str,\n                    )\n                    mem_confusion_path_str = None\n\n            if (\n                self.shadow_impl.mem.confusion_matrix is None\n                or mem_force\n                or not mem_confusion_path_str\n            ):\n                mem_dir = self.data_dir / \"mem\"\n                mem_dir.mkdir(parents=True, exist_ok=True)\n                confusion_matrix_path = mem_dir / f\"{experiment_id}.npz\"\n                saved_confusion_path = self.shadow_impl.mem.calibrate(\n                    mem_qubits,\n                    shots=mem_shots,\n                    run_options=run_options,\n                    output_path=confusion_matrix_path,\n                )\n                mem_confusion_path = (\n                    saved_confusion_path\n                    if saved_confusion_path is not None\n                    else confusion_matrix_path\n                )\n                self.mitigation_config.confusion_matrix_path = str(mem_confusion_path.resolve())\n                mem_confusion_path_str = self.mitigation_config.confusion_matrix_path\n                self.shadow_impl.mem.confusion_matrix_path = Path(mem_confusion_path_str)\n            else:\n                self.mitigation_config.confusion_matrix_path = mem_confusion_path_str\n\n            if \"MEM\" not in self.mitigation_config.techniques:\n                self.mitigation_config.techniques.append(\"MEM\")\n            mem_params[\"mem_qubits\"] = mem_qubits\n            mem_params[\"mem_shots\"] = mem_shots\n\n        # Transpile for backend\n        transpiled_circuits = transpile(shadow_circuits, backend=self.backend)\n\n        # Respect backend batching limits\n        max_experiments = None\n        backend_config = None\n        if hasattr(self.backend, \"configuration\"):\n            try:\n                backend_config = self.backend.configuration()\n            except Exception:\n                backend_config = None\n\n        if backend_config is not None:\n            max_experiments = getattr(backend_config, \"max_experiments\", None)\n\n        if isinstance(max_experiments, np.integer):\n            max_experiments = int(max_experiments)\n\n        if not isinstance(max_experiments, int) or max_experiments &lt;= 0:\n            # Use safe default batch size for IBM backends to avoid submission failures\n            max_experiments = 500\n            print(\n                f\"Warning: Backend max_experiments unavailable or invalid. \"\n                f\"Using safe default batch size: {max_experiments}\"\n            )\n\n        measurement_outcomes_list: list[np.ndarray] = []\n\n        sampler = self._get_runtime_sampler()\n\n        for start_idx in range(0, len(transpiled_circuits), max_experiments):\n            circuit_batch = transpiled_circuits[start_idx : start_idx + max_experiments]\n            if sampler is not None:\n                job = sampler.run(list(circuit_batch), shots=1)\n                result = job.result()\n\n                for batch_idx, _ in enumerate(circuit_batch):\n                    counts = result[batch_idx].data.meas.get_counts()\n                    bitstring = list(counts.keys())[0].replace(\" \", \"\")\n                    outcomes = np.array([int(b) for b in bitstring[::-1]], dtype=int)\n                    measurement_outcomes_list.append(outcomes)\n            else:\n                job = self.backend.run(circuit_batch, shots=1)  # Each circuit is one shadow\n                result = job.result()\n\n                for batch_idx, _ in enumerate(circuit_batch):\n                    counts = result.get_counts(batch_idx)\n                    bitstring = list(counts.keys())[0].replace(\" \", \"\")\n                    outcomes = np.array([int(b) for b in bitstring[::-1]], dtype=int)\n                    measurement_outcomes_list.append(outcomes)\n\n        if len(measurement_outcomes_list) != shadow_size:\n            raise RuntimeError(\n                \"Collected measurement outcomes do not match the requested shadow size.\"\n            )\n\n        measurement_outcomes = np.asarray(measurement_outcomes_list, dtype=int)\n\n        measurement_bases = self.shadow_impl.measurement_bases\n        if measurement_bases is None:\n            raise ValueError(\"Shadow implementation did not record measurement bases.\")\n        measurement_bases = np.asarray(measurement_bases, dtype=int)\n        self.shadow_impl.measurement_bases = measurement_bases\n\n        # Save shot data to Parquet\n        shot_data_path = self.shot_data_writer.save_shadow_measurements(\n            experiment_id=experiment_id,\n            measurement_bases=measurement_bases,\n            measurement_outcomes=measurement_outcomes,\n            num_qubits=circuit.num_qubits,\n        )\n\n        # Reconstruct shadows\n        self.shadow_impl.reconstruct_classical_shadow(measurement_outcomes, measurement_bases)\n\n        # Estimate all observables\n        estimates: dict[str, dict[str, object]] = {}\n        for obs in observables:\n            estimate = self.shadow_impl.estimate_observable(obs)\n            estimates[str(obs)] = {\n                \"expectation_value\": estimate.expectation_value,\n                \"variance\": estimate.variance,\n                \"ci_95\": estimate.confidence_interval,\n                \"ci_width\": estimate.ci_width,\n            }\n\n        execution_time = time.time() - start_time\n\n        # Create provenance manifest\n        if save_manifest:\n            manifest = self._create_manifest(\n                experiment_id,\n                circuit,\n                observables,\n                estimates,\n                shadow_size,\n                execution_time,\n                shot_data_path,\n            )\n            manifest_path = self.data_dir / \"manifests\" / f\"{experiment_id}.json\"\n            manifest_path.parent.mkdir(parents=True, exist_ok=True)\n            manifest.to_json(manifest_path)\n        else:\n            manifest_path = None\n\n        return EstimationResult(\n            observables=estimates,\n            shots_used=shadow_size,\n            execution_time=execution_time,\n            backend_name=self.backend.name,\n            experiment_id=experiment_id,\n            manifest_path=str(manifest_path) if manifest_path else None,\n            shot_data_path=str(shot_data_path.resolve()),\n            mitigation_confusion_matrix_path=self.mitigation_config.confusion_matrix_path,\n        )\n\n    def estimate_shots_needed(self, observables: list[Observable], target_precision: float) -&gt; int:\n        \"\"\"Estimate shadow size needed for target precision.\"\"\"\n        # Use worst-case observable\n        max_shadow_size = 0\n        for obs in observables:\n            size = self.shadow_impl.estimate_shadow_size_needed(obs, target_precision)\n            max_shadow_size = max(max_shadow_size, size)\n\n        return max_shadow_size\n\n    def replay_from_manifest(\n        self,\n        manifest_path: str | Path,\n        observables: list[Observable] | None = None,\n    ) -&gt; EstimationResult:\n        \"\"\"\n        Replay an experiment from a saved manifest and shot data.\n\n        This allows re-estimation of observables from previously collected shot data\n        without re-executing circuits on the backend.\n\n        Args:\n            manifest_path: Path to the provenance manifest JSON file\n            observables: Optional new list of observables to estimate. If None,\n                        uses observables from the original manifest.\n\n        Returns:\n            EstimationResult with re-estimated observables\n        \"\"\"\n        manifest_path = Path(manifest_path)\n        if not manifest_path.exists():\n            raise FileNotFoundError(f\"Manifest not found: {manifest_path}\")\n\n        # Load manifest\n        manifest = ProvenanceManifest.from_json(manifest_path)\n        experiment_id = manifest.schema.experiment_id\n\n        # Load shot data\n        measurement_bases, measurement_outcomes, num_qubits = (\n            self.shot_data_writer.load_shadow_measurements(experiment_id)\n        )\n\n        if manifest.schema.shadows is None:\n            raise ValueError(\n                \"Manifest does not contain classical shadows configuration information.\"\n            )\n\n        # Reconstruct shadows with loaded data\n        # Create temporary shadow implementation if needed\n        shadow_payload = manifest.schema.shadows.model_dump()\n        shadow_payload[\"random_seed\"] = manifest.schema.random_seed\n        shadow_config = ShadowConfig.model_validate(shadow_payload)\n\n        resolved_confusion_matrix_path: str | None = (\n            manifest.schema.mitigation.confusion_matrix_path\n        )\n\n        if shadow_config.version == ShadowVersion.V0_BASELINE:\n            shadow_impl = RandomLocalCliffordShadows(shadow_config)\n        elif shadow_config.version == ShadowVersion.V1_NOISE_AWARE:\n            confusion_matrix_path_str = manifest.schema.mitigation.confusion_matrix_path\n\n            if not confusion_matrix_path_str:\n                raise FileNotFoundError(\n                    \"Noise-aware manifest does not include a persisted confusion matrix path. \"\n                    \"Re-run estimation or provide the saved calibration artifact before replaying.\"\n                )\n\n            raw_confusion_path = Path(confusion_matrix_path_str)\n            candidate_paths = [raw_confusion_path]\n\n            if not raw_confusion_path.is_absolute():\n                candidate_paths.append((manifest_path.parent / raw_confusion_path).resolve())\n                candidate_paths.append((self.data_dir / raw_confusion_path).resolve())\n\n            candidate_paths.append((self.data_dir / \"mem\" / raw_confusion_path.name).resolve())\n            candidate_paths.append(\n                (manifest_path.parent / \"mem\" / raw_confusion_path.name).resolve()\n            )\n\n            confusion_matrix_path: Path | None = None\n            for candidate in candidate_paths:\n                if candidate and candidate.exists():\n                    confusion_matrix_path = candidate\n                    break\n\n            if confusion_matrix_path is None:\n                raise FileNotFoundError(\n                    \"Unable to locate the persisted confusion matrix required for noise-aware replay. \"\n                    f\"Looked for {raw_confusion_path} and related paths.\"\n                )\n\n            with np.load(confusion_matrix_path, allow_pickle=False) as archive:\n                if \"confusion_matrix\" not in archive:\n                    raise ValueError(\n                        \"Confusion matrix archive is missing the 'confusion_matrix' dataset.\"\n                    )\n                confusion_matrix = archive[\"confusion_matrix\"]\n\n            mem = MeasurementErrorMitigation(self.backend)\n            mem.confusion_matrix = confusion_matrix\n            mem.confusion_matrix_path = confusion_matrix_path.resolve()\n            mem._calibrated_qubits = tuple(range(num_qubits))\n\n            shadow_impl = NoiseAwareRandomLocalCliffordShadows(shadow_config, mem)\n            resolved_confusion_matrix_path = str(confusion_matrix_path.resolve())\n        else:\n            raise NotImplementedError(\n                f\"Replay for shadow version {shadow_config.version.value} is not implemented\"\n            )\n        shadow_impl.measurement_bases = measurement_bases\n        shadow_impl.reconstruct_classical_shadow(measurement_outcomes, measurement_bases)\n\n        # Use observables from manifest if not provided\n        if observables is None:\n            observables = [\n                Observable(obs_dict[\"pauli\"], obs_dict.get(\"coefficient\", 1.0))\n                for obs_dict in manifest.schema.observables\n            ]\n\n        # Estimate all observables\n        estimates: dict[str, dict[str, object]] = {}\n        for obs in observables:\n            estimate = shadow_impl.estimate_observable(obs)\n            estimates[str(obs)] = {\n                \"expectation_value\": estimate.expectation_value,\n                \"variance\": estimate.variance,\n                \"ci_95\": estimate.confidence_interval,\n                \"ci_width\": estimate.ci_width,\n            }\n\n        return EstimationResult(\n            observables=estimates,\n            shots_used=manifest.schema.shadows.shadow_size,\n            execution_time=0.0,  # No execution time for replay\n            backend_name=manifest.schema.backend.backend_name,\n            experiment_id=experiment_id,\n            manifest_path=str(manifest_path),\n            shot_data_path=manifest.schema.shot_data_path,\n            mitigation_confusion_matrix_path=resolved_confusion_matrix_path,\n        )\n\n    def _create_manifest(\n        self,\n        experiment_id: str,\n        circuit: QuantumCircuit,\n        observables: list[Observable],\n        estimates: dict[str, dict[str, object]],\n        shadow_size: int,\n        execution_time: float,\n        shot_data_path: Path,\n    ) -&gt; ProvenanceManifest:\n        \"\"\"Create provenance manifest for the experiment.\"\"\"\n        import sys\n\n        import qiskit\n\n        # Circuit fingerprint\n        try:\n            qasm_str = qasm3.dumps(circuit)\n        except Exception:\n            qasm_str = circuit.qasm()\n\n        gate_counts: dict[str, int] = {}\n        for instruction in circuit.data:\n            gate_name = instruction.operation.name\n            gate_counts[gate_name] = gate_counts.get(gate_name, 0) + 1\n\n        circuit_hash = hashlib.sha256(qasm_str.encode()).hexdigest()[:16]\n\n        circuit_fp = CircuitFingerprint(\n            qasm3=qasm_str,\n            num_qubits=circuit.num_qubits,\n            depth=circuit.depth(),\n            gate_counts=gate_counts,\n            circuit_hash=circuit_hash,\n        )\n\n        # Backend snapshot\n        backend_snapshot = self._backend_snapshot or create_backend_snapshot(self.backend)\n\n        # Shadows config\n        shadows_config = ShadowsConfig.model_validate(\n            {\n                \"version\": self.shadow_config.version.value,\n                \"shadow_size\": shadow_size,\n                \"measurement_ensemble\": self.shadow_config.measurement_ensemble.value,\n                \"noise_model_path\": self.shadow_config.noise_model_path,\n                \"inverse_channel_applied\": self.shadow_config.apply_inverse_channel,\n                \"fermionic_mode\": self.shadow_config.fermionic_mode,\n                \"rdm_order\": self.shadow_config.rdm_order,\n                \"adaptive\": self.shadow_config.adaptive,\n                \"target_observables\": self.shadow_config.target_observables,\n                \"bayesian_inference\": self.shadow_config.bayesian_inference,\n                \"bootstrap_samples\": self.shadow_config.bootstrap_samples,\n            }\n        )\n\n        # Resource usage\n        resource_usage = ResourceUsage.model_validate(\n            {\n                \"total_shots\": shadow_size,\n                \"execution_time_seconds\": execution_time,\n                \"queue_time_seconds\": None,\n                \"estimated_cost_usd\": None,\n                \"credits_used\": None,\n                \"classical_compute_seconds\": None,\n            }\n        )\n\n        metadata = {}\n        if self._backend_descriptor:\n            metadata[\"backend_descriptor\"] = self._backend_descriptor\n\n        # Create manifest\n        shot_checksum = compute_file_checksum(shot_data_path)\n\n        mitigation_config = self.mitigation_config.model_copy(deep=True)\n        confusion_path = mitigation_config.confusion_matrix_path\n        if confusion_path:\n            mitigation_config.confusion_matrix_checksum = compute_file_checksum(confusion_path)\n\n        manifest_schema = ManifestSchema(\n            experiment_id=experiment_id,\n            experiment_name=None,\n            circuit=circuit_fp,\n            observables=[\n                {\"pauli\": obs.pauli_string, \"coefficient\": obs.coefficient} for obs in observables\n            ],\n            backend=backend_snapshot,\n            mitigation=mitigation_config,\n            shadows=shadows_config,\n            shot_data_path=str(shot_data_path.resolve()),\n            shot_data_checksum=shot_checksum,\n            results_summary=estimates,\n            resource_usage=resource_usage,\n            metadata=metadata,\n            random_seed=self.shadow_config.random_seed,\n            quartumse_version=__version__,\n            qiskit_version=qiskit.__version__,\n            python_version=f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\",\n        )\n\n        return ProvenanceManifest(manifest_schema)\n</code></pre>"},{"location":"reference/api/#quartumse.ShadowEstimator.__init__","title":"<code>__init__(backend, shadow_config=None, mitigation_config=None, data_dir=None)</code>","text":"<p>Initialize shadow estimator.</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>Backend | str</code> <p>Qiskit backend or backend name (e.g., \"aer_simulator\")</p> required <code>shadow_config</code> <code>ShadowConfig | None</code> <p>Classical shadows configuration</p> <code>None</code> <code>mitigation_config</code> <code>MitigationConfig | None</code> <p>Error mitigation configuration</p> <code>None</code> <code>data_dir</code> <code>str | Path | None</code> <p>Directory for storing shot data and manifests</p> <code>None</code> Source code in <code>src/quartumse/estimator/shadow_estimator.py</code> <pre><code>def __init__(\n    self,\n    backend: Backend | str,\n    shadow_config: ShadowConfig | None = None,\n    mitigation_config: MitigationConfig | None = None,\n    data_dir: str | Path | None = None,\n):\n    \"\"\"\n    Initialize shadow estimator.\n\n    Args:\n        backend: Qiskit backend or backend name (e.g., \"aer_simulator\")\n        shadow_config: Classical shadows configuration\n        mitigation_config: Error mitigation configuration\n        data_dir: Directory for storing shot data and manifests\n    \"\"\"\n    # Handle backend\n    self._backend_descriptor: str | None = None\n    self._backend_snapshot: BackendSnapshot | None = None\n\n    if isinstance(backend, str):\n        self._backend_descriptor = backend\n        if \":\" in backend:\n            resolved_backend, snapshot = resolve_backend(backend)\n            backend = resolved_backend\n            self._backend_snapshot = snapshot\n        elif backend == \"aer_simulator\":\n            backend = AerSimulator()\n            self._backend_snapshot = create_backend_snapshot(backend)\n        else:\n            raise ValueError(f\"Unknown backend string: {backend}\")\n    else:\n        self._backend_descriptor = getattr(backend, \"name\", None)\n\n    super().__init__(backend, shadow_config)\n\n    self._runtime_sampler: SamplerPrimitive | None = None\n    self._runtime_sampler_checked = False\n    self._use_runtime_sampler = is_ibm_runtime_backend(self.backend)\n\n    self.shadow_config = shadow_config or ShadowConfig.model_validate({})\n    self.mitigation_config = mitigation_config or MitigationConfig()\n    self.data_dir = Path(data_dir) if data_dir else Path(\"./data\")\n    self.data_dir.mkdir(parents=True, exist_ok=True)\n\n    self.measurement_error_mitigation: MeasurementErrorMitigation | None = None\n    self._mem_required = (\n        self.shadow_config.version == ShadowVersion.V1_NOISE_AWARE\n        or self.shadow_config.apply_inverse_channel\n        or (\"MEM\" in self.mitigation_config.techniques)\n    )\n    if self._mem_required:\n        self.measurement_error_mitigation = MeasurementErrorMitigation(self.backend)\n\n    # Initialize shadow implementation based on version\n    self.shadow_impl: ClassicalShadows = self._create_shadow_implementation()\n\n    # Initialize shot data writer\n    self.shot_data_writer = ShotDataWriter(self.data_dir)\n</code></pre>"},{"location":"reference/api/#quartumse.ShadowEstimator.estimate","title":"<code>estimate(circuit, observables, target_precision=None, save_manifest=True)</code>","text":"<p>Estimate observables using classical shadows.</p> <p>Workflow: 1. Generate shadow measurement circuits 2. Transpile and execute on backend 3. Reconstruct shadow snapshots 4. Estimate all observables 5. Generate provenance manifest</p> Source code in <code>src/quartumse/estimator/shadow_estimator.py</code> <pre><code>def estimate(\n    self,\n    circuit: QuantumCircuit,\n    observables: list[Observable],\n    target_precision: float | None = None,\n    save_manifest: bool = True,\n) -&gt; EstimationResult:\n    \"\"\"\n    Estimate observables using classical shadows.\n\n    Workflow:\n    1. Generate shadow measurement circuits\n    2. Transpile and execute on backend\n    3. Reconstruct shadow snapshots\n    4. Estimate all observables\n    5. Generate provenance manifest\n    \"\"\"\n    experiment_id = str(uuid.uuid4())\n    start_time = time.time()\n\n    # Determine shadow size\n    if target_precision:\n        required_sizes = [\n            self.shadow_impl.estimate_shadow_size_needed(obs, target_precision)\n            for obs in observables\n        ]\n        shadow_size = max(required_sizes) if required_sizes else self.shadow_config.shadow_size\n        if shadow_size &lt;= 0:\n            raise ValueError(\"Shadow size estimation produced a non-positive value\")\n        self.shadow_config.shadow_size = shadow_size\n        self.shadow_impl.config.shadow_size = shadow_size\n    else:\n        shadow_size = self.shadow_config.shadow_size\n        self.shadow_impl.config.shadow_size = shadow_size\n\n    # Generate shadow measurement circuits\n    shadow_circuits = self.shadow_impl.generate_measurement_circuits(circuit, shadow_size)\n\n    # Calibrate measurement error mitigation if required\n    if isinstance(self.shadow_impl, NoiseAwareRandomLocalCliffordShadows):\n        mem_params = self.mitigation_config.parameters\n        mem_shots = int(mem_params.get(\"mem_shots\", 4096))\n        mem_qubits_param = mem_params.get(\"mem_qubits\")\n        if mem_qubits_param is None:\n            mem_qubits = list(range(circuit.num_qubits))\n        elif isinstance(mem_qubits_param, (list, tuple)):\n            mem_qubits = [int(q) for q in mem_qubits_param]\n        else:\n            mem_qubits = [int(mem_qubits_param)]\n\n        mem_force = bool(mem_params.get(\"mem_force_calibration\", False))\n        run_options = mem_params.get(\"mem_run_options\", {})\n        mem_confusion_path_str = self.mitigation_config.confusion_matrix_path\n\n        if mem_confusion_path_str and not mem_force:\n            try:\n                self.shadow_impl.mem.load_confusion_matrix(mem_confusion_path_str)\n                metadata = self.shadow_impl.mem.get_confusion_metadata()\n                if isinstance(metadata.get(\"shots_per_state\"), (int, float)):\n                    mem_shots = int(metadata[\"shots_per_state\"])\n                    mem_params[\"mem_shots\"] = mem_shots\n                if isinstance(metadata.get(\"qubits\"), (list, tuple)):\n                    mem_qubits = [int(q) for q in metadata[\"qubits\"]]\n                    mem_params[\"mem_qubits\"] = mem_qubits\n            except FileNotFoundError:\n                LOGGER.warning(\n                    \"Configured confusion matrix %s not found; recalibrating.\",\n                    mem_confusion_path_str,\n                )\n                mem_confusion_path_str = None\n\n        if (\n            self.shadow_impl.mem.confusion_matrix is None\n            or mem_force\n            or not mem_confusion_path_str\n        ):\n            mem_dir = self.data_dir / \"mem\"\n            mem_dir.mkdir(parents=True, exist_ok=True)\n            confusion_matrix_path = mem_dir / f\"{experiment_id}.npz\"\n            saved_confusion_path = self.shadow_impl.mem.calibrate(\n                mem_qubits,\n                shots=mem_shots,\n                run_options=run_options,\n                output_path=confusion_matrix_path,\n            )\n            mem_confusion_path = (\n                saved_confusion_path\n                if saved_confusion_path is not None\n                else confusion_matrix_path\n            )\n            self.mitigation_config.confusion_matrix_path = str(mem_confusion_path.resolve())\n            mem_confusion_path_str = self.mitigation_config.confusion_matrix_path\n            self.shadow_impl.mem.confusion_matrix_path = Path(mem_confusion_path_str)\n        else:\n            self.mitigation_config.confusion_matrix_path = mem_confusion_path_str\n\n        if \"MEM\" not in self.mitigation_config.techniques:\n            self.mitigation_config.techniques.append(\"MEM\")\n        mem_params[\"mem_qubits\"] = mem_qubits\n        mem_params[\"mem_shots\"] = mem_shots\n\n    # Transpile for backend\n    transpiled_circuits = transpile(shadow_circuits, backend=self.backend)\n\n    # Respect backend batching limits\n    max_experiments = None\n    backend_config = None\n    if hasattr(self.backend, \"configuration\"):\n        try:\n            backend_config = self.backend.configuration()\n        except Exception:\n            backend_config = None\n\n    if backend_config is not None:\n        max_experiments = getattr(backend_config, \"max_experiments\", None)\n\n    if isinstance(max_experiments, np.integer):\n        max_experiments = int(max_experiments)\n\n    if not isinstance(max_experiments, int) or max_experiments &lt;= 0:\n        # Use safe default batch size for IBM backends to avoid submission failures\n        max_experiments = 500\n        print(\n            f\"Warning: Backend max_experiments unavailable or invalid. \"\n            f\"Using safe default batch size: {max_experiments}\"\n        )\n\n    measurement_outcomes_list: list[np.ndarray] = []\n\n    sampler = self._get_runtime_sampler()\n\n    for start_idx in range(0, len(transpiled_circuits), max_experiments):\n        circuit_batch = transpiled_circuits[start_idx : start_idx + max_experiments]\n        if sampler is not None:\n            job = sampler.run(list(circuit_batch), shots=1)\n            result = job.result()\n\n            for batch_idx, _ in enumerate(circuit_batch):\n                counts = result[batch_idx].data.meas.get_counts()\n                bitstring = list(counts.keys())[0].replace(\" \", \"\")\n                outcomes = np.array([int(b) for b in bitstring[::-1]], dtype=int)\n                measurement_outcomes_list.append(outcomes)\n        else:\n            job = self.backend.run(circuit_batch, shots=1)  # Each circuit is one shadow\n            result = job.result()\n\n            for batch_idx, _ in enumerate(circuit_batch):\n                counts = result.get_counts(batch_idx)\n                bitstring = list(counts.keys())[0].replace(\" \", \"\")\n                outcomes = np.array([int(b) for b in bitstring[::-1]], dtype=int)\n                measurement_outcomes_list.append(outcomes)\n\n    if len(measurement_outcomes_list) != shadow_size:\n        raise RuntimeError(\n            \"Collected measurement outcomes do not match the requested shadow size.\"\n        )\n\n    measurement_outcomes = np.asarray(measurement_outcomes_list, dtype=int)\n\n    measurement_bases = self.shadow_impl.measurement_bases\n    if measurement_bases is None:\n        raise ValueError(\"Shadow implementation did not record measurement bases.\")\n    measurement_bases = np.asarray(measurement_bases, dtype=int)\n    self.shadow_impl.measurement_bases = measurement_bases\n\n    # Save shot data to Parquet\n    shot_data_path = self.shot_data_writer.save_shadow_measurements(\n        experiment_id=experiment_id,\n        measurement_bases=measurement_bases,\n        measurement_outcomes=measurement_outcomes,\n        num_qubits=circuit.num_qubits,\n    )\n\n    # Reconstruct shadows\n    self.shadow_impl.reconstruct_classical_shadow(measurement_outcomes, measurement_bases)\n\n    # Estimate all observables\n    estimates: dict[str, dict[str, object]] = {}\n    for obs in observables:\n        estimate = self.shadow_impl.estimate_observable(obs)\n        estimates[str(obs)] = {\n            \"expectation_value\": estimate.expectation_value,\n            \"variance\": estimate.variance,\n            \"ci_95\": estimate.confidence_interval,\n            \"ci_width\": estimate.ci_width,\n        }\n\n    execution_time = time.time() - start_time\n\n    # Create provenance manifest\n    if save_manifest:\n        manifest = self._create_manifest(\n            experiment_id,\n            circuit,\n            observables,\n            estimates,\n            shadow_size,\n            execution_time,\n            shot_data_path,\n        )\n        manifest_path = self.data_dir / \"manifests\" / f\"{experiment_id}.json\"\n        manifest_path.parent.mkdir(parents=True, exist_ok=True)\n        manifest.to_json(manifest_path)\n    else:\n        manifest_path = None\n\n    return EstimationResult(\n        observables=estimates,\n        shots_used=shadow_size,\n        execution_time=execution_time,\n        backend_name=self.backend.name,\n        experiment_id=experiment_id,\n        manifest_path=str(manifest_path) if manifest_path else None,\n        shot_data_path=str(shot_data_path.resolve()),\n        mitigation_confusion_matrix_path=self.mitigation_config.confusion_matrix_path,\n    )\n</code></pre>"},{"location":"reference/api/#quartumse.ShadowEstimator.estimate_shots_needed","title":"<code>estimate_shots_needed(observables, target_precision)</code>","text":"<p>Estimate shadow size needed for target precision.</p> Source code in <code>src/quartumse/estimator/shadow_estimator.py</code> <pre><code>def estimate_shots_needed(self, observables: list[Observable], target_precision: float) -&gt; int:\n    \"\"\"Estimate shadow size needed for target precision.\"\"\"\n    # Use worst-case observable\n    max_shadow_size = 0\n    for obs in observables:\n        size = self.shadow_impl.estimate_shadow_size_needed(obs, target_precision)\n        max_shadow_size = max(max_shadow_size, size)\n\n    return max_shadow_size\n</code></pre>"},{"location":"reference/api/#quartumse.ShadowEstimator.replay_from_manifest","title":"<code>replay_from_manifest(manifest_path, observables=None)</code>","text":"<p>Replay an experiment from a saved manifest and shot data.</p> <p>This allows re-estimation of observables from previously collected shot data without re-executing circuits on the backend.</p> <p>Parameters:</p> Name Type Description Default <code>manifest_path</code> <code>str | Path</code> <p>Path to the provenance manifest JSON file</p> required <code>observables</code> <code>list[Observable] | None</code> <p>Optional new list of observables to estimate. If None,         uses observables from the original manifest.</p> <code>None</code> <p>Returns:</p> Type Description <code>EstimationResult</code> <p>EstimationResult with re-estimated observables</p> Source code in <code>src/quartumse/estimator/shadow_estimator.py</code> <pre><code>def replay_from_manifest(\n    self,\n    manifest_path: str | Path,\n    observables: list[Observable] | None = None,\n) -&gt; EstimationResult:\n    \"\"\"\n    Replay an experiment from a saved manifest and shot data.\n\n    This allows re-estimation of observables from previously collected shot data\n    without re-executing circuits on the backend.\n\n    Args:\n        manifest_path: Path to the provenance manifest JSON file\n        observables: Optional new list of observables to estimate. If None,\n                    uses observables from the original manifest.\n\n    Returns:\n        EstimationResult with re-estimated observables\n    \"\"\"\n    manifest_path = Path(manifest_path)\n    if not manifest_path.exists():\n        raise FileNotFoundError(f\"Manifest not found: {manifest_path}\")\n\n    # Load manifest\n    manifest = ProvenanceManifest.from_json(manifest_path)\n    experiment_id = manifest.schema.experiment_id\n\n    # Load shot data\n    measurement_bases, measurement_outcomes, num_qubits = (\n        self.shot_data_writer.load_shadow_measurements(experiment_id)\n    )\n\n    if manifest.schema.shadows is None:\n        raise ValueError(\n            \"Manifest does not contain classical shadows configuration information.\"\n        )\n\n    # Reconstruct shadows with loaded data\n    # Create temporary shadow implementation if needed\n    shadow_payload = manifest.schema.shadows.model_dump()\n    shadow_payload[\"random_seed\"] = manifest.schema.random_seed\n    shadow_config = ShadowConfig.model_validate(shadow_payload)\n\n    resolved_confusion_matrix_path: str | None = (\n        manifest.schema.mitigation.confusion_matrix_path\n    )\n\n    if shadow_config.version == ShadowVersion.V0_BASELINE:\n        shadow_impl = RandomLocalCliffordShadows(shadow_config)\n    elif shadow_config.version == ShadowVersion.V1_NOISE_AWARE:\n        confusion_matrix_path_str = manifest.schema.mitigation.confusion_matrix_path\n\n        if not confusion_matrix_path_str:\n            raise FileNotFoundError(\n                \"Noise-aware manifest does not include a persisted confusion matrix path. \"\n                \"Re-run estimation or provide the saved calibration artifact before replaying.\"\n            )\n\n        raw_confusion_path = Path(confusion_matrix_path_str)\n        candidate_paths = [raw_confusion_path]\n\n        if not raw_confusion_path.is_absolute():\n            candidate_paths.append((manifest_path.parent / raw_confusion_path).resolve())\n            candidate_paths.append((self.data_dir / raw_confusion_path).resolve())\n\n        candidate_paths.append((self.data_dir / \"mem\" / raw_confusion_path.name).resolve())\n        candidate_paths.append(\n            (manifest_path.parent / \"mem\" / raw_confusion_path.name).resolve()\n        )\n\n        confusion_matrix_path: Path | None = None\n        for candidate in candidate_paths:\n            if candidate and candidate.exists():\n                confusion_matrix_path = candidate\n                break\n\n        if confusion_matrix_path is None:\n            raise FileNotFoundError(\n                \"Unable to locate the persisted confusion matrix required for noise-aware replay. \"\n                f\"Looked for {raw_confusion_path} and related paths.\"\n            )\n\n        with np.load(confusion_matrix_path, allow_pickle=False) as archive:\n            if \"confusion_matrix\" not in archive:\n                raise ValueError(\n                    \"Confusion matrix archive is missing the 'confusion_matrix' dataset.\"\n                )\n            confusion_matrix = archive[\"confusion_matrix\"]\n\n        mem = MeasurementErrorMitigation(self.backend)\n        mem.confusion_matrix = confusion_matrix\n        mem.confusion_matrix_path = confusion_matrix_path.resolve()\n        mem._calibrated_qubits = tuple(range(num_qubits))\n\n        shadow_impl = NoiseAwareRandomLocalCliffordShadows(shadow_config, mem)\n        resolved_confusion_matrix_path = str(confusion_matrix_path.resolve())\n    else:\n        raise NotImplementedError(\n            f\"Replay for shadow version {shadow_config.version.value} is not implemented\"\n        )\n    shadow_impl.measurement_bases = measurement_bases\n    shadow_impl.reconstruct_classical_shadow(measurement_outcomes, measurement_bases)\n\n    # Use observables from manifest if not provided\n    if observables is None:\n        observables = [\n            Observable(obs_dict[\"pauli\"], obs_dict.get(\"coefficient\", 1.0))\n            for obs_dict in manifest.schema.observables\n        ]\n\n    # Estimate all observables\n    estimates: dict[str, dict[str, object]] = {}\n    for obs in observables:\n        estimate = shadow_impl.estimate_observable(obs)\n        estimates[str(obs)] = {\n            \"expectation_value\": estimate.expectation_value,\n            \"variance\": estimate.variance,\n            \"ci_95\": estimate.confidence_interval,\n            \"ci_width\": estimate.ci_width,\n        }\n\n    return EstimationResult(\n        observables=estimates,\n        shots_used=manifest.schema.shadows.shadow_size,\n        execution_time=0.0,  # No execution time for replay\n        backend_name=manifest.schema.backend.backend_name,\n        experiment_id=experiment_id,\n        manifest_path=str(manifest_path),\n        shot_data_path=manifest.schema.shot_data_path,\n        mitigation_confusion_matrix_path=resolved_confusion_matrix_path,\n    )\n</code></pre>"},{"location":"reference/api/#commands","title":"Commands","text":"<p>See the CLI reference for command-line usage details.</p>"},{"location":"strategy/phase1_reference_runs/","title":"Phase 1 Reference Simulation Procedure","text":"<p>This document defines the procedure used during Phase 1 to generate and maintain reusable reference datasets for QuartumSE experiments. The goal is to capture a high-fidelity simulator baseline that downstream experiments can replay without resampling, ensuring that shot budgets are preserved for hardware executions.</p>"},{"location":"strategy/phase1_reference_runs/#overview","title":"Overview","text":"<p>Reference runs are executed on the Qiskit <code>aer_simulator</code> backend using the classical-shadows estimator. Artifacts are stored under <code>data/</code>:</p> Artifact Location Provenance manifests <code>data/manifests/</code> Persisted shadow measurement parquet <code>data/shots/</code> Reference manifest index <code>data/manifests/reference_index.json</code> <p>Each manifest contains a <code>metadata.reference_dataset</code> block and is tagged with <code>reference-dataset</code> plus scenario-specific tags (e.g., <code>phase1</code>, <code>ghz</code>). The index file is used by experiment scripts to look up a reference run before generating new data.</p>"},{"location":"strategy/phase1_reference_runs/#simulator-configuration","title":"Simulator configuration","text":"<p>Phase 1 reference runs use the following simulator settings:</p> <ul> <li>Backend: <code>aer_simulator</code> (default configuration, single shot queue)</li> <li>Shadow version: Baseline <code>v0</code> for noise-free references and <code>v1</code> when   MEM calibration data is required.</li> <li>Random seed: Fixed to <code>42</code> to guarantee deterministic measurement bases.</li> <li>Measurement ensemble: Local random Clifford rotations (default for   <code>ShadowConfig</code>).</li> <li>Output precision: 64-bit floating point expectations with 95% confidence   intervals generated by the estimator.</li> </ul>"},{"location":"strategy/phase1_reference_runs/#shot-counts","title":"Shot counts","text":"Scenario Measurement shots Calibration shots Notes GHZ reference (<code>v0</code>) 4,096 0 Three-qubit GHZ prepared via CNOT ladder. GHZ reference (<code>v1</code> + MEM) 4,096 4,096 MEM shots allocated as 512 per basis state on three qubits. <p>Tip: When a configuration includes MEM calibration the calibration shots are recorded inside the manifest metadata and will be skipped when an existing reference run is replayed.</p>"},{"location":"strategy/phase1_reference_runs/#naming-and-metadata","title":"Naming and metadata","text":"<p>Reference datasets are keyed by a slug that uniquely identifies the scenario. Recommended convention:</p> <pre><code>{phase}-{circuit}-{variant}-n{num_qubits}-s{measurement_shots}\n</code></pre> <p>Example: <code>phase1-ghz-v0-n3-s4096</code>.</p> <p>When a reference run completes, the manifest metadata is populated with:</p> <pre><code>\"reference_dataset\": {\n  \"slug\": \"phase1-ghz-v0-n3-s4096\",\n  \"phase\": \"phase1\",\n  \"experiment\": \"ghz-reference\",\n  \"run_name\": \"ghz-3q-baseline\",\n  \"variant\": \"v0\",\n  \"backend_descriptor\": \"aer_simulator\",\n  \"shadow_size\": 4096,\n  \"num_qubits\": 3,\n  \"observable_count\": 5,\n  \"calibration_shots\": 0,\n  \"registered_at\": \"&lt;UTC timestamp&gt;\",\n  \"last_used_at\": \"&lt;UTC timestamp&gt;\",\n  \"tags\": [\"phase1\", \"reference\", \"ghz\"]\n}\n</code></pre> <p>The manifest <code>tags</code> field is also extended with the <code>reference-dataset</code> marker and all scenario tags, allowing simple filtering.</p>"},{"location":"strategy/phase1_reference_runs/#execution-steps","title":"Execution steps","text":"<ol> <li>Prepare configuration \u2013 Either use the default YAML configuration    embedded in the template CLI or author a custom config file describing the    runs (see below).</li> <li>Invoke the template CLI \u2013 Run    <code>python experiments/reference/run_phase1_reference.py</code> with optional    overrides such as <code>--config custom.yml</code> or <code>--backend aer_simulator</code>.</li> <li>Replay when available \u2013 The CLI (through    <code>ReferenceDatasetRegistry</code>) checks <code>reference_index.json</code> and manifest    metadata. If an entry with the requested slug exists, it is replayed via the    estimator without queuing new shots.</li> <li>Review outputs \u2013 The CLI prints the manifest and shot data paths for    each run. Additional summary files can be generated later using    <code>quartumse report</code> against the saved manifests.</li> </ol>"},{"location":"strategy/phase1_reference_runs/#configuration-schema","title":"Configuration schema","text":"<p>Custom configurations are authored as YAML or JSON with the shape:</p> <pre><code>experiment_name: ghz-reference\nphase: phase1\ndefault_tags: [phase1, reference]\nruns:\n  - name: ghz-3q-baseline\n    reference_slug: phase1-ghz-v0-n3-s4096\n    circuit: ghz\n    num_qubits: 3\n    variant: v0\n    shadow_size: 4096\n    backend: aer_simulator\n    tags: [ghz]\n    observables:\n      - pauli: ZII\n      - pauli: IZI\n      - pauli: IIZ\n      - pauli: ZZI\n      - pauli: ZZZ\n\n  - name: ghz-3q-mem\n    reference_slug: phase1-ghz-v1-n3-s4096\n    circuit: ghz\n    num_qubits: 3\n    variant: v1\n    shadow_size: 4096\n    mem_shots: 512\n    backend: aer_simulator\n    tags: [ghz, mem]\n    observables: *same_as_above\n</code></pre> <p>Each run entry is processed independently. Omitting <code>mem_shots</code> defaults to the CLI argument (512). The <code>ReferenceDatasetRegistry</code> will add bookkeeping fields such as <code>registered_at</code> and <code>last_used_at</code> automatically.</p>"},{"location":"strategy/phase1_reference_runs/#manifest-index-maintenance","title":"Manifest index maintenance","text":"<ul> <li>The registry updates <code>reference_index.json</code> on every successful run.</li> <li>Stale entries are pruned automatically if the manifest file is removed.</li> <li>When editing manifests manually, keep the <code>reference_dataset.slug</code> field in   sync with the filename or update the index by rerunning the CLI with   <code>--force</code> to regenerate the dataset.</li> </ul> <p>Following this procedure guarantees that all Phase 1 simulators share the same reference baselines and that manifests carry enough metadata for downstream automation to reason about provenance and reuse.</p>"},{"location":"strategy/phase1_task_checklist/","title":"Phase 1 Operational Task Checklist","text":"<p>This checklist aggregates the outstanding Phase 1 tasks called out across the roadmap, experiment plans, and validation guides so the execution team can run them without cross-referencing multiple documents. Use it alongside the detailed procedures in <code>experiments/shadows</code> and the runtime runbook when scheduling IBM Quantum jobs.</p>"},{"location":"strategy/phase1_task_checklist/#shared-infrastructure-preparation","title":"Shared infrastructure &amp; preparation","text":"<ul> <li>[x] Establish a reusable readout calibration workflow (circuit templates, manifest storage, reuse cadence) that precedes every hardware run.</li> <li>[x] Draft the runtime budgeting checklist (shot counts, batching, queue timing) to stay within the 10-minute IBM Quantum free-tier window.</li> <li>[x] Implement shared analysis utilities for shot-saving ratio (SSR), confidence-interval (CI) coverage, and variance tracking so experiments share the same metrics code.</li> <li>[x] Document how to generate and store high-statistics reference datasets (simulators or large-shot baselines) whenever analytical ground truth is unavailable.</li> </ul>"},{"location":"strategy/phase1_task_checklist/#readout-calibration-cadence-and-artifacts","title":"Readout calibration cadence and artifacts","text":"<ul> <li>Invoke <code>quartumse calibrate-readout --backend &lt;provider:name&gt; --qubit &lt;i&gt; ...</code> before each hardware session to refresh confusion matrices. The CLI will reuse an existing archive unless <code>--force</code> is set or <code>--max-age-hours</code> expires.</li> <li>Calibrations live under <code>validation_data/calibrations/&lt;backend&gt;/q&lt;indices&gt;/confusion_matrix.npz</code> with a sibling <code>.manifest.json</code> capturing metadata (<code>backend_descriptor</code>, <code>shots_per_state</code>, reuse flag, etc.). The manager in <code>experiments/shadows/common_utils.py</code> uses the same layout so GHZ, Bell, Clifford, Ising, and H\u2082 scripts automatically share matrices.</li> <li>Surface the cached path in manifests via <code>MitigationConfig.confusion_matrix_path</code>; the CLI output and experiment metadata record this location directly for provenance linking.</li> <li>Recommended cadence: refresh for new backend calibrations, topology changes, or when the cached artifact exceeds its <code>--max-age-hours</code> threshold (default is unlimited reuse). Force a regeneration whenever qubit mappings change or significant readout drift is observed.</li> </ul>"},{"location":"strategy/phase1_task_checklist/#shadows-workstream-s","title":"Shadows workstream (S)","text":""},{"location":"strategy/phase1_task_checklist/#extended-ghz-s-t01s-t02-bridge","title":"Extended GHZ (S-T01/S-T02 bridge)","text":"<ul> <li>[ ] Simulate connectivity-aware GHZ(4\u20135) preparation circuits for target backends.</li> <li>[ ] Integrate MEM-calibrated measurement routines and demonstrate mitigated fidelity \u2265 0.5.</li> <li>[ ] Expand observable estimation to full stabilizer + Mermin terms and compare against grouped measurement baselines.</li> <li>[ ] Run \u226510 hardware trials to study CI coverage/heavy tails; apply robust estimators if needed.</li> <li>[ ] Archive procedures, raw logs, processed metrics, and discussion notes in the experiment subfolders.</li> </ul>"},{"location":"strategy/phase1_task_checklist/#parallel-bell-pairs-sbell","title":"Parallel Bell pairs (S\u2011BELL)","text":"<ul> <li>[ ] Build 4-qubit (optionally 6/8-qubit) disjoint Bell-pair circuits and verify pairwise entanglement.</li> <li>[ ] Measure $ZZ$, $XX$, and CHSH combinations with MEM such that mitigated $S&gt;2$.</li> <li>[ ] Quantify SSR gains for simultaneous subsystem observables versus per-pair grouped runs.</li> <li>[ ] File methodologies, datasets, and analyses under the dedicated directories.</li> </ul>"},{"location":"strategy/phase1_task_checklist/#random-clifford-benchmarking-scliff","title":"Random Clifford benchmarking (S\u2011CLIFF)","text":"<ul> <li>[ ] Generate depth-limited random Clifford circuits (\u22655 qubits) and capture stabilizer references from simulation.</li> <li>[ ] Estimate \u226550 Pauli observables with shadows and grouped baselines, reporting MAE distributions and CI coverage.</li> <li>[ ] Execute direct fidelity estimation (DFE) and compare shot requirements to shadows.</li> <li>[ ] Store scripts, calibration notes, stats summaries, and interpretation artifacts.</li> </ul>"},{"location":"strategy/phase1_task_checklist/#ising-chain-sising","title":"Ising chain (S\u2011ISING)","text":"<ul> <li>[ ] Assemble first-order Trotter circuits for the 6-qubit transverse-field Ising model and validate expected observables in simulation.</li> <li>[ ] Collect hardware data comparing grouped vs. shadow measurements for equal shot budgets (track energy error/variance).</li> <li>[ ] Extract auxiliary observables (magnetization, correlators, energy variance) from the same shadows datasets.</li> <li>[ ] Document procedures, execution logs, analyses, and interpretation materials.</li> </ul>"},{"location":"strategy/phase1_task_checklist/#h2-energy-schem","title":"H\u2082 energy (S\u2011CHEM)","text":"<ul> <li>[ ] Implement the 4-qubit H\u2082 ansatz and benchmark ideal expectations for validation.</li> <li>[ ] Run shadow+MEM versus grouped-measurement comparisons, targeting 0.02\u20130.05 Ha accuracy and \u226530% uncertainty reduction.</li> <li>[ ] Monitor and correct estimator bias from locally weighted sampling if uncertainties are exceeded.</li> <li>[ ] Capture methodology narratives, raw/processed data, and publication-ready discussion notes.</li> </ul>"},{"location":"strategy/phase1_task_checklist/#cross-experiment-reporting","title":"Cross-experiment reporting","text":"<ul> <li>[ ] Aggregate the high-impact findings (Hamiltonian efficiency gains, entanglement recovery, multi-observable accuracy) into a consolidated Phase 1 report.</li> <li>[ ] Ensure each experiment\u2019s discussion notes document success criteria, SSR achievements, and limitations for manuscript prep.</li> </ul>"},{"location":"strategy/phase1_task_checklist/#validation-gating-tasks","title":"Validation gating tasks","text":"<ul> <li>[ ] Complete the extended IBM hardware validation campaign (SSR \u2265 1.1\u00d7; manifests saved under <code>validation_data/</code>).</li> <li>[ ] Run the hardware validation post-checks: manifests present, calibration snapshot archived, v0 vs v1 MAE comparison, and results summarised in the Phase 1 status log section below.</li> <li>[ ] Verify validation CI coverage \u2265 80% and document Phase 1 completion once criteria are met.</li> </ul>"},{"location":"strategy/phase1_task_checklist/#cross-workstream-starters-cobm","title":"Cross-workstream starters (C/O/B/M)","text":"<ul> <li>[ ] Execute C/O/B/M starter experiments on simulator and generate first data drops (manifests + shot data for Phase 1 closure).</li> <li>[ ] Confirm patent theme shortlist drafting continues ahead of the Phase 2 gate review.</li> </ul> <p>Note: Advanced shadow variants (v2 Fermionic, v3 Adaptive, v4 Robust) are Phase 2+ scope and intentionally excluded from this checklist to keep Phase 1 focused on v0/v1 hardware validation.</p>"},{"location":"strategy/phase1_task_checklist/#how-to-use-this-checklist","title":"How to use this checklist","text":"<ol> <li>Copy relevant tasks into your sprint tracker, linking back to their detailed procedure files (design docs in <code>experiments/shadows/**/</code> and the hardware validation design note).</li> <li>Before each IBM Quantum run, execute <code>quartumse runtime-status --json --backend &lt;backend&gt;</code> and record queue depth/runtime budget in the runbook.</li> <li>After completing an experiment, attach manifests, calibration data, and summary notebooks to the appropriate <code>results/</code> and <code>discussion/</code> folders and check the corresponding box here.</li> <li>When preparing a public release or milestone summary, update <code>CHANGELOG.md</code> with the scope of work that shipped before tagging.</li> </ol> <p>Update this document whenever a task is completed or a new Phase 1 dependency is identified. Use the log below to capture concise status updates instead of scattering notes across ad-hoc documents.</p>"},{"location":"strategy/phase1_task_checklist/#phase-1-status-log","title":"Phase 1 status log","text":"Date Update 2025-10-22 IBM ibm_torino smoke test complete. GHZ v0/v1 + MEM validated, SSR \u2265 1.2\u00d7 on simulator, CI coverage 100%."},{"location":"strategy/project_bible/","title":"QuartumSE Project Bible \u2014 Strategic Blueprint (2025\u20132028)","text":""},{"location":"strategy/project_bible/#vision-positioning","title":"Vision &amp; Positioning","text":"<p>Product One-Liner: \u201cA vendor-neutral way to run quantum jobs with fewer shots and trusted error bars, plus a provenance report you can cite.\u201d</p> <p>Vision: Establish QuartumSE as the default quantum measurement and observability layer for all quantum computing teams. QuartumSE will provide a universal platform that maximizes the useful information gained per experiment (reducing cost per result) and instill confidence via rigorous error estimates. It will offer a consistent way to run quantum jobs with minimal shots while delivering reliable error bars and detailed provenance. Think of QuartumSE as a neutral monitoring standard enabling robust cross-platform performance metrics and comparisons. By focusing on measurement quality and transparency, QuartumSE also plans to lay the groundwork for advanced capabilities like pulse-level optimizations and real-time error correction support (the upcoming AutoPulse and qLDPC modules).</p>"},{"location":"strategy/project_bible/#target-users-key-use-cases","title":"Target Users &amp; Key Use Cases","text":"<p>QuartumSE is being designed for quantum R&amp;D practitioners across industry and academia:</p> <ul> <li>Algorithm Researchers: Reduce the number of shots (and thus cost) needed to achieve target error margins, while producing 95% confidence intervals for expectation values.  </li> <li>Hardware Teams: Benchmark fairly across backends. QuartumSE aims to enable cross-platform comparisons with consistent mitigation and provenance for apples-to-apples cost-per-accuracy metrics.  </li> <li>Enterprise R&amp;D: Generate auditable, reproducible, compliance-ready reports. Provenance manifests will track every circuit, calibration, and configuration automatically.  </li> </ul>"},{"location":"strategy/project_bible/#differentiators-unique-value-proposition","title":"Differentiators &amp; Unique Value Proposition","text":"<ul> <li>Vendor-Neutral Platform: One SDK will work seamlessly with IBM Quantum, AWS Braket, and beyond. No lock-in.  </li> <li>Cost-for-Accuracy Metrics: QuartumSE will introduce RMSE@$ and Shot-Savings Ratio (SSR) to quantify cost-efficiency. It answers: how many dollars to reach a given precision? </li> <li>\u201cMeasure Once, Ask Later\u201d: Classical shadows that will allow one set of randomized measurements to estimate multiple observables offline \u2013 maximizing insight per shot.  </li> <li>Provenance &amp; Auditability: Every run will produce a JSON Provenance Manifest and a PDF/HTML report with circuits, calibrations, mitigations, and cost.  </li> <li>Local-First Design: All shot data and reports stored locally by default, with optional secure cloud sync. Suitable for sensitive or air\u2011gapped R&amp;D.  </li> <li>Future-Proof Modularity: At a later stage, QuartumSE plans to develop AutoPulse (pulse-level optimization) and qLDPC (error-correction integration) modules to ensure longevity beyond the NISQ era.  </li> </ul>"},{"location":"strategy/project_bible/#planned-technical-architecture","title":"Planned Technical Architecture","text":"<p>Core Components: - Python SDK: <code>QuartumSE.Estimator</code>, <code>QuartumSE.Shadows</code>, <code>QuartumSE.Report</code> \u2014 one-call estimation with confidence intervals and provenance generation. - Mitigation &amp; Shadows Engines: Automated orchestration of ZNE, MEM, PEC, and randomized compiling for accuracy-per-cost optimization. - Data Layer: Local DuckDB/Parquet storage + calibration snapshots; all runs logged to Provenance Manifest. - Connectors: Multi-cloud backends (IBM Qiskit Runtime, AWS Braket, extensible to IonQ/Rigetti). - Server &amp; CLI: FastAPI REST service and Typer CLI for multi-user or CI/CD integration. - Extensibility: Plug-in modules for pulse optimization (AutoPulse) and real-time error correction (qLDPC).  </p>"},{"location":"strategy/project_bible/#competitive-landscape-positioning","title":"Competitive Landscape &amp; Positioning","text":"<p>QuartumSE would bridge a gap that vendor SDKs and point solutions leave open:</p> Category Example Competitors How QuartumSE Differentiates Vendor SDKs IBM Qiskit, AWS Braket Cross-platform; unified reporting; cost-per-accuracy metrics Mitigation Libraries Mitiq, Qermit Full orchestration + provenance; end-to-end workflow Commercial Tools Q-CTRL Fire Opal, Keysight True\u2011Q Open, vendor\u2011neutral, audit\u2011ready results Workflow Platforms Zapata Orquestra, Covalent QuartumSE plugs in as a measurement optimizer; local\u2011first operation <p>No other tool combines cross\u2011provider measurement optimization, multi\u2011observable reuse, and auditable cost\u2011for\u2011accuracy tracking in one open framework.</p>"},{"location":"strategy/project_bible/#long-term-roadmap-highlights","title":"Long-Term Roadmap Highlights","text":"<p>(See detailed milestones in <code>roadmap.md</code>)</p> Year Focus Key Goals 2025\u201326 MVP &amp; Design Partners IBM integration, SSR \u22651.3\u00d7, provenance reports, AWS Braket connector 2026\u201327 Public Beta &amp; Expansion AutoPulse &amp; qLDPC prototypes, SSR \u22652\u00d7, pilot customers 2027\u201328 Scale &amp; Standardization 50+ orgs using QuartumSE; Provenance Manifest adopted as industry standard"},{"location":"strategy/project_bible/#vision-beyond-nisq","title":"Vision Beyond NISQ","text":"<p>QuartumSE is designed to evolve with the field: from today\u2019s noisy processors to tomorrow\u2019s error\u2011corrected systems. It will remain relevant by: - Integrating low\u2011level pulse optimization and logical\u2011qubit error\u2011correction data; - Tracking cross\u2011hardware cost/performance benchmarks; - Defining open standards for quantum experiment reporting; - Offering an enterprise\u2011ready observability layer for quantum runtime workflows.  </p>"},{"location":"strategy/project_bible/#conclusion","title":"Conclusion","text":"<p>QuartumSE is building the foundation for trust and efficiency in quantum computing. By measuring smarter, reporting transparently, and staying vendor\u2011neutral, QuartumSE is positioning itself to become the default measurement and observability standard of the quantum era \u2014 the open, reliable infrastructure every quantum team will depend on.</p>"},{"location":"strategy/roadmap/","title":"QuartumSE R&amp;D\u2011Centric Roadmap (Updated, 2025\u20132026)","text":"<p>Last updated: 2025-10-24</p>"},{"location":"strategy/roadmap/#phase-snapshot-oct-2025","title":"Phase snapshot (Oct 2025)","text":"<ul> <li>\u2705 Phase 1 scaffolding, provenance pipeline, and CI harness are live.</li> <li>\u2705 S\u2011T01 GHZ baseline + S\u2011T02 noise-aware runs validated on IBM <code>ibm_torino</code> (smoke test Oct 22, 2025).</li> <li>\u2705 IBM Runtime CLI (<code>quartumse runtime-status</code>) operational with webhook notifications.</li> <li>\u26a0\ufe0f Extended IBM hardware validation (target SSR \u2265 1.1 across repeated runs) scheduled for Nov 2025.</li> <li>\u26a0\ufe0f Cross-workstream starter experiments (C/O/B/M) need first data drops before Phase 1 closes.</li> <li>\ud83d\udcdd Patent theme shortlist drafting in progress ahead of the Phase 2 gate review.</li> <li>\ud83d\udccb See <code>phase1_task_checklist.md</code> for the consolidated execution checklist that enumerates every   outstanding task before the Phase 1 gate review.</li> </ul> <p>Principle: Front\u2011load research &amp; hardware iteration. Build on IBM Quantum free\u2011tier devices until we have an attractive, validated, and patentable measurement stack. Only then open Early Access for design partners.</p> <p>This roadmap folds in: (i) a sophisticated classical shadows program, (ii) concrete experiments &amp; tests mapped to each phase, and (iii) clear publication/patent gates before external onboarding.</p>"},{"location":"strategy/roadmap/#glossary-metrics-terms","title":"Glossary (metrics &amp; terms)","text":"<ul> <li>SSR (Shot\u2011Savings Ratio): shot\u2011count (baseline) \u00f7 shot\u2011count (QuartumSE) at equal error tolerance.</li> <li>RMSE@$: cost\u2011for\u2011accuracy \u2014 dollars (or credits/time) to reach a target RMSE on an observable/metric.</li> <li>CI coverage: frequency a 95% CI contains ground truth (simulation) or gold standard (hardware cross\u2011checks).</li> <li>Provenance Manifest: JSON artifact capturing circuits, calibrations, mitigations, backend, seeds, versions.</li> <li>MEM / M3: measurement error mitigation (confusion matrices); ZNE: zero\u2011noise extrapolation.</li> <li>PEC: probabilistic error cancellation; RC: randomized compiling.</li> </ul>"},{"location":"strategy/roadmap/#program-structure-at-a-glance","title":"Program Structure at a Glance","text":"<ul> <li>Workstream S (Shadows): Classical Shadows Engine v0\u2192v4 (baseline \u2192 noise\u2011aware \u2192 fermionic \u2192 adaptive/derandomized \u2192 robust Bayesian/bootstrapped).</li> <li>Workstream C (Chemistry/VQE): Shadow\u2011VQE for small molecules (H\u2082, LiH, BeH\u2082).</li> <li>Workstream O (Optimization/QAOA): Shot\u2011frugal QAOA on MAX\u2011CUT &amp; MIS toy instances.</li> <li>Workstream B (Benchmarking): RB/XEB/Quantum\u2011Volume + Shadow\u2011Benchmarking (fidelity/entropy/purity via shadows).</li> <li>Workstream M (Metrology): Variational entangled probes (GHZ/W states) for phase\u2011sensing toy tasks.</li> <li>Workstream P (Provenance &amp; Reporting): Manifest schema, CI pipelines, PDF/HTML reports, reproducibility notebooks.</li> </ul> <p>Each phase below enumerates Experiments &amp; Tests with IDs that recur across phases for iteration &amp; scaling.</p>"},{"location":"strategy/roadmap/#operational-cadence-checkpoints","title":"Operational cadence checkpoints","text":"<ul> <li>Monthly (first business day): Run <code>quartumse runtime-status --json --backend ibm:ibmq_brisbane --instance ibm-q/open/main</code> and log runtime minutes, queue caps, and fallback readiness in <code>OPS_RUNTIME_RUNBOOK.md</code>. Schedule a recurring calendar reminder for the ops lead.</li> <li>Weekly (Mondays): Trigger the runtime status CLI with Slack webhook enabled to post queue depth/quota snapshots into the project notifications channel. Use the summary to reprioritise hardware jobs if the queue is saturated.</li> </ul>"},{"location":"strategy/roadmap/#phase-1-foundation-rd-sprints-now-nov-2025","title":"Phase 1 \u2014 Foundation &amp; R&amp;D Sprints (Now \u2192 Nov 2025)","text":"<p>Focus: Ship scaffolding and start real algorithmic experiments immediately (sim + small IBM jobs).</p>"},{"location":"strategy/roadmap/#objectives","title":"Objectives","text":"<ul> <li>Solidify repository, CI/CD, SDK skeleton, provenance/reporting.</li> <li>Implement Shadows v0 (random local Clifford) + v1 (noise\u2011aware inverse\u2011channel + MEM).</li> <li>Stand up baseline C, O, B, M toy pipelines against Aer simulator and at least one IBM free\u2011tier backend.</li> <li>Deliver a tractable test suite and benchmarking harness (pytest + notebooks).</li> </ul>"},{"location":"strategy/roadmap/#deliverables","title":"Deliverables","text":"<ul> <li>SDK modules: <code>Estimator</code>, <code>Shadows</code>, <code>Report</code>; Provenance Manifest v1; quickstart notebook.</li> <li>Mitigation core: MEM (M3) (production) and ZNE scaffolding; PEC/RC hooks planned post-Phase 1.</li> <li>Shadows v0\u2013v1 reference implementation with CI. </li> <li>Test harness: datasets, seeds, fixtures; storage: Parquet/DuckDB; PDF/HTML report.</li> <li>Internal whiteboard spec for patent themes (see Phase 2 gate).</li> </ul>"},{"location":"strategy/roadmap/#experiments-tests-p1","title":"Experiments &amp; Tests (P1)","text":"<ul> <li>S\u2011T01 (Shadows\u2011Core): Random local Clifford shadows on GHZ(3\u20135), Bell pairs; estimate \u27e8Z\u1d62\u27e9, \u27e8Z\u1d62Z\u2c7c\u27e9, purity. Targets: CI coverage \u2265 0.9; SSR \u2265 1.2 on sim, \u2265 1.1 on IBM.</li> <li>S\u2011T02 (Noise\u2011Aware): Calibrate per\u2011qubit inverse channel; compare with/without MEM; compute variance reduction.</li> <li>C\u2011T01 (H\u2082@STO\u20113G): Hardware\u2011efficient VQE (depth \u2264 2) + Shadows readout of Hamiltonian terms; energy error \u2264 50 mHa (sim), \u2264 80 mHa (IBM).</li> <li>O\u2011T01 (MAX\u2011CUT\u20115): QAOA p\u2208{1,2} on 5\u2011node ring; shot\u2011frugal optimizer; compare cost estimate variance with/without Shadows proxy.</li> <li>B\u2011T01 (RB/XEB): 1\u20133 qubit RB; XEB on depth\u2011limited random circuits; log into Manifest; compare to IBM backend calibration metadata.</li> <li>M\u2011T01 (GHZ\u2011Phase): Prepare GHZ(3\u20134), encode small Z\u2011phase, estimate via optimal readout; CI coverage \u2265 0.8 on sim; explore ZNE for readout bias.</li> </ul>"},{"location":"strategy/roadmap/#exit-success-criteria","title":"Exit / Success Criteria","text":"<ul> <li>End\u2011to\u2011end run from notebook \u2192 manifest \u2192 report on Aer + at least one IBM free\u2011tier backend.</li> <li>SSR \u2265 1.2\u00d7 on Shadows\u2011Core (sim) and \u2265 1.1\u00d7 (IBM).</li> <li>CI coverage \u2265 80%, zero critical issues, reproducible seeds &amp; manifests.</li> <li>Patent themes shortlist (top\u20113) + experiment data to support novelty.</li> </ul>"},{"location":"strategy/roadmap/#phase-2-hardwarefirst-iteration-patent-drafts-nov-dec-2025","title":"Phase 2 \u2014 Hardware\u2011First Iteration &amp; Patent Drafts (Nov \u2192 Dec 2025)","text":"<p>Focus: Iterate on hardware. Elevate shadows &amp; domain demos; lock initial patent filings; prep first papers.</p>"},{"location":"strategy/roadmap/#objectives_1","title":"Objectives","text":"<ul> <li>Implement Shadows v2 (Fermionic) for 2\u2011RDM estimation; integrate with VQE readout.</li> <li>Prototype Shadows v3 (Adaptive/Derandomized): choose measurement ensembles to minimize estimator variance given target observable set.</li> <li>Harden error mitigation combinations (MEM + RC + ZNE) with ablation studies.</li> <li>Run structured hardware campaigns (blocked time windows) to control drift.</li> </ul>"},{"location":"strategy/roadmap/#deliverables_1","title":"Deliverables","text":"<ul> <li>IBM hardware campaign #1 dataset + full manifests + PDF/HTML reports.</li> <li>Provisional patent draft(s) for: Variance\u2011Aware Adaptive Classical Shadows (VACS); Shadow\u2011VQE readout integration; Shadow\u2011Benchmarking workflow.</li> <li>Two arXiv preprints: (i) Shadows engine on IBM, (ii) Shadow\u2011VQE for H\u2082/LiH small\u2011basis.</li> <li>Updated SDK APIs (stabilize experimental flags), plus \u201creplay from manifest\u201d tooling.</li> </ul>"},{"location":"strategy/roadmap/#experiments-tests-p2","title":"Experiments &amp; Tests (P2)","text":"<ul> <li>S\u2011T03 (Fermionic\u2011Shadows): Direct 2\u2011RDM from shadows; H\u2082/LiH energies within 40\u201360 mHa on IBM at \u2264 baseline shots; SSR \u2265 1.3\u00d7 (IBM).</li> <li>S\u2011T04 (Adaptive/Derand): Greedy/importance\u2011sampled basis selection vs plain random; measure variance \u2193 \u2265 25% for fixed shots (IBM).</li> <li>C\u2011T02 (LiH@Minimal): VQE with Shadow\u2011readout vs grouped\u2011Pauli readout; RMSE@$ \u2193 by \u2265 30% at matched error bars.</li> <li>O\u2011T02 (MAX\u2011CUT\u20116/7): Depth\u2011aware layout + RC; shot\u2011allocation per\u2011iteration; track optimizer steps saved vs fixed\u2011shot budget.</li> <li>B\u2011T02 (Shadow\u2011Benchmarking): Estimate linear entropy, multi\u2011qubit purities, and fidelity to GHZ using the same shadows dataset; compare to direct methods; sample\u2011efficiency \u2265 2\u00d7.</li> <li>M\u2011T02 (Variational\u2011Metrology): Variational state+measurement co\u2011optimization for phase sensing; demonstrate &gt; classical shot\u2011noise scaling on sim, and robust advantage trend on IBM within CI.</li> </ul>"},{"location":"strategy/roadmap/#exit-success-criteria-gate-to-p3","title":"Exit / Success Criteria (Gate to P3)","text":"<ul> <li>SSR \u2265 1.3\u00d7 on IBM for at least one domain test (Shadows\u2011Core or Fermionic\u2011Shadows).</li> <li>Draft provisional patent(s) filed; arXiv preprints ready.</li> <li>CI artifacts: reproducible notebooks, manifests, reports for all P2 tests.</li> </ul>"},{"location":"strategy/roadmap/#phase-3-internal-validation-publicationpatent-gate-jan-mar-2026","title":"Phase 3 \u2014 Internal Validation &amp; Publication/Patent Gate (Jan \u2192 Mar 2026)","text":"<p>Focus: Consolidate results; conduct controlled comparisons; submit publications; finalize patents. No external users yet.</p>"},{"location":"strategy/roadmap/#objectives_2","title":"Objectives","text":"<ul> <li>Build automated benchmark suite: GHZ, VQE(H\u2082, LiH, BeH\u2082), QAOA(MAX\u2011CUT\u2011k), Shadow\u2011Benchmarking panels.</li> <li>Statistical validation: SSR, RMSE@$, CI coverage, reproducibility (&lt; 2% drift under re\u2011runs).</li> <li>Implement Shadows v4 (Robust/Bayesian): bootstrap CI, variance debiasing, heteroscedastic weighting by device cal data.</li> <li>Prepare journal submissions (PRX Quantum/npjQI/Quantum) and non\u2011provisional patent filings.</li> </ul>"},{"location":"strategy/roadmap/#deliverables_2","title":"Deliverables","text":"<ul> <li>Benchmark suite (pytest + CLI) with per\u2011test Manifest templates and reporting.</li> <li>Internal whitepaper and slide deck with full ablation matrices.</li> <li>Code\u2011frozen R&amp;D branch tagged for archival reproducibility (DOI/Zenodo).</li> </ul>"},{"location":"strategy/roadmap/#experiments-tests-p3","title":"Experiments &amp; Tests (P3)","text":"<ul> <li>S\u2011T05 (Robust\u2011Shadows): Bootstrap CI coverage \u2265 0.9 on sim and \u2265 0.85 on IBM across GHZ and small\u2011chemistry states.</li> <li>C\u2011T03 (BeH\u2082@Minimal): Shadow\u2011VQE energy within 80\u2013100 mHa on IBM; RMSE@$ \u2193 \u2265 35% vs grouped\u2011Pauli baseline.</li> <li>O\u2011T03 (MAX\u2011CUT\u20117) and O\u2011T04 (MIS\u20116): Evaluate solution quality vs shots; show optimizer steps \u2193 \u2265 20% using shot\u2011frugal and variance\u2011aware estimates.</li> <li>B\u2011T03 (Cross\u2011Provider Sim): Aer vs IBM reproducibility; manifest \u201creplay\u201d round\u2011trip equality.</li> <li>M\u2011T03 (Sensor\u2011Tuning): Variational probe robustness to readout noise; CI width \u2193 15\u201325% after robust shadows weighting.</li> </ul>"},{"location":"strategy/roadmap/#exit-success-criteria-gate-to-early-access","title":"Exit / Success Criteria (Gate to Early Access)","text":"<ul> <li>SSR \u2265 1.5\u00d7 achieved on internal benchmarks; RMSE@$ consistently better than baselines.</li> <li>At least one paper accepted (or under strong revise\u2011&amp;\u2011resubmit) and patents filed.</li> <li>Provenance &amp; replay validated; CI green across full suite.</li> <li>Repository made public: Audit Git history for secrets, make repo public to enable external contributions.</li> <li>CI matrix expanded: Restore full cross-platform testing (12 jobs: 3 OSes \u00d7 4 Python versions). See <code>docs/ops/ci_expansion_guide.md</code>.</li> </ul> <p>Only once the above gates are cleared do we begin external onboarding.</p>"},{"location":"strategy/roadmap/#phase-4-early-access-design-partners-multiprovider-expansion-apr-jun-2026","title":"Phase 4 \u2014 Early Access (Design Partners) &amp; Multi\u2011Provider Expansion (Apr \u2192 Jun 2026)","text":"<p>Focus: Limited Early Access after patents/papers. Add AWS Braket connector. Gather external evidence on real workloads.</p>"},{"location":"strategy/roadmap/#objectives_3","title":"Objectives","text":"<ul> <li>Onboard 2\u20133 design partners (academia/industry) with NDAs referencing filed IP.</li> <li>Implement AWS Braket connector; cross\u2011provider parity and consistency tests.</li> <li>Partner\u2011coauthored case studies; feedback loop into APIs &amp; docs.</li> </ul>"},{"location":"strategy/roadmap/#deliverables_3","title":"Deliverables","text":"<ul> <li>Partner playbooks; onboarding notebooks; Slack/Discord channels.</li> <li>Cross\u2011provider tests: same circuits on IBM vs AWS; delta analysis reported.</li> <li>Case study draft(s) + testimonial(s).</li> </ul>"},{"location":"strategy/roadmap/#experiments-tests-p4","title":"Experiments &amp; Tests (P4)","text":"<ul> <li>B\u2011T04 (Cross\u2011Provider Parity): Within 10% agreement on observables post\u2011mitigation across IBM/AWS for GHZ and VQE(H\u2082) tasks.</li> <li>C\u2011T04 (Partner\u2011Chemistry): Run partner\u2011provided small chemistry model; maintain SSR \u2265 1.5\u00d7.</li> <li>O\u2011T05 (Partner\u2011Optimization): QAOA on a partner toy instance; capture wall\u2011clock + cost deltas in RMSE@$.</li> <li>S\u2011T06 (Partner\u2011Shadows): Validate adaptive shadows on partner circuits; document any domain\u2011specific gains.</li> </ul>"},{"location":"strategy/roadmap/#exit-success-criteria_1","title":"Exit / Success Criteria","text":"<ul> <li>\u22653 partners actively running; parity across providers; partner satisfaction survey \u2265 8/10.</li> <li>External replication of SSR \u2265 1.5\u00d7; stable APIs for public beta drafting.</li> </ul>"},{"location":"strategy/roadmap/#phase-5-public-beta-pilot-conversion-jul-sep-2026","title":"Phase 5 \u2014 Public Beta &amp; Pilot Conversion (Jul \u2192 Sep 2026)","text":"<p>Focus: Stabilize and open up. Convert Early Access into pilots. Prepare commercial posture.</p>"},{"location":"strategy/roadmap/#objectives_4","title":"Objectives","text":"<ul> <li>Public Beta (v1.0) on PyPI + GitHub; full docs; examples; tutorials.</li> <li>Secure 2\u20133 pilot customers/LOIs; webinar/demo using published results.</li> <li>Verify SSR \u2265 2.0\u00d7 in multi\u2011provider benchmarks; publish follow\u2011ups.</li> </ul>"},{"location":"strategy/roadmap/#deliverables_4","title":"Deliverables","text":"<ul> <li>v1.0 release; docs portal; community channels; issue triage.</li> <li>Pilot SOW templates; pricing experiments around RMSE@$ value metric.</li> <li>Public benchmark report with manifests for community reproduction.</li> </ul>"},{"location":"strategy/roadmap/#experiments-tests-p5","title":"Experiments &amp; Tests (P5)","text":"<ul> <li>B\u2011T05 (Public Benchmarks): Community\u2011reproducible GHZ/VQE/QAOA panels with manifests and reference CI.</li> <li>C\u2011T05 (Chemistry\u2011Scale\u2011Up): Largest feasible molecule instance on accessible hardware; publish shot &amp; cost curves.</li> <li>S\u2011T07 (Shadows\u2011Ablation Public): Public ablation notebook isolating contributions from v0\u2192v4 components.</li> </ul>"},{"location":"strategy/roadmap/#kpis","title":"KPIs","text":"<ul> <li>\u22655 orgs using (3 design partners + \u22652 pilots); \u22652 paying/committed customers.</li> <li>Verified SSR \u2265 2.0\u00d7 on multi\u2011provider suite; community replications reported.</li> </ul>"},{"location":"strategy/roadmap/#algorithm-test-matrix-ids-referenced-above","title":"Algorithm &amp; Test Matrix (IDs referenced above)","text":"ID Category Technique Circuits / Instances Backends Primary Metrics Evidence Artifacts S\u2011T01 Shadows v0 (random local Clifford) Bell, GHZ(3\u20135) Aer, IBM free\u2011tier SSR, CI coverage Manifest, notebook, PDF S\u2011T02 Shadows v1 (noise\u2011aware + MEM) As above Aer, IBM Var. reduction, bias Manifest, ablation table S\u2011T03 Shadows v2 (fermionic) H\u2082/LiH 2\u2011RDM Aer, IBM Energy error, SSR Manifest, data parquet S\u2011T04 Shadows v3 (adaptive/derand) Target Pauli sets Aer, IBM Variance \u2193 Manifest, policy snapshot S\u2011T05 Shadows v4 (robust/Bayesian) GHZ + chemistry Aer, IBM CI coverage, width Manifest, bootstrap logs C\u2011T01 Chemistry VQE + Shadow readout H\u2082@STO\u20113G Aer, IBM Energy error, RMSE@$ Manifest, report C\u2011T02 Chemistry Shadow\u2011VQE vs grouped LiH@minimal Aer, IBM RMSE@$ \u2193 Notebook, plot C\u2011T03 Chemistry Scale\u2011up BeH\u2082@minimal Aer, IBM Energy error, SSR Manifest, report C\u2011T04 Chemistry Partner task Partner circuit IBM/AWS SSR \u22651.5\u00d7 Case study C\u2011T05 Chemistry Public benchmark Largest feasible IBM/AWS Shot &amp; cost curves Public repo O\u2011T01 Optimization QAOA p\u22642 MAX\u2011CUT\u20115 Aer, IBM Cost var., steps Manifest, runtime logs O\u2011T02 Optimization Shot\u2011frugal + RC MAX\u2011CUT\u20116/7 IBM Steps \u2193, RMSE@$ Report O\u2011T03 Optimization MIS\u20116 MIS\u20116 IBM Quality vs shots Manifest O\u2011T04 Optimization MAX\u2011CUT\u20117 MAX\u2011CUT\u20117 IBM Steps \u2193 Logs O\u2011T05 Optimization Partner task Partner graph IBM/AWS RMSE@$ Case study B\u2011T01 Benchmark RB/XEB 1\u20133q RB; XEB IBM Gate error trends Manifest, plots B\u2011T02 Benchmark Shadow\u2011Benchmarking Purity, entropy, GHZ\u2011Fid IBM Sample\u2011efficiency Report B\u2011T03 Benchmark Reproducibility Aer vs IBM Aer/IBM Replay fidelity Replay manifests B\u2011T04 Benchmark Cross\u2011provider IBM vs AWS IBM/AWS Parity Report B\u2011T05 Benchmark Public suite Community panels All Replications Public repo M\u2011T01 Metrology GHZ phase toy GHZ(3\u20134) Aer/IBM CI cov. Manifest M\u2011T02 Metrology Variational GHZ/W Aer/IBM Advantage trend Logs M\u2011T03 Metrology Robust probes GHZ k\u2011qubit Aer/IBM CI width \u2193 Report"},{"location":"strategy/roadmap/#governance-gating-quality","title":"Governance, Gating &amp; Quality","text":"<ul> <li>Gates: P2\u2192P3 requires IBM SSR \u2265 1.3\u00d7; P3\u2192P4 requires SSR \u2265 1.5\u00d7 + patent(s) filed + \u22651 paper accepted/near\u2011accept; P4\u2192P5 requires cross\u2011provider parity and partner replication of SSR.</li> <li>Reproducibility: Every result ships with a Manifest, raw parquet shot data, and a replay notebook.</li> <li>Risk controls: Time\u2011boxed hardware campaigns; ablations to isolate mitigation effects; fail\u2011closed CI (no release if tests or coverage gates fail).</li> </ul>"},{"location":"strategy/roadmap/#timeline-target","title":"Timeline (target)","text":"Phase Focus Key Milestone Target Date P1 Foundation &amp; R&amp;D sprints First IBM runs + Shadows v1 Nov 2025 P2 Hardware\u2011first iteration IBM campaign #1 + provisional patents + preprints Dec 2025 P3 Internal validation SSR \u22651.5\u00d7 + journal submits + non\u2011provisionals Mar 2026 P4 Early Access &amp; expansion 2\u20133 partners + AWS parity Jun 2026 P5 Public Beta v1.0 + pilots Sep 2026"},{"location":"strategy/roadmap/#notes-for-engineering","title":"Notes for Engineering","text":"<ul> <li>Keep device\u2011agnostic connectors; IBM first, AWS next.</li> <li>Prefer layout\u2011aware, shallow circuits; re\u2011seed experiments; record cal snapshots.</li> <li>Implement manifest replay (offline) as a first\u2011class command; integrate with CI.</li> <li>Publish small, frequent preprints; convert to journals as results mature.</li> </ul>"},{"location":"strategy/runtime_budgeting_checklist/","title":"Runtime Budgeting Checklist Template","text":"<p>Use this checklist before launching any IBM Quantum workload. Populate it with <code>quartumse runtime-status --json</code> output (which now includes a <code>budgeting</code> section) and the planned experiment slate.</p>"},{"location":"strategy/runtime_budgeting_checklist/#suggested-workflow","title":"Suggested Workflow","text":"<ol> <li>Capture runtime status:    <pre><code>quartumse runtime-status \\\n  --backend ibm:ibmq_jakarta \\\n  --json \\\n  --shots-per-second 8.3 \\\n  --batch-seconds 600 \\\n  --calibration-shots 1024 \\\n  &gt; runtime_status.json\n</code></pre></li> <li>Feed the JSON into <code>experiments.shadows.common_utils.load_budgeting_summary</code>    (see helper below) to obtain standardized allocation notes.</li> <li>Transcribe the summary into the YAML template and record any manual    adjustments or fallback decisions.</li> </ol>"},{"location":"strategy/runtime_budgeting_checklist/#yaml-checklist-template","title":"YAML Checklist Template","text":"<pre><code>runtime_budget_review:\n  collected_at: &lt;ISO8601 timestamp from payload.collected_at&gt;\n  backend: &lt;payload.queue.backend_name&gt;\n  queue:\n    pending_jobs: &lt;payload.queue.pending_jobs&gt;\n    operational: &lt;payload.queue.operational&gt;\n    status_msg: &lt;payload.queue.status_msg&gt;\n  runtime_quota:\n    plan: &lt;payload.quota.plan&gt;\n    limit_seconds: &lt;payload.quota.limit_seconds&gt;\n    remaining_seconds: &lt;payload.quota.remaining_seconds&gt;\n    refresh_date: &lt;payload.quota.refresh_date&gt;\n  budgeting:\n    assumptions: &lt;payload.budgeting.assumptions&gt;\n    timing: &lt;payload.budgeting.timing&gt;\n    shot_capacity: &lt;payload.budgeting.shot_capacity&gt;\n    fallbacks: &lt;payload.budgeting.fallbacks&gt;\n\nshot_allocation:\n  total_measurement_shots: &lt;summary.total_measurement_shots&gt;\n  total_calibration_shots: &lt;summary.total_calibration_shots&gt;\n  per_experiment:\n    - name: &lt;experiment label&gt;\n      allocated_shots: &lt;derived via allocate_shots&gt;\n      notes: &lt;batch ordering / grouping&gt;\n\nbatching_strategy:\n  target_window_seconds: &lt;payload.budgeting.assumptions.batch_seconds&gt;\n  estimated_batches: &lt;payload.budgeting.timing.estimated_batches&gt;\n  queue_checkpoint: &lt;time to re-query runtime-status&gt;\n  batching_notes:\n    - [ ] Submitted circuits grouped to respect measurement shots envelope\n    - [ ] Calibration reuse verified (if measurement shots ~= payload.budgeting.shot_capacity.estimated_batch_shots)\n\nfallback_plan:\n  - trigger: &lt;condition from payload.budgeting.fallbacks&gt;\n    action: &lt;planned mitigation&gt;\n    owner: &lt;on-call engineer&gt;\n  - trigger: \"Runtime quota under 10%\"\n    action: \"Trim measurement shots and re-run allocate_shots for high-priority experiments only\"\n</code></pre>"},{"location":"strategy/runtime_budgeting_checklist/#markdown-checklist-variant","title":"Markdown Checklist Variant","text":"<p>For teams preferring Markdown checklists, adapt the YAML above into the following structure:</p> <pre><code>- [ ] Runtime status captured (`runtime_status.json` attached)\n- [ ] Queue depth reviewed (pending: &lt;payload.queue.pending_jobs&gt;)\n- [ ] Remaining seconds mapped to measurement shots (&lt;payload.budgeting.shot_capacity.measurement_shots_available&gt;)\n- [ ] Shots allocated via `allocate_shots(total_shots, n_experiments)`\n- [ ] Batching window (&lt;payload.budgeting.assumptions.batch_seconds&gt; s) confirmed\n- [ ] Fallback scenarios acknowledged:\n  - &lt;condition&gt;: &lt;action&gt;\n</code></pre> <p>Keep the JSON artifact with the filled checklist so downstream analyses can reference the same budgeting envelope.</p>"},{"location":"tutorials/hardware_quickstart/","title":"Hardware Quickstart (IBM Runtime)","text":"<p>Prereqs: <code>pip install quartumse[mitigation] qiskit-ibm-runtime</code>, IBM Quantum account, <code>export QISKIT_IBM_TOKEN=...</code>.</p>"},{"location":"tutorials/hardware_quickstart/#1-verify-credentials-and-quota","title":"1) Verify credentials and quota","text":"<pre><code>quartumse runtime-status --backend ibm:ibmq_qasm_simulator\n</code></pre>"},{"location":"tutorials/hardware_quickstart/#2-run-s-t01-on-ibm-simulator","title":"2) Run S-T01 on IBM simulator","text":"<pre><code>python experiments/shadows/S_T01_ghz_baseline.py --backend ibm:ibmq_qasm_simulator\n</code></pre>"},{"location":"tutorials/hardware_quickstart/#3-enable-mem-v1-and-compare","title":"3) Enable MEM (v1) and compare","text":"<pre><code>python experiments/shadows/S_T01_ghz_baseline.py --backend ibm:ibmq_qasm_simulator --variant st02\n</code></pre>"},{"location":"tutorials/hardware_quickstart/#4-outputs","title":"4) Outputs","text":"<p>Manifests under <code>data/manifests/</code>, shots under <code>data/shots/</code>. See the Manifest Schema.</p>"},{"location":"tutorials/quickstart/","title":"Quickstart","text":"<p>This guide walks through setting up a local development environment, running core verification checks, and executing your first experiment.  It merges the previous <code>INSTALL_GUIDE.md</code> and <code>SETUP.md</code> content into a single reference.</p>"},{"location":"tutorials/quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10+ (3.11 recommended)</li> <li>Git for cloning the repository</li> <li>Virtual environment tooling such as <code>venv</code>, <code>conda</code>, or <code>pipenv</code></li> <li>(Optional) Jupyter for running the demo notebooks</li> </ul>"},{"location":"tutorials/quickstart/#1-clone-the-repository-create-an-environment","title":"1. Clone the repository &amp; create an environment","text":"<p>Unix/macOS: <pre><code># Clone repository\ngit clone https://github.com/quartumse/quartumse.git\ncd quartumse\n\n# Create virtual environment (replace with your preferred workflow)\npython -m venv .venv\n\n# Activate the environment\nsource .venv/bin/activate\n</code></pre></p> <p>Windows (PowerShell): <pre><code># Clone repository\ngit clone https://github.com/quartumse/quartumse.git\ncd quartumse\n\n# Create virtual environment\npython -m venv .venv\n\n# Activate the environment\n.venv\\Scripts\\activate\n</code></pre></p> <p>Windows (Command Prompt): <pre><code>rem Clone repository\ngit clone https://github.com/quartumse/quartumse.git\ncd quartumse\n\nrem Create virtual environment\npython -m venv .venv\n\nrem Activate the environment\n.venv\\Scripts\\activate.bat\n</code></pre></p> <p>If you use Conda or another environment manager, create an equivalent environment targeting Python 3.10\u20133.12.</p>"},{"location":"tutorials/quickstart/#2-install-quartumse","title":"2. Install QuartumSE","text":"<p>Choose the extra set that matches your workflow:</p> <p>Unix/macOS: <pre><code># Core SDK only\npip install -e .\n\n# Core SDK + development tooling (pytest, black, ruff, mypy, jupyter)\npip install -e \".[dev]\"\n\n# With optional mitigation / chemistry dependencies (Python &lt; 3.13)\npip install -e \".[dev,mitigation,chemistry]\"\n</code></pre></p> <p>Windows: <pre><code># Core SDK only\npip install -e .\n\n# Core SDK + development tooling (pytest, black, ruff, mypy, jupyter)\npip install -e \".[dev]\"\n\n# With optional mitigation / chemistry dependencies (Python &lt; 3.13)\npip install -e \".[dev,mitigation,chemistry]\"\n</code></pre></p> <p>Upgrading <code>pip</code> before installation often avoids wheel build issues:</p> <p>Unix/macOS: <pre><code>python -m pip install --upgrade pip\n</code></pre></p> <p>Windows: <pre><code>python -m pip install --upgrade pip\n</code></pre></p>"},{"location":"tutorials/quickstart/#3-verify-the-installation","title":"3. Verify the installation","text":"<p>Run the basic smoke checks to make sure the package imports and the test suite passes on simulators:</p> <p>Unix/macOS: <pre><code># Confirm the CLI can be invoked\nquartumse --help\n\n# Quick import verification\npython -c \"from quartumse import ShadowEstimator; print('QuartumSE ready')\"\n\n# Run unit tests (skipping slow hardware checks)\npytest tests -m \"not slow and not hardware\" -v\n</code></pre></p> <p>Windows: <pre><code># Confirm the CLI can be invoked\nquartumse --help\n\n# Quick import verification\npython -c \"from quartumse import ShadowEstimator; print('QuartumSE ready')\"\n\n# Run unit tests (skipping slow hardware checks)\npytest tests -m \"not slow and not hardware\" -v\n</code></pre></p> <p>Install <code>pre-commit</code> hooks to keep formatting and linting consistent:</p> <p>Unix/macOS: <pre><code>pre-commit install\n</code></pre></p> <p>Windows: <pre><code>pre-commit install\n</code></pre></p>"},{"location":"tutorials/quickstart/#4-launch-the-quickstart-notebook-optional","title":"4. Launch the quickstart notebook (optional)","text":"<p>Unix/macOS: <pre><code># Ensure Jupyter is installed (included in the [dev] extras)\npip install jupyter\n\n# Start Jupyter Notebook or Lab\njupyter notebook\n# or\njupyter lab\n</code></pre></p> <p>Windows: <pre><code># Ensure Jupyter is installed (included in the [dev] extras)\npip install jupyter\n\n# Start Jupyter Notebook or Lab\njupyter notebook\n# or\njupyter lab\n</code></pre></p> <p>Open <code>notebooks/quickstart_shot_persistence.ipynb</code> and choose Run All.  The notebook walks through:</p> <ol> <li>Preparing a 3-qubit GHZ state.</li> <li>Estimating multiple observables with classical shadows.</li> <li>Inspecting the saved Parquet shot data and JSON provenance manifest.</li> <li>Replaying the experiment to calculate new observables without re-running the    circuit.</li> </ol> <p>Troubleshooting tips:</p> <ul> <li><code>ModuleNotFoundError: quartumse</code> \u2192 ensure the environment is activated and   <code>pip install -e .</code> succeeded.</li> <li>Browser does not open automatically \u2192 copy the Jupyter server URL from the   terminal into your browser.</li> <li>Kernel crashes mid-run \u2192 restart the kernel and choose Run All again.</li> </ul>"},{"location":"tutorials/quickstart/#5-run-the-st01-ghz-baseline-experiment","title":"5. Run the S\u2011T01 GHZ baseline experiment","text":"<p>The CLI script demonstrates the same workflow outside notebooks and produces provenance artifacts in <code>data/</code>:</p> <p>Unix/macOS: <pre><code>python experiments/shadows/S_T01_ghz_baseline.py --backend aer_simulator\n</code></pre></p> <p>Windows: <pre><code>python experiments/shadows/S_T01_ghz_baseline.py --backend aer_simulator\n</code></pre></p> <p>Key outputs:</p> <ul> <li>Observable estimates with 95% confidence intervals.</li> <li>Shot-savings ratio (SSR) versus direct measurement baselines.</li> <li>Manifest &amp; shot files saved under <code>data/manifests/</code> and <code>data/shots/</code>.</li> </ul> <p>Supply an IBM Quantum backend descriptor (e.g., <code>ibm:ibmq_qasm_simulator</code>) to run against managed hardware or the cloud simulator once credentials are configured.</p>"},{"location":"tutorials/quickstart/#6-next-steps","title":"6. Next steps","text":"<ul> <li>Review Testing for guidance on slow, integration,   and hardware test markers.</li> <li>Explore the Manifest Schema reference to   understand the manifest and Parquet schemas.</li> <li>Consult the Runtime runbook when planning IBM   hardware executions.</li> <li>Study the strategic context in the Project Bible   and Roadmap.</li> </ul>"}]}